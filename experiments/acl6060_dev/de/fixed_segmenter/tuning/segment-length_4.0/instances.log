{"index": 0, "prediction": "Hallo, das ist Elena. Ich werde vorstellen, dass wir unsere Arbeit, die Entdeckung und die Anpassung an die Arbeit vorstellen. In Spanien und in der Anpassung von Corpus and Projects Modeling. Wir werden in der Zukunft auch noch mal auf die Stra\u00dfe gehen. Wir haben die Aufgabe, die wir vorstellen, zu verarbeiten. Die Daten sagen, dass wir haben haben und einige Modelle haben. Aber ich muss sagen, was ist lexikalisch Barren? weil es so wichtig ist, wie es an der NLP-Task ist. Das ist die Verkn\u00fcpfung von W\u00f6rtern aus einer Sprache. In der anderen Sprache, in Spanisch, verwenden wir W\u00f6rter, die von Und hier haben Sie einige Beispiele wie z.B. Podcasts. von der von CrunchFind, der in England gespielt hat, in Spanien. Lexical Baring ist eine Art von linguistischer Baring. Was ist eigentlich einfach, wenn man in einer Sprache die Patterns anderer Sprachen verwendet. Und auch Baring und Switching haben manchmal in der er komponiert und beschrieben wird, so wie es #ah, die Sache mit den Linguisten, die mit den Sprachen vermischen. Gleichzeitig gibt es jedoch einige Unterschiede zwischen den Texten von Barrowing und Wir werden versuchen, zu verschieben, um zu versuchen, auf Text zu verschieben. Das ist etwas, das man durch Linguistik und durch Definition Die Code-Switches sind nicht integriert in irgendeine der Was wir in der Vergangenheit benutzt haben, ist etwas, das wir jetzt nicht mehr benutzen. auch dann durch manolingual. Die Borowings werden sich mit der Grammatik der Empf\u00e4nger-Sprache einverstanden erkl\u00e4ren. und schlie\u00dflich in die Empf\u00e4nger-Sprache integriert werden. Warum ist das eine interessante Ph\u00e4nomene? Punkt des Linguistik-Linguistikes ist eine Manifestation von wie man Sprache und wie sie sich verhalten. Und auch lexikalisch. Wir haben einige Beispiele von #ah. Die Textilwaren, die in der spanischen Sprache als Neuwand eingef\u00fchrt wurden, In Bezug auf NLP sind Anleihen eine h\u00e4ufige Sache. von aus der Sprache aus w\u00e4hlbaren W\u00f6rtern und infiziert automatisch. Die Textiltechnik von Leichtathletik hat sich als nutzbar erwiesen. die Streckenschaltung, wie Sparsing, Textsynthese oder Translationsmaschine. Es hat ein wachsendes Interesse in der Einfluss von Englisch auf andere Sprachen ist #ah #ah zu englischen W\u00f6rtern, die manchmal Anglistik und hier haben wir einige Beispiele von #ah auf automatische Entdeckung von Browsing in einigen dieser Sprachen. Also die Aufgabe, die wir vorschlagen, ist, In der spanischen Newspaper News. was bedeutet, dass wir in der Erfindung interessiert sind. aus anderen Sprachen, die in Spanien verwendet werden. Die Zeitungen, die nicht integriert oder integriert wurden, nicht integriert in Spanisch. Ich habe ein Beispiel. Das ist eine Satz in Spanisch, Las Prendas. Bestseller werden mit Blumenmotiven, Animal Print oder Patchwork-Arretalen gestempelt. Und wie Sie sehen, gibt es drei Texte, die Eigentlich ist Englisch wie best selling animal print and patchwork. Das ist die Art von Spannungen, an denen wir interessiert sind. Und das ist ein sehr wichtiger Punkt. auf die Anglisation der #ah, die konzipiert ist. C.R.F. Model f\u00fcr Englisch und Texte auf der Spanish News Wire. Das Modell hat einen Punkt von 86 erreicht. Es gab einige Einschr\u00e4nkungen, sowohl in der Datensammlung als auch in der Modellierung. Also die Daten #ah #ah, die sich auf einen einzigen Punkt konzentrieren. Die Nachrichten sind nur von Heldlines und auch von der in der Brawl in der Trainings- und Test-Tests. So hat das die Bewertung der Modellierung der Eigentlich generell zu generaliseren, vorher sagen wir: Wir wollen einige dieser #ah-Limitationen in #ah-Limitationen Das ist die Aufgabe. Also zu beginnen mit der mit einer neuen Datensatz #um die neue Datensatz Das war #ah ann\u00e4hert mit lexikalischen Bowings und die so ein Test zu erstellen, der so einfach wie m\u00f6glich ist. minimal \u00fcberlappen in Worten und Topics zwischen den Trainings. Und das ist der Test, der von den Quellen kommt. dass wir nicht in der Trainings-Sammlung sehen, Es gibt keinen \u00dcberlappen in der Zeit. Der Test ist auch sehr w\u00fctend, um dir einige Zahlen zu geben. Wenn die Trainingsseiten sechs Borings per Tausende Token, die Test enth\u00e4lt Twenty Bounce. Ich habe 1000 Token. Die Test enth\u00e4lt so viele. Die Ausstattung ist m\u00f6glich, in der Tat zwei Prozent der Die Wins in der Teststelle sind so, dass sie nicht w\u00e4hrend des Trainings gesehen werden. Und der Korpus besteht im Grunde aus einer Sammlung von Texten. Das kommt von verschiedenen Seiten von spanischen Zeitungen und Es ist anhand von Hand #ah using two tags. Einer f\u00fcr English-Lexikbarwins, die die Mehrheit der in Spanien und dann in anderen L\u00e4ndern f\u00fcr andere Sprachen. Wir verwenden Containerformate und wir verwenden BIO-Encoder. so dass wir k\u00f6nnen, um Single So wie man sich auskleidet, so wie man sich auskleidet. Das sind die Zahlen der Korps. wie man es sagen kann, so viel wie drei hundert. Siebzigtausend Token und hier haben Sie die Nummer von Spahn. dass wir als Englisch und die Sprachsprachigen als Englisch bezeichnet werden. wie viele der Kredite und wie viele von ihnen einzigartig sind. Und hier haben wir ein paar Beispiele von der Set. Die Datenstelle, wie Sie sehen k\u00f6nnen, haben wir hier in der ersten Zum Beispiel haben wir das Barwingen, das ist eine M\u00fctze. Wir haben es auch mit der B.I. benutzt. Oh, und so die B.I. Oh, ist f\u00fcr in spanisch so nicht f\u00fcr wo wir nicht barren. Und hier in diesem zweiten Beispiel haben wir Painting und Crash. die auch als \"Borrowings from English\" bezeichnet werden. So, wenn wir die Daten haben, werden wir mehrere weitere erforschen. Modelle f\u00fcr die Aufgabe der Extraktion und Detektion dieser Die ersten, die wir versuchen, sind die Conditioning-Modelle. Das ist das Modell, das schon mal benutzt wurde. Wir haben die gleichen handgefertigten Funktionen verwendet. Von der Seite von der Work, wie man das sehen kann. Diese Features sind bin\u00e4r, wie die Welt und die Token. Aber der Fall ist, dass es sich um einen Mark-Kurs handelt. Das ist so ein Typ von Features, von denen man erwartet, dass sie sich in der die Recognition Task. Das sind die Ergebnisse, Wir haben die. Wir haben die. Wir haben die. Wir haben die. F\u00fcnfzig von F one score using the. mit der Handcrafted-Figur, die unterschiedlich ist. #um vergleichen mit der berichteten F1 Score von mit dem gleichen CRF-Modell. aber auf unterschiedliche Datenst\u00fccke. Das ist eine lexikalische Entdeckung. Das, was wir geschaffen haben, ist viel schwieriger und wir Wir mussten mehr anspruchsvolle Modelle erforschen. Wir haben das Test gemacht. Wir benutzen bei Transformator-Base-Modellen Beton, das monolingual model for spanish and also monolingual model. Beide Modelle werden wir durch die Transformers Library von Hagen und Das ist die Folge, die wir bekommen, wenn du sagen kannst, dass du eine M\u00fctze hast. die besser aussehen als die Beton, beide auf der Entwicklung. auf der Teststelle und \u00fcber alle Metriken. Das haben wir. Ich habe eine Idee, um zu vergleichen. C R F Model Obtain und Eighty Two. Die CRF hat 55 von einem Punkt abgeholt. Wir haben die #ah-Mutation, die wir jetzt aufnehmen, die zwei gro\u00dfe Unterschiede hat. So, dass wir diese Ergebnisse haben, haben wir gefragt. Und wir haben auch noch eine andere Frage, die ist: Was ist #ah? #oh find ein BiosTM CRF-Modell, gef\u00fcllt mit anderen. Die verschiedenen Arten von Embedings k\u00f6nnen unterschiedliche Arten von linguistischen und die Ergebnisse durch Transaktionen. So, wir wollen so etwas machen. Prelimin\u00e4re Experimente, wir f\u00fchren diese Biostimulations- Wir haben die Bibliothek mit der Modelleinrichtung genutzt und wir haben versucht, sie zu erproben. mit unterschiedlichen Typen von Betonungen wie Transformationsb\u00e4umen und auch Fasten. #ah, wie man das so sch\u00f6n macht. Wir haben das gefunden. Transformationsformeln entfalten sich besser als nichtkontextuelle Entfalten. Die Kombination aus English and Spanish and Spanish Beds and Beds will erledigen. Und das ist B.P. Embedings. Besser, wenn man an einem und einem Karakter bearbeitet, wird es besser. Und das war in der Meinte die beste Performance der Woche. Ich habe es nicht gesehen. Beide Modelle waren ohne MCRF. Modell #um using one was feat with #um. Beton und Betonbeton und B.P. und der andere Beton und Betonbeton. Und auch Karate-Besprechungen. Das ist das letzte. produziert die h\u00f6chste F1 Punktzahl auf der Testseite, obwohl die h\u00f6chste Punktzahl auf der Entwicklungsschicht, die von der One with character entwickelt wurde. Ich habe mir das nicht vorgenommen. Die beste L\u00f6sung, die wir mit dem Muttling-Batt bekommen, ist, dass wir von siebenzig sechs auf der Entwicklungsschicht und achtzig zwei auf der Testseite. Das ist eine Verbesserung im Vergleich zu diesen Ergebnissen. Wir fragen uns auch noch eine andere Frage, die ist: Kann man sich mit der Technik auskennen? werden k\u00f6nnen, als Transfer von Language Identification und Code. Also wir laufen den gleichen STM-Modell. Wir haben einen runter verwendeten Flieger, aber wir benutzen ihn nicht. Und das ist ein unadapterter Transformator. Wir verwenden Code-Switching-Embeddings. Die sind so eingebettet. wenn man sich vorstellen kann, dass man sich auf die Transformationsmodelle der Transformationsmodelle vorbereitet hat, f\u00fcr die Sprachidentifizierung auf der spanischen englischen Seite der Das ist die Schaltung der Datei. Das ist die Schaltung der Datei auf der Datei. auf spanisch-englisch-spanisch-englisch-switch so we Wir haben unsere Biologischen DMCRF mit Switch-Bedings und Optionsbediener, B.P.B. und B.B. Und so, der beste Ergebnis, den wir bekommen, ist vier Punkte. In zweiundzwanzig, was die h\u00f6chste ist, \u00fcber die alle Modelle, die wir versuchen, auf der Ich habe gesagt, dass der beste #ah-Rezultat ein Schlag ist. auf der Entwicklungsschicht, die siebenundzwanzig war, ist niedriger als die beste die durch die Biostatistik CFR erworben wurde. mit unadaptierten Embeddings. Also einige Schlussfolgerungen von Wir haben unsere Arbeit produziert. Die neue Version der spanischen Newswire ist mit Analogie angepasst. Das ist mehr Barwings als Barwings. O. W. Rich, der Pr\u00e4sident der US-Regierung, hat einen Ausflug von Four Tables. von #ah models for lexical brainstorming #ah in. von der Analyse, wie man es sozusagen so gut macht. Das ist ein sehr beliebtes Thema. Negative Einbeziehung von Apotheken, Barwings, Worts und so weiter. Und auch in Englisch und Spanisch. Interessant. BPM-Bedings sind so, dass sie einen Punkt verbessern und einen Charakter entwickeln. Und das ist ein sehr interessanter Artikel. Ich finde, dass wir es vielleicht in der Zukunft noch weiterer entwickeln k\u00f6nnen. Und das ist alles, was ich habe. Danke f\u00fcrs Zuh\u00f6ren. Und ich bin froh, dass wir das so gut machen k\u00f6nnen. (Sprechen)", "delays": [4000.0, 4000.0, 4000.0, 4000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 92000.0, 92000.0, 92000.0, 92000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 180000.0, 180000.0, 180000.0, 180000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 444000.0, 444000.0, 444000.0, 444000.0, 448000.0, 448000.0, 448000.0, 448000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 628000.0, 628000.0, 628000.0, 632000.0, 632000.0, 632000.0, 632000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 648000.0, 648000.0, 648000.0, 648000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 732000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 736000.0, 737440.0], "elapsed": [5277.343511581421, 5277.343511581421, 5277.343511581421, 5277.343511581421, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 10130.962610244751, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 14824.007987976074, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 19439.70489501953, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 24076.133251190186, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 28715.943813323975, 33348.15311431885, 33348.15311431885, 33348.15311431885, 33348.15311431885, 33348.15311431885, 33348.15311431885, 33348.15311431885, 33348.15311431885, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 38221.02904319763, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 42877.39038467407, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 47572.15070724487, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 52246.413469314575, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 56959.03015136719, 61596.147775650024, 61596.147775650024, 61596.147775650024, 61596.147775650024, 61596.147775650024, 61596.147775650024, 61596.147775650024, 61596.147775650024, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 66329.27250862122, 70872.6258277893, 70872.6258277893, 70872.6258277893, 70872.6258277893, 70872.6258277893, 70872.6258277893, 70872.6258277893, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 75486.89150810242, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 80235.25524139404, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 84945.56140899658, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 89659.9133014679, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 94295.55249214172, 98931.94222450256, 98931.94222450256, 98931.94222450256, 98931.94222450256, 98931.94222450256, 98931.94222450256, 98931.94222450256, 98931.94222450256, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 103666.77403450012, 108183.98785591125, 108183.98785591125, 108183.98785591125, 108183.98785591125, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 112989.32528495789, 117646.91233634949, 117646.91233634949, 117646.91233634949, 117646.91233634949, 117646.91233634949, 117646.91233634949, 117646.91233634949, 122207.2913646698, 122207.2913646698, 122207.2913646698, 122207.2913646698, 122207.2913646698, 122207.2913646698, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 126940.83881378174, 131578.5722732544, 131578.5722732544, 131578.5722732544, 131578.5722732544, 131578.5722732544, 131578.5722732544, 131578.5722732544, 131578.5722732544, 136119.76861953735, 136119.76861953735, 136119.76861953735, 136119.76861953735, 136119.76861953735, 136119.76861953735, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 140868.32404136658, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 145503.7772655487, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 150176.41067504883, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 154926.75733566284, 159732.58018493652, 159732.58018493652, 159732.58018493652, 159732.58018493652, 159732.58018493652, 159732.58018493652, 159732.58018493652, 164248.93069267273, 164248.93069267273, 164248.93069267273, 164248.93069267273, 164248.93069267273, 164248.93069267273, 164248.93069267273, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 168888.9183998108, 173437.45970726013, 173437.45970726013, 173437.45970726013, 173437.45970726013, 173437.45970726013, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 178062.09349632263, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 182752.5281906128, 187358.38389396667, 187358.38389396667, 187358.38389396667, 187358.38389396667, 187358.38389396667, 187358.38389396667, 187358.38389396667, 191900.6474018097, 191900.6474018097, 191900.6474018097, 191900.6474018097, 191900.6474018097, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 196545.2859401703, 201128.6425590515, 201128.6425590515, 201128.6425590515, 201128.6425590515, 201128.6425590515, 201128.6425590515, 201128.6425590515, 201128.6425590515, 205750.71954727173, 205750.71954727173, 205750.71954727173, 205750.71954727173, 205750.71954727173, 205750.71954727173, 205750.71954727173, 205750.71954727173, 210263.414144516, 210263.414144516, 210263.414144516, 210263.414144516, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 214978.67560386658, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 219808.51101875305, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 224409.34586524963, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 229136.33489608765, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 233806.5640926361, 238324.1798877716, 238324.1798877716, 238324.1798877716, 238324.1798877716, 238324.1798877716, 238324.1798877716, 238324.1798877716, 242991.39833450317, 242991.39833450317, 242991.39833450317, 242991.39833450317, 242991.39833450317, 242991.39833450317, 242991.39833450317, 242991.39833450317, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 247723.34051132202, 252267.02737808228, 252267.02737808228, 252267.02737808228, 252267.02737808228, 252267.02737808228, 252267.02737808228, 252267.02737808228, 252267.02737808228, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 257038.86198997498, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 261714.16115760803, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 266309.335231781, 270977.8735637665, 270977.8735637665, 270977.8735637665, 270977.8735637665, 270977.8735637665, 270977.8735637665, 270977.8735637665, 270977.8735637665, 275551.35202407837, 275551.35202407837, 275551.35202407837, 275551.35202407837, 275551.35202407837, 275551.35202407837, 275551.35202407837, 275551.35202407837, 280171.062707901, 280171.062707901, 280171.062707901, 280171.062707901, 280171.062707901, 280171.062707901, 280171.062707901, 284865.9908771515, 284865.9908771515, 284865.9908771515, 284865.9908771515, 284865.9908771515, 284865.9908771515, 284865.9908771515, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 289426.0129928589, 294002.7186870575, 294002.7186870575, 294002.7186870575, 294002.7186870575, 294002.7186870575, 294002.7186870575, 294002.7186870575, 294002.7186870575, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 298673.36440086365, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 303286.9403362274, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 307940.1683807373, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 312552.94847488403, 317145.46155929565, 317145.46155929565, 317145.46155929565, 317145.46155929565, 317145.46155929565, 317145.46155929565, 317145.46155929565, 321706.42137527466, 321706.42137527466, 321706.42137527466, 321706.42137527466, 321706.42137527466, 321706.42137527466, 321706.42137527466, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 326401.48186683655, 330959.5773220062, 330959.5773220062, 330959.5773220062, 330959.5773220062, 330959.5773220062, 330959.5773220062, 335576.16567611694, 335576.16567611694, 335576.16567611694, 335576.16567611694, 335576.16567611694, 335576.16567611694, 335576.16567611694, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 340172.66368865967, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 344791.5506362915, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 349543.64943504333, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 354220.45135498047, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 358799.16191101074, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 363418.05267333984, 368113.5473251343, 368113.5473251343, 368113.5473251343, 368113.5473251343, 368113.5473251343, 368113.5473251343, 368113.5473251343, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 372712.7377986908, 377401.9994735718, 377401.9994735718, 377401.9994735718, 377401.9994735718, 377401.9994735718, 377401.9994735718, 377401.9994735718, 381897.89295196533, 381897.89295196533, 381897.89295196533, 381897.89295196533, 381897.89295196533, 381897.89295196533, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 386603.0230522156, 391137.8846168518, 391137.8846168518, 391137.8846168518, 391137.8846168518, 391137.8846168518, 391137.8846168518, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 395754.54020500183, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 400444.0493583679, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 405154.46877479553, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 409792.6149368286, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 414389.4658088684, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 419044.16513442993, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 423716.2313461304, 428315.1183128357, 428315.1183128357, 428315.1183128357, 428315.1183128357, 428315.1183128357, 428315.1183128357, 428315.1183128357, 428315.1183128357, 432934.97681617737, 432934.97681617737, 432934.97681617737, 432934.97681617737, 432934.97681617737, 432934.97681617737, 432934.97681617737, 432934.97681617737, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 437534.3608856201, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 442168.5152053833, 446782.7935218811, 446782.7935218811, 446782.7935218811, 446782.7935218811, 446782.7935218811, 446782.7935218811, 446782.7935218811, 446782.7935218811, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 451451.8449306488, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 456084.66839790344, 460755.8696269989, 460755.8696269989, 460755.8696269989, 460755.8696269989, 460755.8696269989, 460755.8696269989, 460755.8696269989, 460755.8696269989, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 465333.12249183655, 469906.9905281067, 469906.9905281067, 469906.9905281067, 469906.9905281067, 469906.9905281067, 469906.9905281067, 469906.9905281067, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 474519.91748809814, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 479195.09196281433, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 483870.2988624573, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 488598.96516799927, 493175.12941360474, 493175.12941360474, 493175.12941360474, 493175.12941360474, 493175.12941360474, 493175.12941360474, 493175.12941360474, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 497845.064163208, 502399.81341362, 502399.81341362, 502399.81341362, 502399.81341362, 502399.81341362, 502399.81341362, 502399.81341362, 507029.89530563354, 507029.89530563354, 507029.89530563354, 507029.89530563354, 507029.89530563354, 507029.89530563354, 511640.0594711304, 511640.0594711304, 511640.0594711304, 511640.0594711304, 511640.0594711304, 511640.0594711304, 511640.0594711304, 511640.0594711304, 516174.69215393066, 516174.69215393066, 516174.69215393066, 516174.69215393066, 520689.5263195038, 520689.5263195038, 520689.5263195038, 520689.5263195038, 525249.7224807739, 525249.7224807739, 525249.7224807739, 525249.7224807739, 525249.7224807739, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 529868.6368465424, 534507.0035457611, 534507.0035457611, 534507.0035457611, 534507.0035457611, 534507.0035457611, 534507.0035457611, 538991.081237793, 538991.081237793, 538991.081237793, 538991.081237793, 538991.081237793, 543666.7053699493, 543666.7053699493, 543666.7053699493, 543666.7053699493, 543666.7053699493, 543666.7053699493, 548347.8746414185, 548347.8746414185, 548347.8746414185, 548347.8746414185, 548347.8746414185, 548347.8746414185, 548347.8746414185, 548347.8746414185, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 552984.400510788, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 557775.1677036285, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 562414.3145084381, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 567072.0703601837, 571630.8536529541, 571630.8536529541, 571630.8536529541, 571630.8536529541, 571630.8536529541, 571630.8536529541, 571630.8536529541, 576209.000825882, 576209.000825882, 576209.000825882, 576209.000825882, 576209.000825882, 576209.000825882, 576209.000825882, 576209.000825882, 580800.8806705475, 580800.8806705475, 580800.8806705475, 580800.8806705475, 580800.8806705475, 580800.8806705475, 580800.8806705475, 580800.8806705475, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 585621.7541694641, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 590235.226392746, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 594929.0716648102, 599657.7498912811, 599657.7498912811, 599657.7498912811, 599657.7498912811, 599657.7498912811, 599657.7498912811, 599657.7498912811, 599657.7498912811, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 604291.6083335876, 608788.2068157196, 608788.2068157196, 608788.2068157196, 608788.2068157196, 608788.2068157196, 613307.8529834747, 613307.8529834747, 613307.8529834747, 613307.8529834747, 613307.8529834747, 613307.8529834747, 617958.5509300232, 617958.5509300232, 617958.5509300232, 617958.5509300232, 617958.5509300232, 617958.5509300232, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 622788.3381843567, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 627539.2029285431, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 632197.0076560974, 636929.8288822174, 636929.8288822174, 636929.8288822174, 636929.8288822174, 636929.8288822174, 636929.8288822174, 636929.8288822174, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 641645.2453136444, 646225.5191802979, 646225.5191802979, 646225.5191802979, 646225.5191802979, 646225.5191802979, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 650938.0121231079, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 655560.8110427856, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 660218.0378437042, 664818.9747333527, 664818.9747333527, 664818.9747333527, 664818.9747333527, 664818.9747333527, 664818.9747333527, 664818.9747333527, 664818.9747333527, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 669630.567073822, 674307.3451519012, 674307.3451519012, 674307.3451519012, 674307.3451519012, 674307.3451519012, 674307.3451519012, 674307.3451519012, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 679057.9898357391, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 683728.9447784424, 688244.875907898, 688244.875907898, 688244.875907898, 688244.875907898, 688244.875907898, 688244.875907898, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 692991.6887283325, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 698408.2336425781, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 702986.7532253265, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 707776.7143249512, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 712397.1102237701, 716996.6855049133, 716996.6855049133, 716996.6855049133, 716996.6855049133, 716996.6855049133, 716996.6855049133, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 721711.6968631744, 726292.8268909454, 726292.8268909454, 726292.8268909454, 726292.8268909454, 726292.8268909454, 726292.8268909454, 730912.0013713837, 730912.0013713837, 730912.0013713837, 735414.7622585297, 735414.7622585297, 735414.7622585297, 735414.7622585297, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 740284.3050956726, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 744943.1455135345, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 749736.020565033, 754464.4014835358, 754464.4014835358, 754464.4014835358, 754464.4014835358, 759019.2437171936, 759019.2437171936, 759019.2437171936, 759019.2437171936, 759019.2437171936, 759019.2437171936, 763828.9754390717, 763828.9754390717, 763828.9754390717, 763828.9754390717, 763828.9754390717, 763828.9754390717, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 768506.5643787384, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 773358.8829040527, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 778073.6100673676, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 782840.0130271912, 787473.254442215, 787473.254442215, 787473.254442215, 787473.254442215, 787473.254442215, 787473.254442215, 787473.254442215, 792187.0729923248, 792187.0729923248, 792187.0729923248, 792187.0729923248, 792187.0729923248, 792187.0729923248, 792187.0729923248, 796691.153049469, 796691.153049469, 796691.153049469, 796691.153049469, 796691.153049469, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 801380.0699710846, 805955.6741714478, 805955.6741714478, 805955.6741714478, 805955.6741714478, 805955.6741714478, 805955.6741714478, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 810759.9165439606, 815408.5702896118, 815408.5702896118, 815408.5702896118, 815408.5702896118, 815408.5702896118, 815408.5702896118, 815408.5702896118, 815408.5702896118, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 820044.730424881, 824562.664270401, 824562.664270401, 824562.664270401, 824562.664270401, 824562.664270401, 824562.664270401, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 829329.7717571259, 833924.4284629822, 833924.4284629822, 833924.4284629822, 833924.4284629822, 833924.4284629822, 833924.4284629822, 833924.4284629822, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 838658.5109233856, 843199.4421482086, 843199.4421482086, 843199.4421482086, 843199.4421482086, 843199.4421482086, 843199.4421482086, 843199.4421482086, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 847874.2263317108, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 852566.8406486511, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 857202.5771141052, 859090.6791114807], "prediction_length": 1681, "reference": "Hallo, hier ist Elena und ich stelle nun unsere Arbeit vor: Die Erkennung nicht-assimilierter Entlehnungen im Spanischen: Ein annotierter Korpus und Ans\u00e4tze zur Modellierung. Wir werden uns also damit besch\u00e4ftigen, was die lexikalische Entlehnung ist, die von uns vorgeschlagene Aufgabe, den ver\u00f6ffentlichten Datensatz und einige untersuchte Modelle. Doch zun\u00e4chst einmal: Was ist die lexikalische Entlehnung und warum ist sie als NLP-Aufgabe so wichtig? Die lexikalische Entlehnung ist im Grunde die \u00dcbernahme von W\u00f6rtern aus einer Sprache in eine andere Sprache. Zum Beispiel verwenden wir im Spanischen W\u00f6rter, die aus dem Englischen stammen. Und hier ein paar Beispiele: W\u00f6rter wie Podcast, App und Online-Crowdfunding sind englische W\u00f6rter, die wir manchmal im Spanischen verwenden. Die lexikalische Entlehnung ist eine Art der sprachlichen Entlehnung, die im Grunde genommen die Reproduktion von Mustern einer Sprache in einer anderen Sprache bedeutet. Manchmal wurde die Entlehnung mit dem Code-Switching verglichen und als ein Kontinuum beschrieben. Code-Switching wird von Zweisprachigen praktiziert, wenn sie zwei Sprachen gleichzeitig verwenden. Es gibt jedoch einige Unterschiede zwischen lexikalischer Entlehnung und Code-Switching. Wir werden uns auf die lexikalische Entlehnung konzentrieren. Zweisprachige Personen praktizieren das sogenannte Code-Switching. Per Definition sind die Code-Switches nicht Teil der verwendeten Sprachen, w\u00e4hrend die lexikalische Entlehnung auch von einsprachigen Personen verwendet wird. Die Entlehnungen werden der Grammatik der Empf\u00e4ngersprache angepasst. Entlehnungen k\u00f6nnen Schritt f\u00fcr Schritt in die Empf\u00e4ngersprache integriert werden. Warum ist Entlehnen so ein interessantes Ph\u00e4nomen? Aus Sicht der Linguistik ist die Entlehnung eine Manifestation dessen, wie sich Sprachen ver\u00e4ndern und wie sie interagieren. Auch lexikalische Entlehnungen sind eine Quelle f\u00fcr neue W\u00f6rter. Hier finden Sie einige Beispiele f\u00fcr lexikalische Entlehnungen, die als neue W\u00f6rter in die spanische Sprache aufgenommen wurden. Beim NLP sind Entlehnungen eine h\u00e4ufige Quelle von W\u00f6rtern, die nicht im Wortschatz enthalten sind. Die automatische Erkennung lexikalischer Entlehnungen erwies sich als n\u00fctzlich f\u00fcr NLP und nachgelagerte Aufgaben wie Parsing, Text-zu-Sprache-Synthesen oder die maschinelle \u00dcbersetzung. Der Einfluss des Englischen auf andere Sprachen erf\u00e4hrt immer st\u00e4rkeres Interesse, insbesondere bei englischen lexikalischen Entlehnungen. Diese werden manchmal auch als Anglizismen bezeichnet. Hier sind einige Beispiele von Arbeiten zur automatischen Erkennung von Entlehnungen in einigen dieser Sprachen. Die Aufgabe, die wir vorschlagen, besteht also darin, nicht-assimilierte lexikalische Entlehnungen in spanischen Nachrichten zu erkennen. Wir sind daran interessiert, aus anderen Sprachen entlehnte W\u00f6rter zu extrahieren, die in spanischen Zeitungen verwendet werden, aber nicht in die Empf\u00e4ngersprache integriert oder assimiliert wurden. Sie wurden also noch nicht ins Spanische integriert. Hier ist ein Beispiel. Dies ist ein Satz auf Spanisch: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork. Wie Sie sehen k\u00f6nnen, sind hier drei Textpassagen, die eigentlich englische W\u00f6rter sind: Bestseller, Animal Print und Patchwork. Bei diesen Passagen wollen wir extrahieren und erkennen. Es gab fr\u00fcher schon Arbeiten \u00fcber die Erkennung von Anglizismen. Diese besch\u00e4ftigten sich mit einem CRF-Modell f\u00fcr die Erkennung von Anglizismen in spanischen Nachrichten. Dieses Modell erreichte einen F1-Score von 86. Es gab jedoch einige Einschr\u00e4nkungen sowohl beim Datensatz als auch beim Modellierungsansatz. Der Datensatz konzentrierte sich also ausschlie\u00dflich auf eine Quelle von den Nachrichten und bestand nur aus Schlagzeilen. Au\u00dferdem gab es \u00dcberschneidungen bei den Entlehnungen, die im Trainingssatz und im Testsatz vorkommen. Dadurch konnte nicht beurteilt werden, ob der Modellierungsansatz tats\u00e4chlich auf zuvor unbekannte Entlehnungen verallgemeinert werden kann. Unser Ziel ist es also, einige dieser Einschr\u00e4nkungen in der Aufgabe zu \u00fcberwinden. Zu Beginn haben wir also einen neuen Datensatz erstellt. Das Ziel war ein neuer Datensatz, der mit lexikalischen Entlehnungen annotiert wurde, und einen m\u00f6glichst schwierigen Testsatz zu erstellen. Es g\u00e4be also minimale \u00dcberschneidungen bei W\u00f6rtern und Themen zwischen dem Trainingssatz und dem Testsatz. Das Ergebnis ist, dass der Testsatz aus Quellen und Daten stammt, die wir nicht im Trainingssatz sehen. Hier k\u00f6nnen Sie sehen, dass es keine \u00dcberschneidungen in der Zeit gibt. Au\u00dferdem enth\u00e4lt der Testsatz auch sehr viele Entlehnungen. Um Ihnen ein paar Zahlen zu nennen: Wenn der Trainingssatz sechs Entlehnungen pro 1000 Token enth\u00e4lt, enth\u00e4lt der Testsatz 20 Entlehnungen pro 1000 Token. Der Testsatz enthielt so viele Vokabelw\u00f6rter wie m\u00f6glich. Tats\u00e4chlich sind 92 Prozent der Entlehnungen im Testsatz OOV. Sie waren also w\u00e4hrend des Trainings nicht bekannt. Der Korpus bestand im Wesentlichen aus einer Sammlung von Texten, die aus verschiedenen Quellen spanischer Zeitungen stammten. Er wurde manuell mit zwei Tags annotiert. Einer f\u00fcr englische lexikalische Entlehnungen, die den Gro\u00dfteil der lexikalischen Entlehnungen im Spanischen ausmachen, und dann das andere Label f\u00fcr Entlehnungen aus anderen Sprachen. Wir verwenden CONLL-Formate und die BIO-Kodierung, sodass wir einfache Token-Entlehnungen wie \u201eApp\u201c oder mehrteilige Token-Entlehnungen wie \u201emaschinelles Lernen\u201c kodieren k\u00f6nnen. Das sind die Nummern des Korpus. Wie Sie sehen k\u00f6nnen, handelt es sich um etwa 370 000 Token. Hier sehen Sie die Reihe an Passagen, die als Englisch markiert wurden, und die Passagen, die als andere Entlehnungen markiert waren, und wie viele davon einzigartig waren. Hier sehen Sie einige Beispiele f\u00fcr den Datensatz. Wie Sie zum Beispiel hier sehen k\u00f6nnen, haben wir im ersten Beispiel die Entlehnung \u201ebatch cooking\u201c, die eine mehrteilige Wort-Entlehnung ist. Wir haben dieses Wort mit der BIO-Kodierung annotiert. BIO wurde also f\u00fcr W\u00f6rter im Spanischen verwendet, also nicht f\u00fcr W\u00f6rter, die nicht entlehnt wurden. Hier in diesem zweiten Beispiel sehen Sie \u201ebenching\u201c und \u201ecrash\u201c, die ebenfalls als Entlehnungen aus dem Englischen markiert sind. Nachdem wir also den Datensatz hatten, untersuchten wir verschiedene Modelle f\u00fcr die Aufgabe, bei der wir lexikalische Entlehnungen extrahieren und erkennen wollten. Zuerst haben wir das bedingte Zufallsfeld Modell getestet. Das war das Modell, das bei fr\u00fcheren Arbeiten verwendet worden war. Wir haben die gleichen manuell erstellten Funktionen wie bei dieser Arbeit verwendet. Wie Sie sehen k\u00f6nnen, sind dies die Funktionen. Dies sind bin\u00e4re Funktionen, wie das Wort oder das Token in Gro\u00dfbuchstaben. Handelt es sich um einen Titel? Ist es ein Anf\u00fchrungszeichen? Solche Dinge sind die Art von Funktionen, die man bei einer Named Entity Recognition-Aufgabe erwarten w\u00fcrde. Das sind die Ergebnisse, die wir erhalten haben. Wir erhalten 55 F1-Scores, wenn wir das CRF-Modell mit manuell erstellten Funktionen verwenden. Das ist ein gro\u00dfer Unterschied im Vergleich zum bereits berichteten F1-Score von 86, der ein Ergebnis desselben CRF-Modells mit derselben Funktionen war, aber auf einen anderen Datensatz angewendet wurde, auch f\u00fcr die Erkennung von spanischen lexikalischen Entlehnungen. Das beweist also, dass der Datensatz, den wir erstellt haben, schwieriger ist und dass wir anspruchsvollere Modelle f\u00fcr diese Aufgaben entwickeln m\u00fcssen. Wir haben also zwei Transformer-basierte Modelle getestet. Wir haben BETO verwendet, ein einsprachiges BERT-Modell, das auf Spanisch trainiert ist, und auch ein mehrsprachiges BERT-Modell. Beide Modelle verwenden wir \u00fcber die Transformer-Bibliothek von HuggingFace. Das sind die Ergebnisse, die wir erhalten haben. Wie Sie sehen k\u00f6nnen, schneidet das mehrsprachige BERT sowohl im Entwicklungssatz als auch im Testsatz und bei allen Metriken besser ab als BETO. Das CRF-Modell hat 82 erreicht, nur damit wir einen Vergleich ziehen k\u00f6nnen. Das CRF-Modell erreichte einen F1-Score von 55, w\u00e4hrend das mehrsprachige BERT 82 erreichte, was ein gro\u00dfer Unterschied ist. Nachdem wir also diese Ergebnisse hatten, stellten wir uns eine weitere Frage, n\u00e4mlich: K\u00f6nnen wir ein BiLSTM-CRF-Modell finden, verschiedene Arten von Einbettungen darin einspeisen, Einbettungen, die verschiedene Arten von sprachlichen Informationen kodieren, und die Ergebnisse von Transformer-basierten Modellen \u00fcbertreffen? Daf\u00fcr haben wir einige pr\u00e4limin\u00e4re Experimente durchgef\u00fchrt, und zwar mit dem BiLSTM-CRF-Modell unter Verwendung von Flare Library. Wir haben mit verschiedenen Arten von Einbettungen experimentiert, z.\u00a0B. mit Transformer-basierten, aber auch mit Schnell-Text-Einbettungen und Zeichen-Einbettungen. Wir haben herausgefunden, dass Transformer-basierte Einbettungen besser abschneiden als nicht kontextualisierte Einbettungen, dass die Kombination aus englischer BERT- und spanischer BETO-Einbettung besser ist als mehrsprachige BERT-Einbettungen. Auch ergeben die BPE-Einbettungen ein besseres F1 und die Zeicheneinbettungen ein besseres Recall. Vor diesem Hintergrund waren dies die besten Ergebnisse, die wir erzielen konnten. Beide Modelle waren BiLSTM-CRF-Modelle unter Verwendung von Flare. Bei einem wurden BETO- und BERT-Einbettungen und BPE eingespeist, beim anderen BETO- und BERT-Einbettungen und BPE sowie Zeichen-Einbettungen. Letzteres war dasjenige, das den h\u00f6chste F1-Score beim Testsatz erzielte, obwohl der h\u00f6chste Score beim Entwicklungssatz durch das Modell ohne Zeichen-Einbettungen erreicht wurde. Vergessen Sie nicht, dass das beste Ergebnis, das wir mit mehrsprachigem BERT erzielt haben, einen F1-Wert von 76 im Entwicklungssatz und 82 im Testsatz erreichte. Dies ist also eine Verbesserung im Vergleich zu diesen Ergebnissen. Schlie\u00dflich stellten wir uns noch eine weitere Frage: Kann die Erkennung von lexikalischen Entlehnungen als Transferlernen von Sprachidentifikation beim Code-Switching formuliert werden? Wir haben also dasselbe BiLSTM-CRF-Modell wie mit Flare verwendet, aber anstelle dieser nicht angepassten Transformer-basierten BETO- und BERT-Einbettungen haben wir Code-Switch-Einbettungen verwendet. Was sind Code-Switch-Einbettungen? Dies sind Einbettungen, die auf Transformer-basierte Einbettungen abgestimmt wurden. Diese wurden f\u00fcr die Sprachidentifikation im Spanisch-Englisch-Abschnitt des LinCE-Code-Switching-Datensatzes vortrainiert. LinCE ist ein Datensatz vom Code-Switching, der einen Abschnitt mit Code-Switching von Spanisch und Englisch enth\u00e4lt. Wir speisten also Code-Switch-Einbettungen in unser BiLSTM-CRF ein. Optional k\u00f6nnen Zeicheneinbettungen, BPE-Einbettungen und so weiter eingef\u00fcgt werden. Das beste Ergebnis, das wir erzielt haben, war 84,22. Das ist das beste Ergebnis aller Modelle, die wir mit dem Testsatz ausprobiert haben. Obwohl der beste F1-Score, den wir beim Entwicklungssatz erzielt haben, 97 war, war dieser niedriger als das beste Ergebnis vom BiLSTM-CRF, das mit unangepassten Einbettungen eingespeist war. Hier sind einige Schlussfolgerungen aus unserer Arbeit. Wir haben einen neuen Datensatz mit spanischen Nachrichten erstellt, der mit nicht assimilierten lexikalischen Entlehnungen annotiert ist. Dieser Datensatz ist dichter an Entlehnungen und OOV-reicher als fr\u00fchere Ressourcen. Wir haben vier Arten von Modellen f\u00fcr die Erkennung lexikalischer Entlehnungen erforscht. Also. Was die Fehleranalyse betrifft, war der Recall ein Schwachpunkt bei allen Modellen. Wie Sie hier sehen k\u00f6nnen, geh\u00f6ren zu den h\u00e4ufigen falsch-negativen Ergebnissen beispielsweise auch Entlehnungen in Gro\u00dfbuchstaben und W\u00f6rter, die es sowohl im Englischen als auch im Spanischen gibt. Interessant ist auch, dass BPE-Einbettungen den F1-Core zu verbessern scheinen. Und die Einbettung von Zeichen scheint den Recall zu verbessern. Das ist eine interessante Erkenntnis, die wir vielleicht in k\u00fcnftigen Arbeiten untersuchen k\u00f6nnen. Also. Das w\u00e4re alles, was ich zu sagen habe. Vielen Dank f\u00fcrs Zuh\u00f6ren.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.268.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:17.440 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 737440.0}
{"index": 1, "prediction": "Mein Name ist Antoine, ich bin Doktorandin. Ich pr\u00e4sentiere Ihnen unsere Arbeit an der Universit\u00e4t von Massachusetts. Kenia, Kenya Belt, Morphology are Kenya Rwanda Language. Ich bin ein Moderator. Heute werde ich \u00fcber die Motivation f\u00fcr diese Forschung, dann pr\u00e4sentieren wir Kenya Beret Model Architecture. In Detail, dann erz\u00e4hlen wir \u00fcber die experimentellen Ergebnisse. Dann schlie\u00dfen wir mit einigen Schlussfolgerungen. Wir wissen alle, dass das Natural Language Project die vorl\u00e4ufigen Erweiterungen h\u00e4tten m\u00f6glich gemacht durch die Verwendung der in der Sprache Models wie Belt, wie auch immer, die der Zahl der Einschr\u00e4nkungen. Das ist expressiv von den meisten morphologischen Sprachen. die Ubiquitas-Byte-Peer-Enkodierung ist so einfach. Die Algorithmen, die ich benutze, k\u00f6nnen nicht die genaue die World Lexical Unit, die die Morphine braucht, die f\u00fcr Wir haben eine sehr gute Idee. Hier haben wir drei Kinyarwanda-W\u00f6rter, die mehrere weitere aber die B P Algorithmen k\u00f6nnen nicht extrahieren. Das ist, weil es morphologische Regeln gibt. produziert verschiedene Oberfl\u00e4chenformen, die die genauen und BPE, die sich bereits auf der die Forms, die nicht auf diese lexikalische Formeln zugreifen k\u00f6nnen. Die zweite Herausforderung ist, dass auch wenn wir nicht alleine sind, One hard access to anorak morphologischer Analyzer, repliziert. B P P E-Token mit Morphins ist nicht genug, um auszusprechen. morphologische Kompositionalit\u00e4t. Ein drittes Das ist das neue, pr\u00e4tentierte Language Models sind mehr. und wir m\u00fcssen uns auf High-Resource-Sprachen die die Anwendbarkeit auf Low Resources und Diverse Languages ist. Wir pr\u00e4sentieren daher Kenya Bert. die eine einfache, aber effektive Anpassung der Das ist eine Technik, die es erfordert, um mehr effektiv zu handhaben. Wir entwickeln kenianische Sprachen. Rwanda, eine Low Resource Morphological Language, die Spoken by mehr als zw\u00f6lf Millionen Menschen in der East East. und Central Afrika. Das ist der Input zu dem Modell. ist auch eine Satz oder ein Dokument. Zum Beispiel Hier haben wir John Twarah, einen Bieradutanten. Das bedeutet, dass wir \u00fcberrascht sein werden, John Day zu finden. wie Sie sehen k\u00f6nnen, Kenya Rwanda Worlds enth\u00e4lt mehrere Morphine. die verschiedene Informationen enthalten. Deshalb haben wir in unserem Modell Ist das ein Satz oder ein Dokument f\u00fcr einen morphologischen Analyzer? Das erzeugt dann Morpheme, die Inhalte in jeder der W\u00f6rter. Die Morpheme sind normalerweise der Stamm und Zero oder mehr Affix. Das wird indizieren, ten Aspekt, Subjekt oder Objekt. in Vabs und mehr und mehr zu den Bands. f\u00fcr Subjekte und Objekte. Der morphologische Analyzer produziert auch ein Teil des Sprachtags f\u00fcr jedes der W\u00f6rter. Nach diesem Schritt machen wir Impediments f\u00fcr die Ich bin ein Teil von Speechtags. f\u00fcr die Affix. Und im Das ist die morphologische. Dies sind die Morphology Level Embeddings. Wir f\u00fchren diese Einbettungen dann durch eine Molek\u00fcle. die eine kleine Transformer-Enkodierung, die ist auf jede Welt unabh\u00e4ngig angewendet. Die Ausgaben der sind die Vektoren, die in Kontext stehen. mit der morphologischen Information at any world. Wir haben jetzt eine Komposition durchgef\u00fchrt. phlogical embedding ist mit einer Sprach- und Stamm-Party verbunden. mit anderen, wir haben mit anderen. Konzentriert sie mit einem anderen Stamm, der in der Satzstufe eingebaut wird. dann werden wir einen Beitrag zu der Haupt-Satzung oder Dokumentenkoder. die f\u00fcr die Down-Downgebietung verwendet werden k\u00f6nnen. NLP-Tasks. F\u00fcr eine Morphologie, Wir verwenden einen analyzierenden Analyzer, der ein finites State two level mit der Kundenimplementierung, die das ist. Wir haben die Sprache der Die Morphologie der alten kenianischen W\u00f6rter, einschlie\u00dflich der die nun den demonstrativen und processorischen Pronons. Wir verwenden un\u00fcberwachte Pakete. Das ist ein Sprach-Tagging-Algorithmus. ist f\u00fcr die Morphologie-Probabilit\u00e4t verwendet. physikalisch, die Wahrscheinlichkeit, die durch die morphologische Analyse angegeben wird. Wir werden auch zur Betrachtung der Part of Speech nehmen. die Pr\u00e4sidentschaft, wie auch die synthetischen Vereinbarungen, die in den Eingaben. Der Part of Speech Tagger verwendet eine bidirektionale Einer der wichtigsten Infektionen, die sich auf die Ich habe oft Viterbi-Algorithmen f\u00fcr die Entschl\u00fcsselung verwendet. Ein paar Bemerkungen hier f\u00fcr Positionalschl\u00fcsselung. Erstens: Der Morphologie-Enkoder verwendet keine Positioning and encoding, das ist, weil jeder der Morpheme die ist es nicht in der morphologischen Form, dann f\u00fcr positionale Informationen. Die Information ist inh\u00e4rent, wenn die Morpheme gegeben werden. Zweitens verwendet der Satzencoder die und so auch nicht. wurde in der Vergangenheit in der I Clear Conference ver\u00f6ffentlicht. Diese Position Impeditions sind in der Regel disengaging positional correlations. von Token zu Token, Aufmerksamkeit-Computing. \u00c4hnlich wie bei Bird verwenden wir eine maskierte Sprachmodelle. vorbereitenden Objekt. Im Wesentlichen m\u00fcssen wir die Stemme und die Affizien, die mit den Worten verbunden sind. W\u00e4hrend des Pretraining sind 15 % der Sch\u00fcler von allen Worten werden f\u00fcr eine Vorhersage betrachtet, von denen 80 Prozent Das ist ein Problem. f\u00fcr Affix-Predikationen. Wir werden malte classification problem for this. Wir weiten die Gruppe zusammen in eine bestimmte Anzahl von und vorhersagen, dass das Set als Class Label Die andere Option ist, die Affix-Wahrscheinlichkeit zu vorhersagen. Wir evaluieren beide dieser Ans\u00e4tze in unserer Erfahrung. Ich habe mich nicht gefreut, dass ich so ein paar Minuten mit dem Mann gesprochen habe. Prinz von Kenia beret auf etwa zwei und eine H\u00e4lfte Gigabyte von Kenia. Text und komperiert zu drei Baseline Models. Einer ist ein multilingue Modell, Code Excel M R. Das ist ein Trend auf einem gro\u00dfen Textkorporation. Das ist eine Menge von mehreren Sprachen. Die anderen Bels Lines sind auf demselben Kenia Rwanda Texte verwendet. oder die Algorithmen codieren oder morphologische Analysen verwenden. mit der Verwendung der zwei Tire Transformator Encoder. Alle Modelle sind in der Konstruktion konfiguriert. In der Bese Architektur, die zwischen hundert und mit der hundert und zehn Millionen Parameter mit Kenya Rwanda mit Kenya. mit der geringsten Anzahl von Parametern. Models, die den Multi-Lingual-Modell f\u00fcr drei Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei-Drei. mit der Grades of Two Thousand Five Hundred. Ich habe 200 Sequenzen in jeder Satz. Wir bewerten die Pretraining-Modelle auf drei T-Shirts. Set of Taks, eine ist die Gruppebankmark, die es nicht gab. f\u00fcr die Erweiterung der Effektivit\u00e4t der Pretriebe-Sprachmodelle verwendet. Wir haben unsere Gruppenspiegel erreicht. durch die \u00dcbertragung der Originalbenchmark-Daten in Kenya. Ich bin der zweite, der nicht so viel wie ein Das ist Kenya Rwanda Name Identification Benchmark. die eine hohe Qualit\u00e4tsdaten-Satz ist, die durch Train angezeigt wird. Die dritte ist eine neue Sprache. Kategorienbildung task. We will pull News Artikel. von mehreren Websites und die Kategoriisierung der Kategorien. Das wird von den Autoren unterschrieben und dann wird es nat\u00fcrlich versucht, zu vorbereiten. die gleichen Kategorien. Und jetzt gehen wir zu den Ergebnissen. F\u00fcr den Gluebenchmark finden wir, dass Kenia Beria die konsequent outperforms Baseline-Modelle. Hier die durchschnittliche Leistung f\u00fcr zehn Wir werden auch eine User-Evolution der Transaktionen der produziert werden. Ich kann es nicht transkribieren. \u00fcber sechstausend Beispiele, assigning Scores. auf einer Skala von einem bis vier, die die Qualit\u00e4t der Transmission der Das Ergebnis ist, dass viele \u00dcbersetzungen Ich bin nicht so sicher, ob ich das noch mal sagen kann. Aber alle Modelle m\u00fcssen mit demselben Translationsger\u00e4usch und der gleichen Relative Performance zwischen den Modellen ist immer noch wichtig zu bemerken. F\u00fcr die Namenserkennungs- und Zahnverzeichnungsaufgaben Ich finde auch, dass die Kniebein die beste Leistung mit der die Besten. Die Ergebnisse sind auch durchschnittlich zehn Funtuning-Rans. F\u00fcr die Kategoriisierung der Nachrichten find find results, vorherige Work-Classification f\u00fcr Kenia Rwanda. dass die einfache KW-Erkennung meistens genug ist, Das ist ein sehr spezieller Test. von der Verwendung von vorbereiteten Sprachmodellen auf dieser Seite. Das ist eine besondere Task of News Classification. Wir haben auch eine Ablationsstudie durchgef\u00fchrt, um zu sehen, die alternative Strukturen, die die Leistung verbessern, f\u00fcr den Wir finden, dass wir mit einer Konsistenz von Affix-Sets arbeiten. die Forms besser, weil wir wahrscheinlich eine Ver\u00f6ffentlichung Die Best Performance von Named Identity Recognition. Oder auch, indem man die verlorenen Kurven betrachtet. f\u00fcr die F\u00fcllung finden, werden wir finden, dass die Knybet hat bessere Konvergenz. In den meisten F\u00e4llen, so zu dem Schluss, Das hat die Effektivit\u00e4t von Explicit gezeigt. mit der Verwendung morphologischer Informationen in der Preten Language Model. Die vorgeschlagene zwei-Tier-Transformator-Enkoder-Architektur. Er kann morphologisch erfassen. Kapping morphologische Kompositionalit\u00e4t, die eine wichtige von morphologisch reichen Sprachen. Diese Funde sollte weiterer Forschung in Morphologie f\u00f6rdern. Pre-Tend Language Models.", "delays": [4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 44000.0, 44000.0, 44000.0, 44000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 104000.0, 104000.0, 104000.0, 104000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 132000.0, 132000.0, 132000.0, 132000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 144000.0, 144000.0, 144000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 168000.0, 168000.0, 168000.0, 168000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 200000.0, 200000.0, 200000.0, 200000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 224000.0, 224000.0, 224000.0, 224000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 272000.0, 272000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 280000.0, 280000.0, 280000.0, 280000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 304000.0, 304000.0, 304000.0, 304000.0, 308000.0, 308000.0, 308000.0, 308000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 328000.0, 328000.0, 328000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 368000.0, 368000.0, 368000.0, 368000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 404000.0, 404000.0, 404000.0, 404000.0, 408000.0, 408000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 604000.0, 604000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 676000.0, 676000.0, 676000.0, 680000.0, 680000.0, 680000.0, 680000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 695019.6875, 695019.6875, 695019.6875], "elapsed": [4583.259582519531, 4583.259582519531, 4583.259582519531, 4583.259582519531, 4583.259582519531, 4583.259582519531, 4583.259582519531, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 9183.479309082031, 13840.959548950195, 13840.959548950195, 13840.959548950195, 13840.959548950195, 13840.959548950195, 13840.959548950195, 13840.959548950195, 13840.959548950195, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 18478.505849838257, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 23117.649793624878, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 27755.16128540039, 32356.688499450684, 32356.688499450684, 32356.688499450684, 32356.688499450684, 32356.688499450684, 32356.688499450684, 36891.979694366455, 36891.979694366455, 36891.979694366455, 36891.979694366455, 36891.979694366455, 36891.979694366455, 36891.979694366455, 36891.979694366455, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 41539.09635543823, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 46149.8064994812, 50645.00665664673, 50645.00665664673, 50645.00665664673, 50645.00665664673, 55281.819343566895, 55281.819343566895, 55281.819343566895, 55281.819343566895, 55281.819343566895, 55281.819343566895, 55281.819343566895, 55281.819343566895, 60015.99216461182, 60015.99216461182, 60015.99216461182, 60015.99216461182, 60015.99216461182, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 64709.65647697449, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 69365.8640384674, 73868.74508857727, 73868.74508857727, 73868.74508857727, 73868.74508857727, 73868.74508857727, 73868.74508857727, 78522.78780937195, 78522.78780937195, 78522.78780937195, 78522.78780937195, 78522.78780937195, 78522.78780937195, 78522.78780937195, 78522.78780937195, 83156.9037437439, 83156.9037437439, 83156.9037437439, 83156.9037437439, 83156.9037437439, 83156.9037437439, 83156.9037437439, 83156.9037437439, 87737.70451545715, 87737.70451545715, 87737.70451545715, 87737.70451545715, 87737.70451545715, 87737.70451545715, 87737.70451545715, 92338.15264701843, 92338.15264701843, 92338.15264701843, 92338.15264701843, 92338.15264701843, 92338.15264701843, 96880.53703308105, 96880.53703308105, 96880.53703308105, 96880.53703308105, 96880.53703308105, 96880.53703308105, 96880.53703308105, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 101575.528383255, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 106234.08651351929, 110909.45291519165, 110909.45291519165, 110909.45291519165, 110909.45291519165, 110909.45291519165, 110909.45291519165, 110909.45291519165, 110909.45291519165, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 115677.29902267456, 120253.62300872803, 120253.62300872803, 120253.62300872803, 120253.62300872803, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 124911.16118431091, 129547.80602455139, 129547.80602455139, 129547.80602455139, 129547.80602455139, 129547.80602455139, 129547.80602455139, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 134203.33766937256, 138706.26425743103, 138706.26425743103, 138706.26425743103, 138706.26425743103, 138706.26425743103, 143267.32420921326, 143267.32420921326, 143267.32420921326, 143267.32420921326, 143267.32420921326, 143267.32420921326, 143267.32420921326, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 147981.3961982727, 152519.84024047852, 152519.84024047852, 152519.84024047852, 152519.84024047852, 157119.45629119873, 157119.45629119873, 157119.45629119873, 157119.45629119873, 157119.45629119873, 157119.45629119873, 157119.45629119873, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 161774.71089363098, 166220.73125839233, 166220.73125839233, 166220.73125839233, 170762.4945640564, 170762.4945640564, 170762.4945640564, 170762.4945640564, 170762.4945640564, 170762.4945640564, 170762.4945640564, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 175340.15011787415, 179994.18878555298, 179994.18878555298, 179994.18878555298, 179994.18878555298, 179994.18878555298, 179994.18878555298, 179994.18878555298, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 184652.00972557068, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 189308.69603157043, 193768.0003643036, 193768.0003643036, 193768.0003643036, 193768.0003643036, 198248.13675880432, 198248.13675880432, 198248.13675880432, 198248.13675880432, 198248.13675880432, 198248.13675880432, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 202936.95187568665, 207509.9482536316, 207509.9482536316, 207509.9482536316, 207509.9482536316, 207509.9482536316, 207509.9482536316, 212127.75087356567, 212127.75087356567, 212127.75087356567, 212127.75087356567, 212127.75087356567, 212127.75087356567, 212127.75087356567, 212127.75087356567, 216687.35337257385, 216687.35337257385, 216687.35337257385, 216687.35337257385, 216687.35337257385, 216687.35337257385, 216687.35337257385, 221343.7056541443, 221343.7056541443, 221343.7056541443, 221343.7056541443, 221343.7056541443, 221343.7056541443, 221343.7056541443, 221343.7056541443, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 225942.76404380798, 230460.57224273682, 230460.57224273682, 230460.57224273682, 230460.57224273682, 234999.037027359, 234999.037027359, 234999.037027359, 234999.037027359, 234999.037027359, 239616.86444282532, 239616.86444282532, 239616.86444282532, 239616.86444282532, 239616.86444282532, 239616.86444282532, 239616.86444282532, 239616.86444282532, 244177.56628990173, 244177.56628990173, 244177.56628990173, 244177.56628990173, 244177.56628990173, 244177.56628990173, 244177.56628990173, 244177.56628990173, 248717.8716659546, 248717.8716659546, 248717.8716659546, 248717.8716659546, 248717.8716659546, 248717.8716659546, 253222.71823883057, 253222.71823883057, 253222.71823883057, 253222.71823883057, 253222.71823883057, 257740.89860916138, 257740.89860916138, 257740.89860916138, 257740.89860916138, 262318.8245296478, 262318.8245296478, 262318.8245296478, 262318.8245296478, 262318.8245296478, 262318.8245296478, 266953.43375205994, 266953.43375205994, 266953.43375205994, 266953.43375205994, 266953.43375205994, 266953.43375205994, 266953.43375205994, 266953.43375205994, 271528.3887386322, 271528.3887386322, 271528.3887386322, 271528.3887386322, 271528.3887386322, 276048.12026023865, 276048.12026023865, 276048.12026023865, 276048.12026023865, 276048.12026023865, 276048.12026023865, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 280700.6413936615, 285279.81519699097, 285279.81519699097, 285279.81519699097, 285279.81519699097, 285279.81519699097, 285279.81519699097, 285279.81519699097, 289796.66900634766, 289796.66900634766, 289796.66900634766, 289796.66900634766, 289796.66900634766, 289796.66900634766, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 294523.30493927, 299039.9146080017, 299039.9146080017, 299039.9146080017, 299039.9146080017, 299039.9146080017, 299039.9146080017, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 303822.8108882904, 308416.44620895386, 308416.44620895386, 308416.44620895386, 308416.44620895386, 308416.44620895386, 308416.44620895386, 308416.44620895386, 308416.44620895386, 312894.79303359985, 312894.79303359985, 317550.76265335083, 317550.76265335083, 317550.76265335083, 317550.76265335083, 317550.76265335083, 317550.76265335083, 317550.76265335083, 322169.7528362274, 322169.7528362274, 322169.7528362274, 322169.7528362274, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 326881.1490535736, 331458.61554145813, 331458.61554145813, 331458.61554145813, 331458.61554145813, 331458.61554145813, 331458.61554145813, 335919.13509368896, 335919.13509368896, 335919.13509368896, 335919.13509368896, 335919.13509368896, 340592.9489135742, 340592.9489135742, 340592.9489135742, 340592.9489135742, 340592.9489135742, 340592.9489135742, 340592.9489135742, 340592.9489135742, 345210.55269241333, 345210.55269241333, 345210.55269241333, 345210.55269241333, 345210.55269241333, 345210.55269241333, 345210.55269241333, 349750.9710788727, 349750.9710788727, 349750.9710788727, 349750.9710788727, 354404.8283100128, 354404.8283100128, 354404.8283100128, 354404.8283100128, 359016.16883277893, 359016.16883277893, 359016.16883277893, 359016.16883277893, 359016.16883277893, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 363781.2342643738, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 368418.81561279297, 373090.1470184326, 373090.1470184326, 373090.1470184326, 373090.1470184326, 373090.1470184326, 373090.1470184326, 373090.1470184326, 373090.1470184326, 377552.4740219116, 377552.4740219116, 377552.4740219116, 382168.59102249146, 382168.59102249146, 382168.59102249146, 382168.59102249146, 382168.59102249146, 382168.59102249146, 382168.59102249146, 382168.59102249146, 386760.5073451996, 386760.5073451996, 386760.5073451996, 386760.5073451996, 386760.5073451996, 386760.5073451996, 386760.5073451996, 386760.5073451996, 391465.0728702545, 391465.0728702545, 391465.0728702545, 391465.0728702545, 391465.0728702545, 391465.0728702545, 391465.0728702545, 391465.0728702545, 396073.69017601013, 396073.69017601013, 396073.69017601013, 396073.69017601013, 396073.69017601013, 396073.69017601013, 400682.8758716583, 400682.8758716583, 400682.8758716583, 400682.8758716583, 400682.8758716583, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 405377.9299259186, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 410069.9677467346, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 414719.331741333, 419274.5871543884, 419274.5871543884, 419274.5871543884, 419274.5871543884, 419274.5871543884, 423732.38229751587, 423732.38229751587, 423732.38229751587, 423732.38229751587, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 428348.47497940063, 433006.14309310913, 433006.14309310913, 433006.14309310913, 433006.14309310913, 433006.14309310913, 433006.14309310913, 433006.14309310913, 433006.14309310913, 437624.5119571686, 437624.5119571686, 437624.5119571686, 437624.5119571686, 437624.5119571686, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 442314.5215511322, 446908.91885757446, 446908.91885757446, 446908.91885757446, 446908.91885757446, 446908.91885757446, 446908.91885757446, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 451598.08230400085, 456159.7864627838, 456159.7864627838, 456159.7864627838, 456159.7864627838, 456159.7864627838, 456159.7864627838, 456159.7864627838, 456159.7864627838, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 460832.47351646423, 465294.7177886963, 465294.7177886963, 465294.7177886963, 465294.7177886963, 469831.93492889404, 469831.93492889404, 474415.381193161, 474415.381193161, 474415.381193161, 474415.381193161, 474415.381193161, 474415.381193161, 474415.381193161, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 478992.959022522, 483587.41760253906, 483587.41760253906, 483587.41760253906, 483587.41760253906, 483587.41760253906, 483587.41760253906, 483587.41760253906, 483587.41760253906, 488297.47462272644, 488297.47462272644, 488297.47462272644, 488297.47462272644, 488297.47462272644, 488297.47462272644, 488297.47462272644, 488297.47462272644, 492892.3547267914, 492892.3547267914, 492892.3547267914, 492892.3547267914, 492892.3547267914, 492892.3547267914, 492892.3547267914, 492892.3547267914, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 497663.29288482666, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 502415.0629043579, 507011.35778427124, 507011.35778427124, 507011.35778427124, 507011.35778427124, 507011.35778427124, 507011.35778427124, 507011.35778427124, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 511644.0010070801, 516244.0822124481, 516244.0822124481, 516244.0822124481, 516244.0822124481, 516244.0822124481, 516244.0822124481, 516244.0822124481, 516244.0822124481, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 520818.1517124176, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 525467.6978588104, 530138.950586319, 530138.950586319, 530138.950586319, 530138.950586319, 530138.950586319, 530138.950586319, 530138.950586319, 530138.950586319, 534730.6971549988, 534730.6971549988, 534730.6971549988, 534730.6971549988, 534730.6971549988, 534730.6971549988, 534730.6971549988, 534730.6971549988, 539362.1687889099, 539362.1687889099, 539362.1687889099, 539362.1687889099, 539362.1687889099, 539362.1687889099, 539362.1687889099, 543956.3422203064, 543956.3422203064, 543956.3422203064, 543956.3422203064, 543956.3422203064, 543956.3422203064, 543956.3422203064, 543956.3422203064, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 548632.0326328278, 553192.7282810211, 553192.7282810211, 553192.7282810211, 553192.7282810211, 553192.7282810211, 553192.7282810211, 560863.7623786926, 560863.7623786926, 560863.7623786926, 560863.7623786926, 560863.7623786926, 560863.7623786926, 560863.7623786926, 565464.9078845978, 565464.9078845978, 565464.9078845978, 565464.9078845978, 565464.9078845978, 565464.9078845978, 565464.9078845978, 565464.9078845978, 570046.023607254, 570046.023607254, 570046.023607254, 570046.023607254, 570046.023607254, 570046.023607254, 570046.023607254, 574760.6663703918, 574760.6663703918, 574760.6663703918, 574760.6663703918, 574760.6663703918, 574760.6663703918, 574760.6663703918, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 579494.8456287384, 584287.5487804413, 584287.5487804413, 584287.5487804413, 584287.5487804413, 584287.5487804413, 584287.5487804413, 584287.5487804413, 584287.5487804413, 588844.28358078, 588844.28358078, 588844.28358078, 588844.28358078, 588844.28358078, 593514.7507190704, 593514.7507190704, 593514.7507190704, 593514.7507190704, 593514.7507190704, 593514.7507190704, 593514.7507190704, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 598095.8721637726, 602654.3474197388, 602654.3474197388, 602654.3474197388, 602654.3474197388, 602654.3474197388, 602654.3474197388, 602654.3474197388, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 607365.6704425812, 611884.2251300812, 611884.2251300812, 611884.2251300812, 611884.2251300812, 611884.2251300812, 611884.2251300812, 616484.646320343, 616484.646320343, 616484.646320343, 616484.646320343, 616484.646320343, 616484.646320343, 616484.646320343, 621105.6985855103, 621105.6985855103, 621105.6985855103, 621105.6985855103, 621105.6985855103, 621105.6985855103, 621105.6985855103, 621105.6985855103, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 625880.1908493042, 630364.9854660034, 630364.9854660034, 630364.9854660034, 634907.1524143219, 634907.1524143219, 634907.1524143219, 634907.1524143219, 634907.1524143219, 634907.1524143219, 634907.1524143219, 639562.0920658112, 639562.0920658112, 639562.0920658112, 639562.0920658112, 639562.0920658112, 639562.0920658112, 639562.0920658112, 639562.0920658112, 644199.292421341, 644199.292421341, 644199.292421341, 644199.292421341, 644199.292421341, 648679.8634529114, 648679.8634529114, 648679.8634529114, 648679.8634529114, 648679.8634529114, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 653369.5056438446, 657906.5320491791, 657906.5320491791, 657906.5320491791, 657906.5320491791, 657906.5320491791, 662519.092798233, 662519.092798233, 662519.092798233, 662519.092798233, 662519.092798233, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 667190.1550292969, 671707.5271606445, 671707.5271606445, 671707.5271606445, 671707.5271606445, 671707.5271606445, 671707.5271606445, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 676344.6099758148, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 681059.2024326324, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 685731.9107055664, 690424.6191978455, 690424.6191978455, 690424.6191978455, 690424.6191978455, 690424.6191978455, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 695082.0190906525, 699528.6633968353, 699528.6633968353, 704166.5990352631, 704166.5990352631, 704166.5990352631, 704166.5990352631, 704166.5990352631, 704166.5990352631, 704166.5990352631, 708670.7940101624, 708670.7940101624, 708670.7940101624, 708670.7940101624, 708670.7940101624, 713346.2264537811, 713346.2264537811, 713346.2264537811, 713346.2264537811, 713346.2264537811, 713346.2264537811, 713346.2264537811, 713346.2264537811, 717984.1692447662, 717984.1692447662, 717984.1692447662, 717984.1692447662, 717984.1692447662, 717984.1692447662, 717984.1692447662, 722506.227016449, 722506.227016449, 722506.227016449, 722506.227016449, 722506.227016449, 722506.227016449, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 727156.6996574402, 731731.5249443054, 731731.5249443054, 731731.5249443054, 731731.5249443054, 731731.5249443054, 731731.5249443054, 731731.5249443054, 731731.5249443054, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 736362.7305030823, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 740981.855392456, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 745696.8245506287, 750295.7389354706, 750295.7389354706, 750295.7389354706, 750295.7389354706, 750295.7389354706, 750295.7389354706, 750295.7389354706, 750295.7389354706, 754894.7250843048, 754894.7250843048, 754894.7250843048, 754894.7250843048, 754894.7250843048, 754894.7250843048, 754894.7250843048, 759512.9885673523, 759512.9885673523, 759512.9885673523, 759512.9885673523, 759512.9885673523, 759512.9885673523, 759512.9885673523, 759512.9885673523, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 764323.4572410583, 768910.163640976, 768910.163640976, 768910.163640976, 768910.163640976, 768910.163640976, 768910.163640976, 768910.163640976, 768910.163640976, 773508.9447498322, 773508.9447498322, 773508.9447498322, 773508.9447498322, 773508.9447498322, 773508.9447498322, 773508.9447498322, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 778165.1134490967, 782937.0517730713, 782937.0517730713, 782937.0517730713, 787480.3171157837, 787480.3171157837, 787480.3171157837, 787480.3171157837, 792079.0450572968, 792079.0450572968, 792079.0450572968, 792079.0450572968, 792079.0450572968, 792079.0450572968, 796699.5549201965, 796699.5549201965, 796699.5549201965, 796699.5549201965, 796699.5549201965, 796699.5549201965, 801260.8289718628, 801260.8289718628, 801260.8289718628, 801260.8289718628, 801260.8289718628, 801260.8289718628, 804803.9575481415, 804803.9575481415, 804803.9575481415], "prediction_length": 1323, "reference": "Mein Name ist Antoine. Ich bin Doktorand an der University of Massachusetts Amherst. Ich stelle unser Paper KinyaBERT vor: ein Morphologie-bewusstes Kinyarwanda-Sprachmodell. Heute werde ich \u00fcber den Grund f\u00fcr diese Forschung sprechen. Dann werde ich die KinyaBERT-Modell-Architektur im Detail vorstellen. Ich werde dann \u00fcber unsere experimentellen Ergebnisse sprechen und zum Schluss einige Schlussfolgerungen darstellen. Wir alle wissen, dass die j\u00fcngsten Fortschritte bei der NLP durch die Verwendung von vortrainierten Sprachmodellen wie BERT erm\u00f6glicht wurden. Allerdings gibt es immer noch eine Reihe von Einschr\u00e4nkungen. Aufgrund der komplexen Morphologie, die von den meisten morphologisch reichen Sprachen ausgedr\u00fcckt wird, kann der allgegenw\u00e4rtige byte pair encoding-Tokenisierungsalgorithmus, den ich verwendet habe, nicht die genauen lexikalischen Unterwort-Einheiten extrahieren, d.\u00a0h. die Morpheme, die f\u00fcr eine effektive Repr\u00e4sentation ben\u00f6tigt werden. Hier haben wir zum Beispiel drei Kinyarwanda-W\u00f6rter, die mehrere Morpheme enthalten, aber die BPE-Algorithmen k\u00f6nnen sie nicht extrahieren. Das liegt daran, dass einige morphologische Regeln verschiedene Oberfl\u00e4chenformen erzeugen, die die genauen lexikalischen Informationen verbergen. BPE st\u00fctzt sich aber nur auf die Oberfl\u00e4chenformen und hat so keinen Zugang zu diesem lexikalischen Modell. Die zweite Herausforderung besteht darin, dass, selbst wenn man Zugang zu einem morphologischen Analysator von Oracle h\u00e4tte, w\u00fcrde es nicht ausreichen, das BPE-Token durch Morpheme zu ersetzen, um die morphologische Kompositionalit\u00e4t auszudr\u00fccken. Eine dritte L\u00fccke in der Forschung besteht darin, dass neue vortrainierte Sprachmodelle meist bei ressourcenintensiven Sprachen evaluiert werden. Wir m\u00fcssen ihre Anwendbarkeit auch bei geringen Ressourcen und in verschiedenen Sprachen bewerten. Daher pr\u00e4sentieren wir KinyaBERT. Das ist eine einfache, aber effektive Anpassung der BERT-Architektur, die f\u00fcr den effektiveren Umgang mit morphologisch reichen Sprachen gedacht ist. Wir evaluieren KinyaBERT mit Kinyarwanda, einer ressourcenarmen und morphologisch reichen Sprache, die von mehr als zw\u00f6lf Millionen Menschen in Ost- und Zentralafrika gesprochen wird. Die Eingabe f\u00fcr das Modell ist entweder ein Satz oder ein Dokument. Zum Beispiel haben wir hier den Satz: \u201eJohn twarahamubonye biradutangaza\u201c. Das bedeutet: \u201eWir waren \u00fcberrascht, John dort anzutreffen.\u201c Wie Sie sehen k\u00f6nnen, enthaltenW\u00f6rter im Kinyarwanda mehrere Morpheme, die unterschiedliche Informationen enthalten. Daher \u00fcbergeben wir in unserem Modell diesen Satz oder ein Dokument an einen morphologischen Analysator. Dieser erzeugt dann Morpheme, die in allen W\u00f6rtern enthalten sind. Die Morpheme setzen sich in der Regel aus dem Stamm und null oder mehr Affixen zusammen. Die Affixe k\u00f6nnen Zeitform, Aspekt, Subjekt oder Objekt in den Verben anzeigen und beziehen sich h\u00e4ufiger auf die Substantivklasse der Bantu f\u00fcr Subjekte und Objekte. Der morphologische Analysator erzeugt auch einen Teil eines Sprach-Tags f\u00fcr jedes der W\u00f6rter. Nach diesem Schritt erstellen wir Einbettungen f\u00fcr den Teil der Sprach-Tags. Einbettungen f\u00fcr die Affixe. Einbettungen f\u00fcr den Stamm. Dies sind die Einbettungen auf Morphologie-Ebene. Anschlie\u00dfend durchlaufen diese Einbettungen einen Morphologie-Encoder, der ein kleiner Transformer-Encoder ist, der auf jedes Wort unabh\u00e4ngig angewendet wird. Ausgegeben werden die Vektoren, die mit den morphologischen Informationen bei jedem Wort kontextualisiert werden. Nun f\u00fchren wir eine Komposition durch, bei der die morphologischen Einbettungen, die der Sprache und dem Wortstamm entsprechen, miteinander verkettet werden. Wir verketten sie mit einer weiteren Einbettung des Stammes auf der Ebene des Satzes. Dann erstellen wir eine Eingabe f\u00fcr den Hauptsatz oder den Dokument-Encoder. Die Endausgabe sind kontextualisierte Einbettungen, die f\u00fcr nachgelagerte NLP-Aufgaben verwendet werden k\u00f6nnen. F\u00fcr einen morphologischen Analysator verwenden wir Morphologie-Prinzipien mit endlichen Automaten auf zwei Ebenen und mit einer ma\u00dfgeschneiderten Implementierung, die auf die Sprache Kinyarwanda zugeschnitten ist. Wir modellieren die Morphologie aller W\u00f6rter auf Kinyarwanda, einschlie\u00dflich der Verben, Substantive, Demonstrativ- und Possessivpronomen, Numerale und andere. Wir verwenden einen nicht \u00fcberwachten Teil eines Sprach-Tagging-Algorithmus. Ein faktorisiertes Modell erster Ordnung wird verwendet, um die Morphologie-Wahrscheinlichkeit zu ber\u00fccksichtigen, d.\u00a0h. die Wahrscheinlichkeit, die vom morphologischen Analysator zugewiesen wird. Wir ber\u00fccksichtigen auch den Vorrang der Sprach-Tags sowie die syntaktischen Vereinbarungen, die in den eingegebenen W\u00f6rtern vorhanden sind. Der Teil des Sprach-Taggers verwendet eine bidirektionale Inferenz, die den h\u00e4ufiger verwendeten Viterbi-Algorithmus f\u00fcr die Dekodierung verbessert. Hier noch ein paar Anmerkungen zur Positionskodierung. Erstens verwendet der Morphologie-Encoder keine Positionskodierung. Das liegt daran, dass jedes der Morpheme einen bekannten Platz im morphologischen Modell einnimmt. Daher ist die positionelle Information inh\u00e4rent, wenn die Morpheme gegeben sind. Zweitens verwendet der Satz-Encoder die so genannten ungebundenen, relativ positionellen Einbettungen, die k\u00fcrzlich auf der ICLR-Konferenz ver\u00f6ffentlicht wurden. Diese positionellen Einbettungen entkoppeln im Wesentlichen positionelle Korrelationen von Token hin zu einer Token-Aufmerksamkeitsberechnung. \u00c4hnlich wie BERT verwenden wir ein maskiertes Sprachmodell als Vortrainingsziel. Im Wesentlichen m\u00fcssen wir sowohl den Stamm als auch die Affixe, aus denen die W\u00f6rter bestehen, vorhersagen. W\u00e4hrend des Vortrainings werden f\u00fcnfzehn Prozent aller W\u00f6rter f\u00fcr die Vorhersage ber\u00fccksichtigt, von denen achtzig Prozent maskiert, zehn Prozent mit zuf\u00e4lligen W\u00f6rtern ausgetauscht und zehn Prozent unver\u00e4ndert gelassen werden. F\u00fcr die Vorhersage der Affixe stehen wir vor einem Multi-Label-Klassifikationsproblem. Daher fassen wir entweder die Affixe zu einer festen Reihe von Gruppen zusammen und sagen die Gruppe als Klassenlabel voraus. Die andere M\u00f6glichkeit ist die Vorhersage der Affixe durch einen Wahrscheinlichkeitsvektor. Wir bewerten beide Ans\u00e4tze in unseren Experimenten. Wir trainieren KinyaBERT mit etwa zweieinhalb Gigabyte an Text in Kinyarwanda vor und vergleichen es mit drei Modellen der Baseline. Eines davon ist ein mehrsprachiges Modell namens XLM-R, das mit gro\u00dfen Textkorpora trainiert wird, die aus mehreren Sprachen bestehen. Die beiden anderen Baselines werden mit demselben Text auf Kinyarwanda vortrainiert, wobei entweder der byte pair encoding-Algorithmus oder die morphologische Analyse ohne die zweistufige Transformer-Encoder-Architektur verwendet wird. Alle Modelle sind in der Basisarchitektur konfiguriert, die etwa hundert bis hundertzehn Millionen Parameter umfasst, wobei Kinyarwanda mit KinyaBERT die geringste Anzahl von Parametern verwendet. Alle au\u00dfer dem mehrsprachigen Modell werden f\u00fcr zweiunddrei\u00dfigtausend Gradient-Updates vortrainiert, mit einer Batchgr\u00f6\u00dfe von zweitausendf\u00fcnfhundertsechzig Sequenzen in jedem Batch. Wir bewerten die vortrainierten Modelle anhand von drei Gruppen von Aufgaben. Eine davon ist die GLUE-Benchmark, die h\u00e4ufig zur Bewertung der Effektivit\u00e4t von vortrainierten Sprachmodellen verwendet wird. Wir erhalten unsere GLUE-Benchmark-Daten, indem wir die originalen Benchmark-Daten mit Google Translate ins Kinyarwanda \u00fcbersetzen. Die zweite Aufgabe ist die named entity recognition-Benchmark von Kinyarwanda, ein qualitativ hochwertiger Datensatz, der von trainierten Muttersprachlern annotiert wurde. Bei der dritten Aufgabe handelt es sich um eine Kategorisierung von Nachrichten. Hier rufen wir Nachrichtenartikel von verschiedenen Websites ab und sammeln ihre Kategorisierungstags, die von den Autoren zugewiesen wurden. Im Wesentlichen versuchen wir, die gleichen Kategorien vorherzusagen. Sehen wir uns jetzt die Ergebnisse an. Bei der GLUE-Benchmark haben wir festgestellt, dass KinyaBERT durchweg besser abschneidet als die Baseline-Modelle. Hier zeigen wir die durchschnittliche Leistung von zehn Durchl\u00e4ufen zur Feinabstimmung. Wir f\u00fchren auch eine Benutzerevaluation der \u00dcbersetzungen durch, die von Google Translate erstellt werden. Im Wesentlichen bewerteten die Benutzer etwa sechstausend Beispiele und vergaben Noten auf einer Skala von eins bis vier, um die Qualit\u00e4t der \u00dcbersetzungen zu bewerten. Das Ergebnis war, dass viele \u00dcbersetzungen qualitativ schlecht waren. Aber alle Modelle mussten mit der gleichen schlechten Qualit\u00e4t der \u00dcbersetzung umgehen, und die relative Leistung zwischen den Modellen kann immer noch bedeutend festgestellt werden. Bei der Aufgabe Named Entity Recognition stellten wir au\u00dferdem fest, dass KinyaBERT die beste Leistung erbringt, wobei die Variante mit der Verteilungsregression der Affixe am besten abschneidet. Diese Ergebnisse sind auch Mittelwerte von zehn Durchl\u00e4ufen zur Feinabstimmung. Bei der Aufgabe zur Kategorisierung der Nachrichten bekamen wir gemischte Ergebnisse. Fr\u00fchere Arbeiten zur Textklassifizierung f\u00fcr Kinyarwanda hatten herausgefunden, dass eine einfache Schl\u00fcsselworterkennung meistens ausreicht, um diese spezifische Aufgabe zu l\u00f6sen. Daher ist die Verwendung von vortrainierten Sprachmodellen weniger erfolgsversprechend. Jetzt zu dieser besonderen Aufgabe der Kategorisierung von Nachrichten. Wir haben auch eine Ablationsstudie durchgef\u00fchrt, um zu sehen, ob es alternative Strukturen gibt, die die Leistung verbessern. Bei der GLUE-Benchmark haben wir festgestellt, dass die Verwendung von Affix-S\u00e4tzen durchweg besser abschneidet, w\u00e4hrend das Ziel der Affix-Wahrscheinlichkeitsregression die beste Leistung bei der Named Entity Recognition erbringt. Auch wenn man die niedrigen Werte bei der Feinabstimmung betrachtet, stellt man fest, dass KinyaBERT in den meisten F\u00e4llen eine bessere Konvergenz aufweist. Abschlie\u00dfend l\u00e4sst sich sagen, dass diese Arbeit die Effektivit\u00e4t der expliziten Verwendung von morphologischen Informationen in vortrainierten Sprachmodellen bewiesen hat. Die vorgeschlagene zweistufige Transformer-Encoder-Architektur erm\u00f6glicht die Erfassung von morphologischer Komplexit\u00e4t und morphologischer Kompositionalit\u00e4t, die ein wichtiger Aspekt von morphologisch reichen Sprachen ist. Diese Ergebnisse sollten zu weiteren Forschungen \u00fcber morphologie-bewusste, vortrainierte Sprachmodelle motivieren.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.367.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:35.020 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 695019.6875}
{"index": 2, "prediction": "Hallo, mein Name ist Michal Petruschka und es ist mein Platz. Ich bin sicher, dass ich Ihnen das Papier mit dem Titel Sparsifying Transformers pr\u00e4sentieren werde. Modelle mit trainierbaren Repr\u00e4sentations-Pooling. Ich habe in Zusammenarbeit mit Lukas Portmann und Lukas Ich m\u00f6chte mit den Problemen beginnen. Unsere Methode funktioniert gut f\u00fcr die F\u00e4lle, in denen wir Wir haben lange Inputs betrachtet. Wir haben \u00fcber 2000 Token eingegeben und die Ziele sind k\u00fcrzer. als die bereitgestellten Inputs. Es gibt einige spezifische Anwendungen in NLP. Stell dir vor, da es ein langes Dokument gibt, muss es zusammengefasst und klassifiziert werden. Ich habe die Frage beantwortet, ob es Informationen gibt, Ich habe einige Schl\u00fcsselphrasen. Die Vanilla-Transformer sind ein Thema, das seine Aufmerksamkeit auf sich zieht. die auf dem Quadrat der Eingangsfl\u00e4che h\u00e4ngt. in einem Vanille-Transformer mit vollem Aufmerksamkeit. die Verbindungsf\u00e4higkeit, die Beziehungen von jedem Token zu jedem anderen. Andere Token m\u00fcssen berechnet werden. Die Komplexit\u00e4t der Aufmerksamkeit h\u00e4ngt von der Anzahl der Schichten ab. Sequenzl\u00e4nge N die Repr\u00e4sentationsdimensionalit\u00e4t der Repr\u00e4sentationen. In \u00e4hnlicher Weise schicken die Dekaturer Aufmerksamkeit auf Das einzige Unterschied ist, dass die beiden Seiten so aussehen. Die Unterschiede hier sind, dass die Ziel-Token den Eingaben in diesem Fall, die man auf dem Bild sehen kann. Die blaue Punktzahl ist ein Zeichen f\u00fcr die Qualit\u00e4t der Formel. die Beziehungen, die berechnet werden m\u00fcssen. Wir m\u00fcssen alle Beziehungen innerhalb der Jetzt sehen wir, was hier passiert ist. Wenn wir einen Block-Wise-Encoder haben, der funktioniert, indem wir die Tokens so dass sie nur andere Token in der N\u00e4he sehen k\u00f6nnen. Der Text wird in Changs gelesen, drastisch die Anzahl der Berechnungen auf der Encoder-Seite reduziert. Aber das verbessert nicht die Cross-Attention der Decoder. Aber jeder Eingangs-Token wird dem Dekoder \u00fcbergeben. Diese Methode wird oft als Fusion-Indikator bezeichnet. Die Verbesserung hier kann als Ver\u00e4nderung interpretiert werden. eine der Dependenzen von n zu einer anderen Konstante m die die Blockgr\u00f6\u00dfe repr\u00e4sentiert. Unsere wichtige Beobachtung ist, dass Diese Tokens sind f\u00fcr eine Vielzahl von Produkten irrelevant. und kann fast komplett vernachl\u00e4ssigt werden. Das ist auf der Schieberliste veranschaulicht. Die Inputs sind f\u00fcr die gew\u00fcnschte Art relevant. Das ist ein Problem. Zum Beispiel kann man einen Artikel einmal lesen. die wichtigsten Teile mit einem Highlighter zu markieren. Dann produzieren wir eine Zusammenfassung, basierend auf diesen Teilen, nur aus der mittleren Stufe. Die Kosten f\u00fcr das Highlighting und das Entscheiden, ob die aktuellen Die Herstellung des Submarines ist also kosteng\u00fcnstig und abh\u00e4ngig von der Lage. Das ist nur auf der Repr\u00e4sentation der Token. Wir haben eine neue M\u00f6glichkeit, Tokens zu nutzen. Wir sind der Top-K-Operator und die Kosten sind unerheblich. Die Kosten f\u00fcr die Herstellung einer Kurzzeit-Summary Der Input ist auch viel niedriger als im Vanilla-Modell. Die ganze Input-Wertung wird ber\u00fccksichtigt. wie man wichtige Token ausw\u00e4hlt und Gradienten zur\u00fcckverbreitet. Das ist das Problem, das die Menschen durch die Auswahl ausgesetzt sind. ist es, den trainierbaren Selektionsmechanismus vorzuschlagen. Das erlaubt es, dass Gradienten w\u00e4hrend des Trainings weitergegeben werden. damit das Netzwerk lernen kann, die wichtigsten Token zu w\u00e4hlen. Genau gesagt, da es ein paar Embedded-Systeme gibt, und ihre R\u00f6cke aus einer einfachen, linearen Schicht. Die Aufgabe ist es, die h\u00f6chsten Scores zur\u00fcckzugeben. Die Sequenz ist permutativ und die Paare sind so vorbereitet, Der h\u00f6here Punktzahlvektor wird mit dem niedrigeren Punktzahlvektor genommen. Als n\u00e4chstes werden die Gewichte mit einer Boost-Software berechnet. Nach jedem Turn ist es ein bisschen schwerer, Neue Vektoren und Punkte, die man sich vorstellen kann. Die Parzellen sind eine lineare Kombination aus diesen Parzellen. Wir haben es nicht gew\u00e4hlt zu warten. Kurz gesagt, wir kombinieren sie linear. und performt Softmax \u00fcber der Partitur. Und w\u00e4hrend wir zwei verschiedene Schulen kombinieren, Es kann auch etwas L\u00e4rm erzeugen. aber es erlaubt auch, dass die Gradienten Das ist eine sehr wichtige Funktion, die wir f\u00fcr alle Input-Embannungen nutzen. Wir haben eine trainierbare Top-K. auf die Durchf\u00fchrung eines Turniers wie Soft Selection. Und aus einer anderen Perspektive: Das Repr\u00e4sentations-Polling folgt der Encoder-Schicht. Jede Repr\u00e4sentation wird mit einem Punkt eingestuft, dann nur die mit dem h\u00f6chsten Punktzahl. Die Ergebnisse werden an die n\u00e4chste Schicht weitergegeben. Das kann man in der Standard-Transformer-Architektur ausf\u00fchren. auf dem vollen L\u00e4ngseingang. Es ist jedoch m\u00f6glich, in Bl\u00f6cken von einer festen L\u00e4nge und globaler Gr\u00f6\u00dfe. die beste Repr\u00e4sentation ausw\u00e4hlen. Hier ist ein Beispiel f\u00fcr das Repr\u00e4sentations-Polling, Das beeinflusst direkt die Qualit\u00e4t der Daten. weil es sich um eine geschlossene Aufmerksamkeit handelt, die nicht von der Eingabe-L\u00e4nge Und aber die Konstante \"k\". Das ist ein sehr sch\u00f6nes Bild. Der Standort informiert, wie viele Repr\u00e4sentanten ausgew\u00e4hlt werden. und dann \u00fcbertragen wir sie an den Dekoder. Der k\u00fcrzere Text ist deutlich billiger als die vorherige L\u00f6sung. Die Sequenzl\u00e4nge kann durch eine gro\u00dfe Gr\u00f6\u00dfe verk\u00fcrzt werden. Zum Beispiel haben wir erfolgreich K von C verwendet. oder sogar sechzigmal vier oder sogar vierundsechzigmal ist viel kleiner als der Wert von N in unseren Experimenten. Bitte nicht. dass die positive Wirkung von Blockwise-Enkodierung und Selbstbetrachtung Ich habe es nicht vergessen, dass die Die computational Kosten der Aufmerksamkeit h\u00e4ngen von der Quadratform des Input-Lakes ab. die Eingabe fr\u00fcher zu reduzieren. Der Kodierungsprozess kann die Kosten deutlich senken. F\u00fcr das pyramidische Modell schr\u00e4nken wir die Gr\u00f6\u00dfe der Repr\u00e4sentation auf der Ausgabe jeder gew\u00e4hlten Schicht. die zu einer exponentiellen Reduzierung der Rechnungskosten f\u00fchrt. Wie Sie sehen k\u00f6nnen, die Gesamtrechnung ist so, dass die Die urspr\u00fcngliche Kosten f\u00fcr einen vollst\u00e4ndigen Encoder sind weniger als zwei Mal so hoch. Das ist die Ursache f\u00fcr die vollgro\u00dfe erste Schicht. Wenn man das Pulling fr\u00fcher vorstellt, Das ist also eine Konstante, nicht abh\u00e4ngig. auf die Anzahl der Buchstaben L, aber auf die konstante die durch die Platzierung der Pulling-Layer beeinflusst werden k\u00f6nnen. Unsere Verbesserungen waren ein Benchmark f\u00fcr die Entwicklung des Netzwerks. auf 8000 Token lange Eing\u00e4nge und die Figuren zeigt, dass beim Pooling die beste Skalierbarkeit f\u00fcr das Netzwerk Hier kann man feststellen, dass die Arbeitsschwindigkeit Das Trainieren der Pyramidion aus 24 Schichten kann billiger sein. Dann trainieren wir einen zwei Schichten gro\u00dfen Transformator. Nicht zu erw\u00e4hnen, wie leicht Vanilla-Transformers kann man f\u00fcr so einen langen Input aus dem Ged\u00e4chtnis gehen. Die qualitative Vergleichung Der andere Grund ist, dass wir die Pyramiden aus dem auf der Long Document Summarization Task oder gegeben den K\u00f6rper einer die Aufgabe ist es, Artikel aus Archive oder PubMat zu generieren. Es ist abstrakt. Blockwise, was unsere Baseline ist. Es ist auf dem Niveau der j\u00fcngsten State-of-the-Art-Modelle. Der Pyramidion beh\u00e4lt oder verbessert die Perfektion. die Leistung dieser Wettbewerbsbasis. Gleichzeitig ist unser Modell 80 %. \u00fcber 450 Prozent schneller zu trainieren. schneller bei der Inferenz im Vergleich zu den Blockweiten. Beide Modelle haben viel niedrigere Parameter. und wurden von Grund auf auf die gew\u00e4hlten Aufgaben aus ausgebildet. Vorherige Ans\u00e4tze zur Um eine \u00e4hnliche Leistung zu erzielen, musste man mehr Parallelen verwenden. und die vorbereitete Stiftung, die Stiftung f\u00fcr und weitere Linguistik-Objekte f\u00fcr das Training. dass es ein Ziel ist, \u00e4hnliche Leistungen zu erzielen. Wir laden Sie ein, unsere vollst\u00e4ndige Seite zu lesen. Wir haben ein paar neue Videos, die wir auf Papier und mit unserem GitHub-Code Ich, ich...", "delays": [4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 36000.0, 36000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 52000.0, 52000.0, 52000.0, 52000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 84000.0, 84000.0, 84000.0, 84000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 156000.0, 156000.0, 156000.0, 156000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 180000.0, 180000.0, 180000.0, 180000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348000.0, 348000.0, 348000.0, 348000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 400000.0, 400000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 428000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 496000.0, 496000.0, 496000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 512000.0, 512000.0, 512000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 528000.0, 528000.0, 528000.0, 528000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 552000.0, 552000.0, 552000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 577237.3125, 577237.3125], "elapsed": [4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 4676.420211791992, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 9520.425796508789, 14194.52977180481, 14194.52977180481, 14194.52977180481, 14194.52977180481, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 18755.67650794983, 23273.12731742859, 23273.12731742859, 23273.12731742859, 23273.12731742859, 23273.12731742859, 23273.12731742859, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 27867.2137260437, 32384.706497192383, 32384.706497192383, 32384.706497192383, 32384.706497192383, 32384.706497192383, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 37059.200286865234, 41596.02499008179, 41596.02499008179, 41596.02499008179, 41596.02499008179, 46153.88369560242, 46153.88369560242, 46153.88369560242, 46153.88369560242, 46153.88369560242, 46153.88369560242, 46153.88369560242, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 50995.52583694458, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 55606.61172866821, 60129.9250125885, 60129.9250125885, 60129.9250125885, 60129.9250125885, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 64837.60380744934, 69429.41093444824, 69429.41093444824, 69429.41093444824, 69429.41093444824, 69429.41093444824, 69429.41093444824, 69429.41093444824, 74042.55247116089, 74042.55247116089, 74042.55247116089, 74042.55247116089, 74042.55247116089, 74042.55247116089, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 78692.16394424438, 83208.55927467346, 83208.55927467346, 83208.55927467346, 83208.55927467346, 83208.55927467346, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 87883.99052619934, 92369.08841133118, 92369.08841133118, 97025.88272094727, 97025.88272094727, 97025.88272094727, 97025.88272094727, 101625.1175403595, 101625.1175403595, 101625.1175403595, 101625.1175403595, 101625.1175403595, 101625.1175403595, 101625.1175403595, 101625.1175403595, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 106238.99292945862, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 110908.5545539856, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 115501.01494789124, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 120150.77924728394, 124685.03522872925, 124685.03522872925, 124685.03522872925, 124685.03522872925, 124685.03522872925, 124685.03522872925, 129169.81887817383, 129169.81887817383, 129169.81887817383, 129169.81887817383, 129169.81887817383, 129169.81887817383, 133710.613489151, 133710.613489151, 133710.613489151, 133710.613489151, 133710.613489151, 133710.613489151, 133710.613489151, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 138482.23328590393, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 143098.35147857666, 147636.27791404724, 147636.27791404724, 147636.27791404724, 147636.27791404724, 147636.27791404724, 147636.27791404724, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 152346.497297287, 156998.73757362366, 156998.73757362366, 156998.73757362366, 156998.73757362366, 156998.73757362366, 156998.73757362366, 156998.73757362366, 156998.73757362366, 161635.7138156891, 161635.7138156891, 161635.7138156891, 161635.7138156891, 161635.7138156891, 161635.7138156891, 161635.7138156891, 166233.86931419373, 166233.86931419373, 166233.86931419373, 166233.86931419373, 166233.86931419373, 166233.86931419373, 166233.86931419373, 170834.21850204468, 170834.21850204468, 170834.21850204468, 170834.21850204468, 170834.21850204468, 170834.21850204468, 170834.21850204468, 170834.21850204468, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 175455.66534996033, 180015.74397087097, 180015.74397087097, 180015.74397087097, 180015.74397087097, 184538.1247997284, 184538.1247997284, 184538.1247997284, 184538.1247997284, 184538.1247997284, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 189156.1975479126, 193717.0798778534, 193717.0798778534, 193717.0798778534, 193717.0798778534, 193717.0798778534, 193717.0798778534, 198374.22704696655, 198374.22704696655, 198374.22704696655, 198374.22704696655, 198374.22704696655, 198374.22704696655, 202990.0257587433, 202990.0257587433, 202990.0257587433, 202990.0257587433, 202990.0257587433, 202990.0257587433, 202990.0257587433, 202990.0257587433, 207456.16817474365, 207456.16817474365, 207456.16817474365, 207456.16817474365, 211995.4104423523, 211995.4104423523, 211995.4104423523, 211995.4104423523, 211995.4104423523, 211995.4104423523, 211995.4104423523, 211995.4104423523, 216594.07877922058, 216594.07877922058, 216594.07877922058, 216594.07877922058, 216594.07877922058, 216594.07877922058, 216594.07877922058, 216594.07877922058, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 221402.79030799866, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 226059.7734451294, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 230791.95952415466, 235412.4083518982, 235412.4083518982, 235412.4083518982, 235412.4083518982, 235412.4083518982, 235412.4083518982, 235412.4083518982, 235412.4083518982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 239993.77989768982, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 244688.4253025055, 249286.92197799683, 249286.92197799683, 249286.92197799683, 249286.92197799683, 249286.92197799683, 249286.92197799683, 249286.92197799683, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 253963.8533592224, 258562.7031326294, 258562.7031326294, 258562.7031326294, 258562.7031326294, 258562.7031326294, 263257.4796676636, 263257.4796676636, 263257.4796676636, 263257.4796676636, 263257.4796676636, 263257.4796676636, 263257.4796676636, 263257.4796676636, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 267911.0195636749, 272622.270822525, 272622.270822525, 272622.270822525, 272622.270822525, 272622.270822525, 272622.270822525, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 277337.03684806824, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 281958.4090709686, 286613.8904094696, 286613.8904094696, 286613.8904094696, 286613.8904094696, 286613.8904094696, 286613.8904094696, 286613.8904094696, 286613.8904094696, 291264.16015625, 291264.16015625, 291264.16015625, 291264.16015625, 291264.16015625, 291264.16015625, 291264.16015625, 291264.16015625, 295895.33019065857, 295895.33019065857, 295895.33019065857, 295895.33019065857, 295895.33019065857, 295895.33019065857, 295895.33019065857, 295895.33019065857, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 300602.06961631775, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 305315.59586524963, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 310010.04910469055, 314587.4900817871, 314587.4900817871, 314587.4900817871, 314587.4900817871, 314587.4900817871, 314587.4900817871, 314587.4900817871, 314587.4900817871, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 319244.10581588745, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 323895.6801891327, 328432.27100372314, 328432.27100372314, 328432.27100372314, 328432.27100372314, 328432.27100372314, 328432.27100372314, 328432.27100372314, 333007.50827789307, 333007.50827789307, 333007.50827789307, 333007.50827789307, 333007.50827789307, 333007.50827789307, 337567.25668907166, 337567.25668907166, 337567.25668907166, 337567.25668907166, 337567.25668907166, 337567.25668907166, 342145.0819969177, 342145.0819969177, 342145.0819969177, 342145.0819969177, 342145.0819969177, 342145.0819969177, 342145.0819969177, 346703.5665512085, 346703.5665512085, 346703.5665512085, 346703.5665512085, 346703.5665512085, 346703.5665512085, 351262.1352672577, 351262.1352672577, 351262.1352672577, 351262.1352672577, 351262.1352672577, 351262.1352672577, 351262.1352672577, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 356013.9231681824, 360592.0810699463, 360592.0810699463, 360592.0810699463, 360592.0810699463, 360592.0810699463, 365185.7867240906, 365185.7867240906, 365185.7867240906, 365185.7867240906, 365185.7867240906, 365185.7867240906, 365185.7867240906, 365185.7867240906, 369701.51114463806, 369701.51114463806, 369701.51114463806, 369701.51114463806, 369701.51114463806, 374370.68796157837, 374370.68796157837, 374370.68796157837, 374370.68796157837, 374370.68796157837, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 379193.6068534851, 383812.63852119446, 383812.63852119446, 383812.63852119446, 383812.63852119446, 383812.63852119446, 383812.63852119446, 383812.63852119446, 383812.63852119446, 388487.02454566956, 388487.02454566956, 388487.02454566956, 388487.02454566956, 388487.02454566956, 388487.02454566956, 388487.02454566956, 393136.3914012909, 393136.3914012909, 393136.3914012909, 393136.3914012909, 393136.3914012909, 393136.3914012909, 393136.3914012909, 393136.3914012909, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 397768.837928772, 402323.5373497009, 402323.5373497009, 402323.5373497009, 402323.5373497009, 406959.61928367615, 406959.61928367615, 406959.61928367615, 406959.61928367615, 406959.61928367615, 406959.61928367615, 406959.61928367615, 411501.531124115, 411501.531124115, 411501.531124115, 411501.531124115, 411501.531124115, 411501.531124115, 411501.531124115, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 416253.97658348083, 420776.6423225403, 420776.6423225403, 420776.6423225403, 420776.6423225403, 420776.6423225403, 425295.4523563385, 425295.4523563385, 425295.4523563385, 425295.4523563385, 425295.4523563385, 425295.4523563385, 429967.86522865295, 429967.86522865295, 429967.86522865295, 429967.86522865295, 429967.86522865295, 429967.86522865295, 429967.86522865295, 429967.86522865295, 434542.25397109985, 434542.25397109985, 434542.25397109985, 434542.25397109985, 434542.25397109985, 434542.25397109985, 434542.25397109985, 434542.25397109985, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 439198.9424228668, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 443874.454498291, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 448434.65781211853, 453070.0340270996, 453070.0340270996, 453070.0340270996, 453070.0340270996, 453070.0340270996, 453070.0340270996, 453070.0340270996, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 457684.27777290344, 462106.72068595886, 462106.72068595886, 466776.864528656, 466776.864528656, 466776.864528656, 466776.864528656, 466776.864528656, 466776.864528656, 466776.864528656, 466776.864528656, 471292.9410934448, 471292.9410934448, 471292.9410934448, 471292.9410934448, 471292.9410934448, 471292.9410934448, 471292.9410934448, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 476088.49596977234, 480592.56172180176, 480592.56172180176, 480592.56172180176, 480592.56172180176, 480592.56172180176, 485167.6046848297, 485167.6046848297, 485167.6046848297, 485167.6046848297, 485167.6046848297, 485167.6046848297, 485167.6046848297, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 489858.0365180969, 494433.7282180786, 494433.7282180786, 494433.7282180786, 494433.7282180786, 494433.7282180786, 494433.7282180786, 499109.9925041199, 499109.9925041199, 499109.9925041199, 499109.9925041199, 499109.9925041199, 499109.9925041199, 499109.9925041199, 499109.9925041199, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 503747.2629547119, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 508458.0366611481, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 513091.82810783386, 517652.5881290436, 517652.5881290436, 517652.5881290436, 517652.5881290436, 517652.5881290436, 517652.5881290436, 522226.48096084595, 522226.48096084595, 522226.48096084595, 522226.48096084595, 522226.48096084595, 522226.48096084595, 522226.48096084595, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 526837.5906944275, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 531524.4681835175, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 536180.5472373962, 540776.9064903259, 540776.9064903259, 540776.9064903259, 540776.9064903259, 540776.9064903259, 540776.9064903259, 540776.9064903259, 540776.9064903259, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 545410.902261734, 549987.9062175751, 549987.9062175751, 549987.9062175751, 549987.9062175751, 549987.9062175751, 549987.9062175751, 549987.9062175751, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 554682.6026439667, 559300.3995418549, 559300.3995418549, 559300.3995418549, 559300.3995418549, 559300.3995418549, 559300.3995418549, 559300.3995418549, 559300.3995418549, 563917.5233840942, 563917.5233840942, 563917.5233840942, 563917.5233840942, 563917.5233840942, 563917.5233840942, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 568590.9080505371, 573051.6095161438, 573051.6095161438, 573051.6095161438, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 577664.882183075, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 582281.3584804535, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 586956.6361904144, 591422.1267700195, 591422.1267700195, 591422.1267700195, 595963.0198478699, 595963.0198478699, 595963.0198478699, 595963.0198478699, 595963.0198478699, 600714.5612239838, 600714.5612239838, 600714.5612239838, 600714.5612239838, 600714.5612239838, 600714.5612239838, 600714.5612239838, 600714.5612239838, 605328.855752945, 605328.855752945, 605328.855752945, 605328.855752945, 605328.855752945, 605328.855752945, 605328.855752945, 609828.7434577942, 609828.7434577942, 609828.7434577942, 609828.7434577942, 614328.7301063538, 614328.7301063538, 614328.7301063538, 614328.7301063538, 614328.7301063538, 614328.7301063538, 618870.548248291, 618870.548248291, 618870.548248291, 618870.548248291, 618870.548248291, 618870.548248291, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 623508.040189743, 628087.7237319946, 628087.7237319946, 628087.7237319946, 628087.7237319946, 628087.7237319946, 628087.7237319946, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 632783.563375473, 637267.3223018646, 637267.3223018646, 637267.3223018646, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 641958.1053256989, 646553.4515380859, 646553.4515380859, 646553.4515380859, 646553.4515380859, 646553.4515380859, 646553.4515380859, 646553.4515380859, 651167.7701473236, 651167.7701473236, 651167.7701473236, 651167.7701473236, 651167.7701473236, 651167.7701473236, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 655801.121711731, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 660413.5134220123, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 665140.6962871552, 666810.824338913, 666810.824338913], "prediction_length": 1160, "reference": "Hallo, mein Name ist Micha\u0142 Pietruszka und es ist mir eine Freude, Ihnen das Paper mit dem Titel Sparsifying Transformer Models with Trainable Representation Pooling vorzustellen. Die Arbeit wurde bei Applica KI in Zusammenarbeit mit Lukasz Borchmann und Lukasz Garncarek durchgef\u00fchrt. Lassen Sie mich mit den Problemen beginnen, die in unserer Arbeit abgehandelt werden. Unsere Methode funktioniert gut f\u00fcr die F\u00e4lle, in denen lange Eingaben ber\u00fccksichtigt werden. Grob gesagt ist sie f\u00fcr Aufgaben und Eingaben von \u00fcber zweitausend Token gedacht, wo die Zieltexte k\u00fcrzer als die vorgegebenen Eingaben sind. Dies f\u00fchrt zu einigen spezifischen Anwendungen in der NLP. Man kann sich zum Beispiel vorstellen, dass ein langes Dokument zusammengefasst, klassifiziert und eine Frage dar\u00fcber beantwortet werden muss und Informationen oder einige Schl\u00fcssels\u00e4tze extrahiert werden m\u00fcssen. Erinnern wir uns an den Vanilla-Transformer und sein Problem mit der Aufmerksamkeitskomplexit\u00e4t, die vom Quadrat der Eingabezeile abh\u00e4ngt. Im Vanilla-Transformer m\u00fcssen bei voller Aufmerksamkeitskonnektivit\u00e4t die Relationen jedes Token zu jedem anderen Token berechnet werden. Die rechnerische Komplexit\u00e4t der Aufmerksamkeit h\u00e4ngt von der Reihe der Schichten l, der Sequenzl\u00e4nge n, einer weiteren Sequenzl\u00e4nge und der Dimensionalit\u00e4t der Repr\u00e4sentationen ab. \u00c4hnlich verh\u00e4lt es sich mit der Cross-Attention des Decoders zu diesem Bild auf der rechten Seite, wobei der einzige Unterschied darin besteht, dass die Ziel-Token in diesem Fall auf die Eingabe-Token gerichtet sind. Das sieht man in dieser Formel. Der BLEU-Score stellt Relationen dar, die berechnet werden m\u00fcssen. Im Falle der vollst\u00e4ndigen Aufmerksamkeit m\u00fcssen wir jede Relation innerhalb der Eingabe-Sequenz berechnen. Jetzt sehen wir, was passiert, wenn wir einen blockweisen Encoder haben, der die Konnektivit\u00e4t der Token so einschr\u00e4nkt, dass sie nur andere Token in der N\u00e4he sehen k\u00f6nnen. Der Text wird in Bl\u00f6cken gelesen, was die Reihe der Berechnungen auf der Encoder-Seite drastisch reduzieren kann. Aber die Cross-Attention des Decoders wird so nicht verbessert, da jedes Eingabe-Token ohnehin an den Decoder weitergegeben wird. Diese Methode wird oft als Fusion im Decoder bezeichnet. Die Verbesserung hier kann so interpretiert werden, dass eine der Abh\u00e4ngigkeiten von n durch eine andere Konstante m ersetzt wird, die die Blockgr\u00f6\u00dfe darstellt. Unsere wichtigste Beobachtung ist, dass die meisten Token f\u00fcr eine Vielzahl von Aufgaben irrelevant sind und fast vollst\u00e4ndig vernachl\u00e4ssigt werden k\u00f6nnen. Dies ist beispielhaft auf der Folie dargestellt. Nur ein Teil der Eingaben ist f\u00fcr die gew\u00fcnschte Ausgabe relevant. Zum Beispiel. Man kann einen Artikel einmal lesen, die wichtigsten Teile mit einem Textmarker markieren und dann eine Zusammenfassung erstellen, die nur auf diesem Teil aus der mittleren Phase basiert. Die Kosten f\u00fcr die Hervorhebung und die Entscheidung, ob das aktuelle Token f\u00fcr die Erstellung der Zusammenfassung wesentlich ist, sind somit gering und h\u00e4ngen nur von der Repr\u00e4sentation des Token ab. Das Pooling der hervorgehobenen Token ist m\u00f6glich. Das ist unserem Top-k-Operator zu verdanken und die Kosten sind vernachl\u00e4ssigbar. Die Kosten f\u00fcr die Erstellung einer Zusammenfassung aus einer gek\u00fcrzten Eingabe sind ebenfalls viel niedriger als beim Vanilla-Modell, wenn die gesamte Eingabe ber\u00fccksichtigt wird. Aber hier stellt sich eine Frage. Wie kann man wichtige Token ausw\u00e4hlen und Gradienten zu dieser Auswahl zur\u00fcckverfolgen? Das zugrundeliegende wesentliche Problem, das wir l\u00f6sen, besteht darin, einen trainierbaren Auswahlmechanismus vorzuschlagen. Dieser erm\u00f6glicht es, dass der Gradient w\u00e4hrend des Trainings r\u00fcckverfolgt werden kann, sodass das Netzwerk lernen kann, die wichtigsten Token auszuw\u00e4hlen. Pr\u00e4ziser ausgedr\u00fcckt: Angesichts einiger Unterwert-Einbettungen, die aus einer einfachen linearen Schicht stammen, besteht die Aufgabe darin, die Einbettungen mit dem h\u00f6chsten Score zu ermitteln. Zun\u00e4chst wird die Sequenz permutiert, und es werden Paare gebildet, sodass der h\u00f6her bewertete Vektor mit dem niedriger bewerteten zusammengebracht wird. Anschlie\u00dfend werden die Gewichtungen mithilfe von einer verst\u00e4rkten Softmax \u00fcber die Scores berechnet. Nach jeder Turnierrunde werden neue Vektoren und Scores als lineare Kombination dieser Paare mit den erhaltenen Gewichtungen zusammengestellt. Kurz gesagt kombinieren wir sie linear, indem wir eine Softmax \u00fcber ihre Scores durchf\u00fchren. W\u00e4hrend man zwei Token kombiniert, kann auch schlechte Qualit\u00e4t erzeugt werden. Aber auch die \u00dcbertragung der Gradienten auf alle eingegebenen Einbettungen wird erm\u00f6glicht. Kurz gesagt wollen wir ein trainierbares Top-k vorschlagen, das eine turnier\u00e4hnliche Soft-Selection bei jedem Schritt ausf\u00fchrt. Aus einem anderen Blickwinkel betrachtet, folgt das Repr\u00e4sentationspooling auf die Encoder-Schicht. Zun\u00e4chst wird jede Repr\u00e4sentation bewertet. Dann werden nur jene mit den h\u00f6chsten Scores an die n\u00e4chste Ebene weitergegeben. Die Kodierung kann wie in der Standard-Transformer-Architektur auf die volle L\u00e4nge der Eingabe durchgef\u00fchrt werden. Es ist jedoch m\u00f6glich, Text in Bl\u00f6cken mit fester L\u00e4nge zu verarbeiten und global die beste Repr\u00e4sentation zu w\u00e4hlen. Hier ist ein Beispiel f\u00fcr das nach dem Encoder eingef\u00fchrte Repr\u00e4sentationspooling. Dies hatte einen direkten Einfluss auf die Ursache der Cross-Attention. Diese h\u00e4ngt nicht von der L\u00e4nge der Eingabe N ab, sondern von der Konstante K, welche die gepoolte L\u00e4nge darstellt. Diese Konstante gibt an, wie viele Repr\u00e4sentationen ausgew\u00e4hlt und an den Decoder \u00fcbergeben werden. Die Erstellung einer Zusammenfassung aus einem k\u00fcrzeren Text ist wesentlich billiger als die fr\u00fchere L\u00f6sung. Die Sequenzl\u00e4nge kann um einen gro\u00dfen Faktor verk\u00fcrzt werden. Wir haben beispielsweise in unseren Experimenten k erfolgreich sechzehnmal oder sogar vierundsechzigmal kleiner als den Wert von n verwendet. Bitte beachten Sie, dass die positive Wirkung von blockweiser Kodierung und selbst\u00e4ndiger Aufmerksamkeit anhaltend ist. Vergessen Sie nicht, dass die Rechenkosten der Aufmerksamkeit vom Quadrat der eingegebenen L\u00e4nge abh\u00e4ngen. Die Reduzierung der Eingabe zu einem fr\u00fcheren Zeitpunkt w\u00e4hrend des Kodierungsprozesses kann die Kosten erheblich senken. F\u00fcr das Pyramidion-Modell haben wir die Gr\u00f6\u00dfe der Repr\u00e4sentation bei der Ausgabe jeder ausgew\u00e4hlten Schicht eingegrenzt, was zu einer exponentiellen Verringerung der Rechenkosten f\u00fchrt, wenn die Kodierung fortschreitet. Wie Sie sehen k\u00f6nnen, sind die gesamten Rechenkosten eines vollst\u00e4ndigen Encoders hier weniger als doppelt so hoch als die Kosten der ersten Schicht in voller Gr\u00f6\u00dfe. Wenn das Pooling fr\u00fcher eingef\u00fchrt wird, wird die Summe aller lila Quadrate auf eine Konstante begrenzt, die nicht von der Anzahl der Schichten abh\u00e4ngt. Die Konstante c kann durch die Anordnung der Pooling-Schichten innerhalb des Netzwerks beeinflusst werden. Unsere Verbesserungen wurden mit Eingaben in der L\u00e4nge von achttausend Token verglichen. Die Abbildung zeigt, dass die beste Skalierbarkeit f\u00fcr die Tiefe des Netzwerks erreicht wird, wenn das Pooling aktiviert ist. Hier kann man feststellen, dass bei solchen langen Eingaben das Training des Pyramidions mit 24 Schichten billiger sein kann als das Training eines zweischichtigen Vanilla-Transformers. Ganz zu schweigen davon, wie schnell ein Vanilla-Transformer bei einer so langen Eingabe ungen\u00fcgend Speicher haben kann. Der qualitative Vergleich unseres Trend-Pyramidions mit anderen Baselines wird anhand der langen Aufgabe mit der Zusammenfassung des Dokuments durchgef\u00fchrt. Alternativ kann der Hauptteil eines Artikels von arXiv oder PubMed herangezogen werden, wo die Aufgabe darin besteht, eine Zusammenfassung zu erstellen. Man kann also sehen, dass der blockweise Ansatz, der unsere Baseline darstellt, auf modernsten Modellen basiert, w\u00e4hrend das Pyramidion die Leistung dieser konkurrenzf\u00e4higen Baseline beibeh\u00e4lt oder verbessert. Gleichzeitig ist unser Modell zu achtzig Prozent schneller zu trainieren und zu \u00fcber vierhundertf\u00fcnfzig Prozent schneller bei der Inferenz im Vergleich zur blockweisen Baseline. Beide Modelle haben viel weniger Parameter und wurden von Grund auf f\u00fcr die ausgew\u00e4hlten Aufgaben trainiert. Fr\u00fchere Ans\u00e4tze zur Erzielung einer \u00e4hnlichen Leistung mussten mehr Parameter verwenden sowie vortrainierte grundlegende Modelle und zus\u00e4tzliche Vortrainingsziele bei der Sprache nutzen. Wir laden Sie ein, unser vollst\u00e4ndiges Paper zu lesen und unseren GitHub-Code zu verwenden. Vielen Dank f\u00fcrs Zuschauen.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.590.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 09:37.237 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 577237.3125}
{"index": 3, "prediction": "Hallo, das ist Jawejo von der Harvard University. Ich freue mich sehr, unsere Arbeit im Bereich der Online-Semantizierung f\u00fcr 18 Jahre vorzustellen. Das ist ein Joint Work mit Jason, der sich f\u00fcr die Produktion Michael, Anthony und Sam von Microsoft Cementing Machines. In auf Aufgaben ausgerichtetem Dialog. Ein Benutzer interagiert mit einem System, das Anfragen von anderen Benutzern bearbeitet. die sich in der Regel im Sprechen von der Endung der User-Atsagen Bei der Systemreaktion gibt es oft eine bemerkenswerte Verz\u00f6gerung. Unter der Haube wird der Benutzerwort in den Namen der ein ausf\u00fchrbares Programm, das dann ausgef\u00fchrt wird, Hier ist das Programm so dargestellt, dass es sich um eine als ein semantisches Graph, das die Berechnung skizziert, wo eine Notiz repr\u00e4sentiert eine Funktion, Invokation und seine Kinder sind die Argumente. Die gro\u00dfen Knoten markieren augenblickliche Operationen, aber die anderen sind langsam. dass wir nicht alle die Regeln der Welt umsetzen k\u00f6nnen. Diese Programme k\u00f6nnen oft kompliziertere Graphen sein. Wir haben in diesem Gespr\u00e4ch gefragt, wie man die Strukturen der B\u00e4ume Die Frage ist: K\u00f6nnen wir mit der Erstellung und Ausf\u00fchrung eines Programms beginnen? bevor der Benutzer die Auswechslung beendet. Das kann durch das System erreicht werden. Es gibt viele andere Probleme in diesem Raum. Beispiele hierf\u00fcr sind die gleichzeitige \u00dcbersetzung, bei der ein Live-Interpreter Der Textverfasser \u00fcbersetzt eine Sprache in Echtzeit in eine andere. die Autokompilation, die den Benutzer in den Sinn bringt und \u00fcberw\u00e4ltigt. wo die Fahrer nach dem vorausgesagten Zeitpunkt Alle diese Szenarien haben eine Sache gemeinsam: Das hei\u00dft, es ist vorteilhaft, Entscheidungen zu treffen, bevor man alles sieht. In unserem Fall werden wir mit Online-Spielen Es ist eine sehr schwierige Aufgabe, die sich in der Vergangenheit Wir m\u00fcssen erraten, was der Benutzer sagen k\u00f6nnte. ohne formelle Bewertungsmetrik. Zuerst schauen wir uns an, wie ein normales System funktioniert. Es ist offline, indem es nur bei der Hier wird vorhergesagt, dass der Kriptograph Wir haben es nach anderen Informationen gesehen. Im Gegensatz dazu Ein Online-System, das bei jedem Alternativ-Pr\u00e4fix passt. Zum Beispiel: Jedes Mal, wenn wir einen neuen Token sehen, der neue Graf. Nicht zu sagen, dass es Fehler geben k\u00f6nnte. Auf der Pull Party mit Barack Obama haben wir einen Graf mit den Roten die Person und das Ereignis-Subjekt, aber Das geht weiter, bis wir die Zeit des Ablaufs erhalten. wie w\u00fcrde das wirken, wenn die Anzeige von der Seite der Anzeige nicht mehr eingehalten wird? die Ausf\u00fchrungszeitlinie in dem Offline-System. Wir haben am Ende den Programmdiagramm, damit das System an dieser Stelle mit der Ausf\u00fchrung beginnen kann. Denken Sie daran, dass die gro\u00dfen Knoten schnell funktionieren. Wir k\u00f6nnen nur die Ausf\u00fchrungszeitlinie der farbigen langsamen Funktionen betrachten. Zuerst k\u00f6nnen diese zwei Personenfunktionen Parallel, wei\u00df aus der rosa Schachtel. dass sie keine Abh\u00e4ngigkeit von anderen Funktionen haben. Das No-Create-Event kann dann ausgef\u00fchrt werden, nachdem er Ergebnisse erhalten hat. und dann die Top-Funktion schrie. Das ganze Programm ist fertig, der Ausf\u00fchrungsprozess ist streng. die sich auf die Programmabh\u00e4ngigkeitsstruktur beschr\u00e4nkt, wo manche Operationen nicht parallelisiert werden, was eine bemerkenswerte Verz\u00f6gerung verursacht. In unserem Online-System, wo wir pr\u00e4parieren, Wir k\u00f6nnen vorhersagen, dass die Ausf\u00fchrung des Programms fr\u00fcher beginnen kann. Hier, nach dem Pr\u00e4fix After Obama, werden die Vertrauenswerte vorhergesagt. dass die definierten Personenfunktionen in einem Programm sein sollten, aber die die Fehler enthalten, als sie ausgegraben werden. Der Knoten kann sofort als Schritt gestartet werden. mit mehr Token werden wir einen ganz neuen Graphen vorhersagen. Es wird bereits ausgef\u00fchrt, also m\u00fcssen wir nur den Rest der die wir sicher sind, dass sie uns helfen werden. kann man parallel ausf\u00fchren. Mit mehr Text haben wir mehr F\u00e4higkeiten, wie die Eventszeit hier, wo AM ist auch richtig erwartet. Dann k\u00f6nnen wir den Rest auszuf\u00fchren, nach der Programmabh\u00e4ngigkeitsstruktur. indem die Ausf\u00fchrungszeitlinie mit der \u00c4nderungszeitlinie \u00fcberlappt wird. Wir sparen eine gro\u00dfe Menge Zeit. Also wir schlagen die Aufgabe der Online-Sementi-Parsing vor. Eine zugrunde liegende Annahme ist, dass die Ausf\u00fchrungszeit Wie viel ist die Modellvorhersagezeit? eine andere Annahme ist, dass als Vorhersage und als die Ausf\u00fchrung hat einen Hintergrund, der nicht f\u00fcr Benutzer sichtbar ist. Wir m\u00fcssen eine konsistente Parsing-Historie aufrechterhalten. Wir haben die Teile von Anfang bis Ende von jedem Token. Wir haben einen zweistufigen Ansatz vorgeschlagen, ein vorgeschlagener Schritt, der Sie k\u00f6nnen einen Grafikbild mit einer vollst\u00e4ndigen Struktur und einem ausgew\u00e4hlten Schritt Ich habe einige Notizen gelassen, die es wert sind, in dieser Zeit ausgef\u00fchrt zu werden. Wir haben zwei Varianten der vorgeschlagenen Methode. Der erste Ansatz kombiniert eine Sprachmodellvollendung mit vollen Ausdrucksm\u00f6glichkeiten. In der Regel ist es nicht so, dass die Pr\u00e4fekten nach Obama ist erst durch ein Find-to-Imbark-Sprachmodell abgeschlossen. und dann in ein Programm mit einem vollen Offline-Parser \u00fcbersetzt. Der zweite Ansatz sagt das Programm direkt von YouTube aus voraus. Das wird durch das Tuning eines einzelnen Online-Parser, um das Goldgraph von jedem Pr\u00e4fix zu \u00fcbersetzen. Dies erleichtert dem Modell, die richtige Vorhersage zu lernen. Wie erzeugt man das? Wir haben das Problem durch die Erstellung einer seriellen Version Jeder Knoten oder jede Kante ist durch eine Hier beginnen wir mit der ersten Node. Das unten stehende zeigt die absolute Indexierung der Aktionsgeschichte. Dann haben wir den zweiten Knoten. Als n\u00e4chstes ist die Kante zwischen ihnen. Es enth\u00e4lt den Pointer zum Index der vorherigen Knoten und Hier bedeutet Null, dass man den neuesten Knoten mit dem anderen Knoten verbindet. mit der Note, die durch die Nullthaktion erzeugt wird. Dieser Prozess geht weiter, bis wir Das zugrunde liegende Modell basiert auf einem Transformator, mit einem selbst-Pointer-Mechanismus, \u00e4hnlich wie bei einem vorherigen \u00dcbergangspersonal. Nach der Erzeugung eines vollst\u00e4ndigen Wir haben die Aktions-Level-Wahrscheinlichkeiten, die zu verschiedenen Teilen des Graphen. Wir w\u00e4hlen zuversichtliche Untergraphen. basierend auf der Schwellenheuristik, die sp\u00e4ter ausgef\u00fchrt werden soll. Wir werden die Schwelle variieren, um verschiedene Kompromisse zwischen der Latenzreduktion und die Ausf\u00fchrungsgestehung. F\u00fcr eine formelle Evaluierung der Online-Methoden schlagen wir vor, Hier ist eine Rekapierung, die wir hier vorstellen. wie ein Offline-System die Ausf\u00fchrungszeitlinie beendet. In Online-Systemen \u00fcberschneidet sich die Ausf\u00fchrung mit der Alternativzeit. FLR ist definiert als eine Art, die sich in der Zeit verl\u00e4uft. Die Reduktionszeit im Vergleich zum Offline-System, das am Ende der Wir f\u00fchren Exzessive-Tests durch, die die Menschen in den letzten Jahren durchf\u00fchren. Experimente auf zwei gro\u00dfen, konversationell zementierten Parsing-Datens\u00e4tzen. Wir haben einen Grafik-Parser, wenn wir einen Graph-Parser haben, Offline zu arbeiten, die modernsten Leistungen bei der Parsing zu erreichen. auf beiden Datens\u00e4tzen. Das komplette Modell Das ist ein nicht trivialer Bl\u00fctengewinn im Vergleich zu einer einfachen Basislinie. Ich bin der Meinung, dass es eine Zeit der Nichtvollendung gibt. Jetzt schauen wir uns die Vorhersage-Genauigkeit unserer Pr\u00e4fix-Grafik-Parsen an. Wir testen das Match nach einem Punkt von zwei Posten zwischen die Generation und die Golgrafen in der Validierung von Daten in weitem f\u00fcr jedes Pr\u00e4fix in der L\u00e4nge und den Repr\u00e4sentanten. Jeder dieser Kurven repr\u00e4sentiert ein anderes Modell, das sich von der anderen Kurve unterscheidet. mit der einzigen Differenz in den Trainingsdaten. Wir mischen Pr\u00e4fixdaten in unterschiedlichen L\u00e4ngen. um das Modell zu einem Online-Parser zu \u00fcbertragen. Das Legend-Pr\u00e4fix 80 % Plus bedeutet, dass das Motto wahr ist. mit Pr\u00e4fixdaten mit Pr\u00e4fixl\u00e4ngen gr\u00f6\u00dfer als 80 %. der vollen Unterfl\u00e4che. Die obere linke Ecke ist wie wir sehen k\u00f6nnen, der Offline-Parser in Black Curve ist nicht gut auf den Pr\u00e4fixdaten. Wenn man mehr Pr\u00e4fixe im Training hat, ist die Kurve und lie\u00df sich besser auf der ganzen Perfektl\u00e4nge ausbilden. Die Leistung der vollst\u00e4ndigen Ordnungsparse ist jedoch nicht beeintr\u00e4chtigt. in der oberen rechten Punkt. Wie viel Latenz reduzieren wir? die von der Anzahl der Quelltokens und simulieren unterschiedliche Funktionsausf\u00fchrungen Die Kurven zeigen den Kompromiss zwischen den beiden Spielarten. und die Ausf\u00fchrungsgestehung, gemessen an der Zahl der die Funktionskosten, die nicht korrekt sind. Das wird durch Variation der Eine h\u00f6here Schwelle w\u00e4hlt weniger Funktionen aus, aber er bekommt eine kleinere FLR, w\u00e4hrend die niedrigere FLR Die Schirmleiter w\u00e4hlen und f\u00fchren Programme aggressiver aus. Vergleichen Sie die beiden Ans\u00e4tze, die wir vorschlagen, mit der Baseline, die nichts tut. indem man direkt den Offline-Parser f\u00fcr den Online-Gebrauch anwendet. Die ober-linke Region hat die beste FLR. Wir sehen, dass beide Methoden die Basislinien schlagen. und sie haben \u00e4hnliche Ergebnisse erzielt. w\u00e4hrend die individuelle Funktion ausgef\u00fchrt wird, Es gibt eher mehr Run-Executions und weniger Run-Executions. Der Latenzreduktionsraum. Wenn die Ausf\u00fchrung langsamer ist, gibt es mehr Raum f\u00fcr FLA-Improvement. Unsere beiden Ans\u00e4tze erzielen bessere Leistungen in verschiedenen Wir haben insgesamt 30 Millionen Euro erreicht. zu 63% relativer Latenzreduktion. Je nach Ausf\u00fchrungszeit und zul\u00e4ssigen Kosten. Schlie\u00dflich haben wir eine Zusammenfassung von Durchschnitts-Latenzreduktion in Tokens f\u00fcr jede Art der Funktion. Die erlaubte Ursache sind drei falsche Hinrichtungen. wie wir sehen, sind sie gegen alle auf der Bord. Es gibt auch Funktionen, bei denen wir eine beeindruckende Latenzzeit bei dieser Reduktion, wo der rote Balken viel l\u00e4nger ist, Manager und Empf\u00e4nger. Das sind Low-Level-Funktionen, dass wir nicht viel von anderen abh\u00e4ngig sind. Als Abschluss schlagen wir vor, Online-Seminar-Parsing als neue Aufgabe zu erforschen, mit der rigorosen Latenzreduktionsmethode. Mit einem starken grafischen Zementparser erreichen wir eine relativ hohe eine relativ gute Latenzreduktion, entweder durch eine Pipeline-Ansatz die durch die Vollendung und den vollst\u00e4ndigen Parser oder direkt durch einen gelernten Parser Wir k\u00f6nnen auch nicht alle Pr\u00e4fixe aufgeben. und kann auf andere ausf\u00fchrbare Zementwerke angewendet werden. in verschiedenen Bereichen. Zukunftswerke k\u00f6nnten Smartphones Wir haben eine Methode zur Vorhersage und Ausf\u00fchrung entwickelt. Wir h\u00f6ren zu.", "delays": [4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 72000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 124000.0, 124000.0, 124000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 128000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 172000.0, 172000.0, 172000.0, 172000.0, 172000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 256000.0, 256000.0, 256000.0, 256000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 360000.0, 360000.0, 360000.0, 360000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 428000.0, 428000.0, 428000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 444000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 556000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 612000.0, 612000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 628000.0, 628000.0, 628000.0, 628000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 652000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 692000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 700000.0, 703007.375, 703007.375, 703007.375], "elapsed": [4601.892948150635, 4601.892948150635, 4601.892948150635, 4601.892948150635, 4601.892948150635, 4601.892948150635, 4601.892948150635, 4601.892948150635, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 9431.281805038452, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 14049.038648605347, 18668.522119522095, 18668.522119522095, 18668.522119522095, 18668.522119522095, 18668.522119522095, 18668.522119522095, 18668.522119522095, 18668.522119522095, 23190.19365310669, 23190.19365310669, 23190.19365310669, 23190.19365310669, 23190.19365310669, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 27942.839860916138, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 32662.477493286133, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 37373.46529960632, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 41971.9352722168, 46583.293437957764, 46583.293437957764, 46583.293437957764, 46583.293437957764, 46583.293437957764, 46583.293437957764, 46583.293437957764, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 51192.65675544739, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 55956.76946640015, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 60646.30961418152, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 65398.95987510681, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 70017.99726486206, 74611.05179786682, 74611.05179786682, 74611.05179786682, 74611.05179786682, 74611.05179786682, 74611.05179786682, 74611.05179786682, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 79320.11890411377, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 84048.8109588623, 88622.88689613342, 88622.88689613342, 88622.88689613342, 88622.88689613342, 88622.88689613342, 88622.88689613342, 93147.04966545105, 93147.04966545105, 93147.04966545105, 93147.04966545105, 93147.04966545105, 93147.04966545105, 93147.04966545105, 97686.13505363464, 97686.13505363464, 97686.13505363464, 97686.13505363464, 97686.13505363464, 97686.13505363464, 97686.13505363464, 97686.13505363464, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 102433.8858127594, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 107130.40280342102, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 111878.69453430176, 116455.53040504456, 116455.53040504456, 116455.53040504456, 116455.53040504456, 116455.53040504456, 116455.53040504456, 116455.53040504456, 121016.0870552063, 121016.0870552063, 121016.0870552063, 121016.0870552063, 121016.0870552063, 121016.0870552063, 121016.0870552063, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 125727.81562805176, 130303.18641662598, 130303.18641662598, 130303.18641662598, 130303.18641662598, 130303.18641662598, 130303.18641662598, 130303.18641662598, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 134916.2368774414, 139490.8332824707, 139490.8332824707, 139490.8332824707, 139490.8332824707, 139490.8332824707, 139490.8332824707, 139490.8332824707, 139490.8332824707, 144012.77565956116, 144012.77565956116, 144012.77565956116, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 148669.68393325806, 153211.20476722717, 153211.20476722717, 153211.20476722717, 153211.20476722717, 153211.20476722717, 153211.20476722717, 153211.20476722717, 153211.20476722717, 157827.88586616516, 157827.88586616516, 157827.88586616516, 157827.88586616516, 157827.88586616516, 157827.88586616516, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 162405.4605960846, 167098.83189201355, 167098.83189201355, 167098.83189201355, 167098.83189201355, 167098.83189201355, 167098.83189201355, 167098.83189201355, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 171755.80883026123, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 176393.79954338074, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 181070.62339782715, 185651.3864994049, 185651.3864994049, 185651.3864994049, 185651.3864994049, 185651.3864994049, 185651.3864994049, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 190283.2531929016, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 195126.5459060669, 199739.2590045929, 199739.2590045929, 199739.2590045929, 199739.2590045929, 199739.2590045929, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 204545.76563835144, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 209168.5597896576, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 213902.9505252838, 218465.36946296692, 218465.36946296692, 218465.36946296692, 218465.36946296692, 218465.36946296692, 223061.81621551514, 223061.81621551514, 223061.81621551514, 223061.81621551514, 223061.81621551514, 223061.81621551514, 227639.89543914795, 227639.89543914795, 227639.89543914795, 227639.89543914795, 227639.89543914795, 227639.89543914795, 227639.89543914795, 227639.89543914795, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 232387.681722641, 236968.40953826904, 236968.40953826904, 236968.40953826904, 236968.40953826904, 236968.40953826904, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 241606.91142082214, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 246302.2825717926, 250997.50018119812, 250997.50018119812, 250997.50018119812, 250997.50018119812, 250997.50018119812, 250997.50018119812, 250997.50018119812, 250997.50018119812, 255629.4982433319, 255629.4982433319, 255629.4982433319, 255629.4982433319, 255629.4982433319, 255629.4982433319, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 260319.2331790924, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 265168.14732551575, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 269838.5663032532, 274432.6972961426, 274432.6972961426, 274432.6972961426, 274432.6972961426, 274432.6972961426, 274432.6972961426, 274432.6972961426, 279012.24088668823, 279012.24088668823, 279012.24088668823, 279012.24088668823, 279012.24088668823, 279012.24088668823, 279012.24088668823, 279012.24088668823, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 283668.44487190247, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 288287.8906726837, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 292868.59941482544, 297354.47120666504, 297354.47120666504, 297354.47120666504, 297354.47120666504, 301876.7547607422, 301876.7547607422, 301876.7547607422, 301876.7547607422, 301876.7547607422, 301876.7547607422, 301876.7547607422, 306414.55817222595, 306414.55817222595, 306414.55817222595, 306414.55817222595, 306414.55817222595, 306414.55817222595, 310934.03363227844, 310934.03363227844, 310934.03363227844, 310934.03363227844, 310934.03363227844, 310934.03363227844, 310934.03363227844, 315548.157453537, 315548.157453537, 315548.157453537, 315548.157453537, 315548.157453537, 315548.157453537, 320257.39550590515, 320257.39550590515, 320257.39550590515, 320257.39550590515, 320257.39550590515, 320257.39550590515, 320257.39550590515, 320257.39550590515, 324773.1728553772, 324773.1728553772, 324773.1728553772, 324773.1728553772, 324773.1728553772, 324773.1728553772, 329480.26299476624, 329480.26299476624, 329480.26299476624, 329480.26299476624, 329480.26299476624, 329480.26299476624, 329480.26299476624, 329480.26299476624, 334149.7926712036, 334149.7926712036, 334149.7926712036, 334149.7926712036, 334149.7926712036, 334149.7926712036, 334149.7926712036, 334149.7926712036, 338710.7973098755, 338710.7973098755, 338710.7973098755, 338710.7973098755, 338710.7973098755, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 343325.33168792725, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 348016.14713668823, 352708.5819244385, 352708.5819244385, 352708.5819244385, 352708.5819244385, 352708.5819244385, 352708.5819244385, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 357327.62837409973, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 362063.7454986572, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 366761.4777088165, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 371534.03091430664, 376113.7399673462, 376113.7399673462, 376113.7399673462, 376113.7399673462, 376113.7399673462, 376113.7399673462, 376113.7399673462, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 380905.08008003235, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 385562.12878227234, 390277.8298854828, 390277.8298854828, 390277.8298854828, 390277.8298854828, 390277.8298854828, 390277.8298854828, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 394992.1100139618, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 399610.1348400116, 404129.50587272644, 404129.50587272644, 404129.50587272644, 404129.50587272644, 404129.50587272644, 404129.50587272644, 404129.50587272644, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 408856.82821273804, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 413507.9083442688, 417986.56582832336, 417986.56582832336, 417986.56582832336, 417986.56582832336, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 422585.70170402527, 427146.93570137024, 427146.93570137024, 427146.93570137024, 427146.93570137024, 427146.93570137024, 427146.93570137024, 427146.93570137024, 427146.93570137024, 431688.9600753784, 431688.9600753784, 431688.9600753784, 431688.9600753784, 431688.9600753784, 431688.9600753784, 431688.9600753784, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 436346.1983203888, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 441060.68110466003, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 445680.6275844574, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 450430.9649467468, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 455104.55083847046, 459602.4286746979, 459602.4286746979, 459602.4286746979, 459602.4286746979, 459602.4286746979, 459602.4286746979, 464234.35163497925, 464234.35163497925, 464234.35163497925, 464234.35163497925, 464234.35163497925, 464234.35163497925, 464234.35163497925, 464234.35163497925, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 469058.23278427124, 473561.3212585449, 473561.3212585449, 473561.3212585449, 473561.3212585449, 473561.3212585449, 478236.03534698486, 478236.03534698486, 478236.03534698486, 478236.03534698486, 478236.03534698486, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 482944.8895454407, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 487636.79099082947, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 492409.2130661011, 496952.7564048767, 496952.7564048767, 496952.7564048767, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 501687.5636577606, 506307.5358867645, 506307.5358867645, 506307.5358867645, 506307.5358867645, 506307.5358867645, 506307.5358867645, 506307.5358867645, 506307.5358867645, 510961.88473701477, 510961.88473701477, 510961.88473701477, 510961.88473701477, 510961.88473701477, 510961.88473701477, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 515671.9868183136, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 520385.70499420166, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 525077.9132843018, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 529845.449924469, 534590.9509658813, 534590.9509658813, 534590.9509658813, 534590.9509658813, 534590.9509658813, 534590.9509658813, 534590.9509658813, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 539358.6235046387, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 544054.2087554932, 548615.3390407562, 548615.3390407562, 548615.3390407562, 548615.3390407562, 548615.3390407562, 548615.3390407562, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 553405.8718681335, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 558081.7985534668, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 562949.9199390411, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 567548.2406616211, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 572261.6324424744, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 576916.1875247955, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 581704.1265964508, 586297.6925373077, 586297.6925373077, 586297.6925373077, 586297.6925373077, 586297.6925373077, 586297.6925373077, 586297.6925373077, 590891.7276859283, 590891.7276859283, 590891.7276859283, 590891.7276859283, 590891.7276859283, 590891.7276859283, 595524.2578983307, 595524.2578983307, 595524.2578983307, 595524.2578983307, 595524.2578983307, 595524.2578983307, 595524.2578983307, 595524.2578983307, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 600238.4502887726, 604874.6161460876, 604874.6161460876, 604874.6161460876, 604874.6161460876, 604874.6161460876, 604874.6161460876, 604874.6161460876, 604874.6161460876, 609510.5218887329, 609510.5218887329, 609510.5218887329, 609510.5218887329, 609510.5218887329, 609510.5218887329, 609510.5218887329, 609510.5218887329, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 614183.2675933838, 618725.1968383789, 618725.1968383789, 618725.1968383789, 618725.1968383789, 618725.1968383789, 618725.1968383789, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 623361.7167472839, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 628035.6888771057, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 632725.3725528717, 637223.6497402191, 637223.6497402191, 637223.6497402191, 637223.6497402191, 637223.6497402191, 641721.8005657196, 641721.8005657196, 641721.8005657196, 641721.8005657196, 641721.8005657196, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 646456.7420482635, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 651095.1697826385, 655753.2231807709, 655753.2231807709, 655753.2231807709, 655753.2231807709, 655753.2231807709, 655753.2231807709, 655753.2231807709, 655753.2231807709, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 660411.1294746399, 664993.6425685883, 664993.6425685883, 664993.6425685883, 664993.6425685883, 664993.6425685883, 664993.6425685883, 664993.6425685883, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 669686.906337738, 674301.3694286346, 674301.3694286346, 674301.3694286346, 674301.3694286346, 674301.3694286346, 674301.3694286346, 674301.3694286346, 674301.3694286346, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 679106.4853668213, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 683878.892660141, 688496.6752529144, 688496.6752529144, 688496.6752529144, 688496.6752529144, 688496.6752529144, 688496.6752529144, 688496.6752529144, 693124.8292922974, 693124.8292922974, 693124.8292922974, 693124.8292922974, 693124.8292922974, 693124.8292922974, 693124.8292922974, 693124.8292922974, 697667.2961711884, 697667.2961711884, 697667.2961711884, 697667.2961711884, 697667.2961711884, 697667.2961711884, 702191.4794445038, 702191.4794445038, 702191.4794445038, 702191.4794445038, 702191.4794445038, 702191.4794445038, 706887.5238895416, 706887.5238895416, 706887.5238895416, 706887.5238895416, 706887.5238895416, 706887.5238895416, 706887.5238895416, 706887.5238895416, 711408.0975055695, 711408.0975055695, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 716159.4026088715, 720736.0382080078, 720736.0382080078, 720736.0382080078, 720736.0382080078, 720736.0382080078, 720736.0382080078, 720736.0382080078, 720736.0382080078, 725253.8151741028, 725253.8151741028, 725253.8151741028, 725253.8151741028, 725253.8151741028, 725253.8151741028, 725253.8151741028, 729827.6696205139, 729827.6696205139, 729827.6696205139, 729827.6696205139, 734427.1352291107, 734427.1352291107, 734427.1352291107, 734427.1352291107, 734427.1352291107, 734427.1352291107, 738944.3988800049, 738944.3988800049, 738944.3988800049, 738944.3988800049, 738944.3988800049, 738944.3988800049, 743689.6960735321, 743689.6960735321, 743689.6960735321, 743689.6960735321, 743689.6960735321, 743689.6960735321, 743689.6960735321, 743689.6960735321, 748280.5516719818, 748280.5516719818, 748280.5516719818, 748280.5516719818, 748280.5516719818, 748280.5516719818, 748280.5516719818, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 752872.6172447205, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 757548.8691329956, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 762205.5382728577, 766917.9117679596, 766917.9117679596, 766917.9117679596, 766917.9117679596, 766917.9117679596, 766917.9117679596, 771485.6495857239, 771485.6495857239, 771485.6495857239, 771485.6495857239, 771485.6495857239, 771485.6495857239, 771485.6495857239, 771485.6495857239, 776161.1309051514, 776161.1309051514, 776161.1309051514, 776161.1309051514, 776161.1309051514, 776161.1309051514, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 780932.3461055756, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 785587.010383606, 790301.5565872192, 790301.5565872192, 790301.5565872192, 790301.5565872192, 790301.5565872192, 790301.5565872192, 790301.5565872192, 790301.5565872192, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 795074.1949081421, 799652.6815891266, 799652.6815891266, 799652.6815891266, 799652.6815891266, 799652.6815891266, 799652.6815891266, 799652.6815891266, 804286.3943576813, 804286.3943576813, 804286.3943576813, 804286.3943576813, 804286.3943576813, 804286.3943576813, 804286.3943576813, 804286.3943576813, 808843.343257904, 808843.343257904, 808843.343257904, 808843.343257904, 808843.343257904, 808843.343257904, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 813456.4428329468, 816894.2546825409, 816894.2546825409, 816894.2546825409], "prediction_length": 1531, "reference": "Hallo, ich bin Jiawei Zhou von der Harvard University. Ich freue mich sehr, unsere Arbeit zum semantischenOnline-Parsing f\u00fcr die Latenzreduktion bei einem aufgabenorientierten Dialog vorstellen zu k\u00f6nnen. Dies ist eine gemeinsame Arbeit mit Jason, Michael, Anthony und Sam von Microsoft Semantic Machines. Beim aufgabenorientierten Dialog interagiert ein Benutzer mit dem System, das Anfragen von Benutzer\u00e4u\u00dferungen, in der Regel in gesprochener Form, bearbeitet. Vom Ende der Benutzer\u00e4u\u00dferung bis zur Antwort des Systems gibt es oft eine sp\u00fcrbare Verz\u00f6gerung. Im Detail wird die Benutzer\u00e4u\u00dferung in ein ausf\u00fchrbares Programm \u00fcbersetzt. Dieses wird dann ausgef\u00fchrt, damit das System richtig reagieren kann. Denn das Programm wird als semantischer Graph dargestellt, der die Berechnung skizziert, wobei ein Knoten einen Funktionsaufruf darstellt und seine Kindknoten die Argumente sind. Die gro\u00dfen Knoten markieren sofortige Operationen, aber die anderen sind langsam in der Ausf\u00fchrung. Das einfache Beispiel hier zeigt, dass diese Programme oft kompliziertere Graphen sein k\u00f6nnen als die Baumstrukturen. In diesem Vortrag stellen wir die Frage, ob wir mit der Generierung des Programms und seiner Ausf\u00fchrung beginnen k\u00f6nnen, bevor der Benutzer \u00fcberhaupt die \u00c4u\u00dferung beendet hat, sodass das System schneller reagieren kann. Dies ist das Problem der Online-Vorhersage und Entscheidung. Es gibt viele andere in diesem REALM. Beispiele sind Simultan\u00fcbersetzungen, bei denen ein Dolmetscher live eine Sprache in eine andere in Echtzeit \u00fcbersetzt; die intelligente automatische Vervollst\u00e4ndigung von Text, um die Absicht des Benutzers zu erraten; und der Uber Pool, wo Fahrer dorthin geschickt werden, wo sie basierend auf der prognostizierten Nachfrage m\u00f6glicherweise ben\u00f6tigt werden. All diese Szenarien haben eines gemeinsam. Es ist vorteilhaft, Entscheidungen zu treffen, bevor man alle Eingaben sieht. In unserem Fall werden wir uns mit dem semantischen Online-Parsing befassen, was eine Herausforderung sein k\u00f6nnte, da wir erraten m\u00fcssen, was der Benutzer sagen k\u00f6nnte. Dieses Gebiet ist auch wenig erforscht und hat keine formale Evaluationsmetrik. Schauen wir uns zun\u00e4chst an, wie ein gew\u00f6hnliches System funktioniert. Dieses funktioniert offline durch Parsing zum Programm erst am Ende der Benutzer\u00e4u\u00dferung. Hier wird das Zeichen Graph vorhergesagt, nachdem alle Information gesehen wurden. Im Gegensatz dazu schlagen wir ein Online-System vor, das bei jedem \u00c4u\u00dferung das Pr\u00e4fix vergleicht. Jedes Mal, wenn wir beispielsweise ein neues Token sehen, prognostizieren wir einen neuen Graphen. Beachten Sie, dass Fehler auftreten k\u00f6nnen. Bei der Position von der Poolparty mit Barack Obama haben wir einen Graphen mit den richtigen Knoten \u00fcber die Person und das Thema des Ereignisses, aber wahrscheinlich die falschen Informationen zu den Zeiten. Dieser Prozess geht weiter, bis wir die vollst\u00e4ndige Benutzer\u00e4u\u00dferung erhalten. Wie w\u00fcrde sich dies auf die Ausf\u00fchrungszeiten im Offline-System auswirken? Am Ende erhalten wir den Programm-Graphen, damit das System an dieser Stelle mit der Ausf\u00fchrung beginnen kann. Vergessen Sie nicht, dass die gro\u00dfen Knoten schnelle Operationen sind. Daher betrachten wir nur die Ausf\u00fchrungszeiten der farbigen langsamen Funktionen. Erstens k\u00f6nnen diese beiden Personensuchfunktionen parallel ausgef\u00fchrt werden, da sie keine Abh\u00e4ngigkeit von anderen Funktionen haben. Sie sind wei\u00df hinterlegt im rosa K\u00e4stchen. Als N\u00e4chstes kann der Knoten \u201eEreignis erstellen\u201c ausgef\u00fchrt werden, nachdem er Ergebnisse von Knoten bekommen hat. Mit der Top-Ertragsfunktion wird das gesamte Programm beendet. Der Ausf\u00fchrungsprozess ist streng und beschr\u00e4nkt sich auf die Abh\u00e4ngigkeitsstruktur des Programms, bei der einige Operationen nicht parallelisiert werden k\u00f6nnen. Das f\u00fchrt zu einer sp\u00fcrbaren Verz\u00f6gerung. In unserem Online-System, wo wir im Laufe der Zeit vorhersagen, kann die Programmausf\u00fchrung fr\u00fcher beginnen. Hier, beim Pr\u00e4fix nach Obama, sagen wir zuversichtlich voraus, dass die Funktion \u201ePerson finden\u201c im Programm sein muss, aber dass der Rest Fehler enthalten kann, da sie ausgegraut sind. Die Ausf\u00fchrung des Knotens kann sofort als Schritt gestartet werden. Dann, mit mehr Token, prognostizieren wir einen v\u00f6llig neuen Graphen, aber ein Teil davon wird bereits ausgef\u00fchrt. Wir m\u00fcssen also nur den Rest der Knoten betrachten, bei denen wir uns auch sicher sind. Hier kann wieder \u201eFinde Person\u201c parallel ausgef\u00fchrt werden. Auch hier k\u00f6nnten wir falsche Vorhersagen haben. Mit mehr Text steigt die Chance, dass wir richtig liegen. Zum Beispiel bei der Zeit des Ereignisses, bei der AM auch richtig vorhergesehen wird. Dann k\u00f6nnen wir mit der Ausf\u00fchrung des Rests beginnen, indem wir der Abh\u00e4ngigkeitsstruktur des Programms folgen. Indem wir die Ausf\u00fchrungszeiten mit den Zeiten der \u00c4u\u00dferungen \u00fcberlappen, sparen wir viel Zeit ein. Also haben wir die Aufgabe mit dem semantischen Online-Parsing vorgeschlagen. Eine zugrunde liegende Annahme ist, dass die Ausf\u00fchrungszeit die Vorhersagezeit des Modells dominiert. Also konnten wir nur Zeit gewinnen, indem wir fr\u00fcher voraussagten. Eine weitere Annahme ist, dass, wenn die Vorhersage und die Ausf\u00fchrung im Hintergrund stattfinden, sie f\u00fcr Benutzer nicht sichtbar sind. Es ist nicht notwendig, eine konsistente Parsing-Historie aufzubewahren. Also parsen wir nach jedem Token von Grund auf neu. Insbesondere wollen wir einen zweistufigen Ansatz vorschlagen. Wir schlagen einen Schritt vor, bei dem ein Graph mit vollst\u00e4ndiger Struktur vorhergesagt wird und einen Schritt, bei dem die Knoten ausgew\u00e4hlt werden, die es zu diesem Zeitpunkt wert sind, ausgef\u00fchrt zu werden. Wir hatten zwei Varianten der vorgeschlagenen Methode. Der erste Ansatz kombiniert eine Sprachmodell-Vervollst\u00e4ndigung mit einer vollst\u00e4ndigen \u00c4u\u00dferung zum Graph-Parsing. Insbesondere wird das Pr\u00e4fix nach Obama zun\u00e4chst durch ein fein abgestimmtes BART-Sprachmodell vervollst\u00e4ndigt und dann in ein Programm mit vollst\u00e4ndigem Offline-Parser \u00fcbersetzt. Der zweite Ansatz sagt das Programm direkt aus den Pr\u00e4fixen der Benutzer\u00e4u\u00dferung voraus. Dies wird durch Training von einem einzigen Online-Parser erreicht, der aus jedem Pr\u00e4fix in den Zielgraphen \u00fcbersetzen soll. Dies erleichtert dem Modell, die richtige Erwartung zu erlernen. Detaillierter gesagt: Wie k\u00f6nnen wir diese Graphen generieren? Wir formulieren das Problem, indem wir eine serielle Version des Graphen generieren. Jeder Knoten oder jede Kante wird durch eine Aktion dargestellt. Hier beginnen wir mit dem ersten Knoten. Die Reihe unten zeichnet den absoluten Index im Aktionsverlauf auf. Dann haben wir den zweiten Knoten. Als N\u00e4chstes kommt die Kante zwischen ihnen. Dort ist der Zeiger auf den Index des fr\u00fcheren Knotens und das Kantenlabel enthalten. Null bedeutet hier, dass der neueste Knoten mit dem Knoten verbunden wird, der durch die Null-Aktion und die Kante des n\u00e4chsten Knotens generiert wurde. Dieser Prozess geht weiter, bis wir den vollst\u00e4ndigen Graph generieren. Das zugrunde liegende Modell basiert auf dem Transformator mit Selbstausrichtungsmechanismus, \u00e4hnlich einem fr\u00fcheren \u00fcbergangsbasierten Parser. Nach Generierung eines vollst\u00e4ndigen Graphen haben wir die Wahrscheinlichkeiten der Aktionsebene erhalten, die verschiedenen Teilen des Graphen entsprechen. Wir w\u00e4hlen Konfidenzteilgraphen auf der Grundlage der auszuf\u00fchrenden Schwellwerte heuristisch aus. Sp\u00e4ter werden wir den Schwellenwert variieren, um unterschiedliche Kompromisse zwischen der Latenzreduzierung und den Ausf\u00fchrungskosten zu erzielen. F\u00fcr die formale Evaluation der Online-Methoden wollen wir eine endg\u00fcltige Latenzreduzierung oder FLR-Metrik vorschlagen. Hier ist eine Zusammenfassung, wie ein Offline-System die Ausf\u00fchrungszeiten beendet. In Online-Systemen \u00fcberschneidet sich die Ausf\u00fchrung mit den Zeiten der \u00c4u\u00dferung. Sie endet also fr\u00fcher. FLR ist als die Reduktionszeit im Vergleich zum Offline-System definiert und durch das Ende der Ausf\u00fchrung markiert. Wir f\u00fchren Experimente an zwei gro\u00dfen Datens\u00e4tzen von Konversationen mit semantischem Parsing durch: SMCalFlow und TreeDST. Unser auf dem Graphen basierte Parser erreicht, wenn er offline betrieben wird, beste Leistungen beim Parsing f\u00fcr beide Datens\u00e4tze. Das LM-Complete-Modell erzielt auch eine nicht triviale BLEU -Verst\u00e4rkung im Vergleich zur einfachen Basislinie der Knotenvervollst\u00e4ndigung. Schauen wir uns nun die Vorhersagegenauigkeit unseres Pr\u00e4fixes f\u00fcr den Graph-Parser an. Wir testen den F1-Score der Graph-Tupel zwischen der Generierung und dem Go-Graph in den Validierungsdaten auf der y-Achse f\u00fcr jede Pr\u00e4fixl\u00e4nge in der x-Achse, dargestellt durch Prozents\u00e4tze. Jede dieser Kurven stellt ein anderes Modell mit dem einzigen Unterschied in den Trainingsdaten dar. Die untere Kurve ist der Offline-Parser. Wir mischen Pr\u00e4fix- Daten in verschiedenen L\u00e4ngen hinein, um das Modell in einen Online-Parser zu \u00fcberf\u00fchren. Zum Beispiel bedeutet das Legendenpr\u00e4fix \u201e80 Prozent plus\u201c, dass das Modell mit Pr\u00e4fix-Daten trainiert wird, wobei die Pr\u00e4fixl\u00e4nge gr\u00f6\u00dfer als 80 Prozent der vollen \u00c4u\u00dferungsl\u00e4nge ist. Die obere linke Ecke ist der gew\u00fcnschte Bereich. Wie wir sehen k\u00f6nnen, funktioniert der Offline-Parser in der schwarzen Kurve der Pr\u00e4fix-Daten nicht gut. Da wir im Training mehr Pr\u00e4fixe mischen, hebt sich die Kurve nach oben und links und schneidet bei allen Pr\u00e4fixl\u00e4ngen besser ab. Die volle Leistung des \u00c4u\u00dferung-Parsings wird jedoch im oberen rechten Punkt nicht beeinflusst. Basierend auf diesen starken Ergebnissen, stellt sich die Frage, wie viel Latenz reduziert wird. Wir messen die Zeit anhand der Reihe von Quelltoken und simulieren verschiedene Funktionsausf\u00fchrungszeiten. Die Kurven zeigen den Kompromiss zwischen der FLR-Metrik und den Ausf\u00fchrungskosten, gemessen an der Reihe \u00fcberm\u00e4\u00dfiger Funktionskosten, die nicht korrekt sind. Dies wird durch Variation der Teilgraphenauswahlschwelle erreicht. Eine h\u00f6here Schwelle w\u00e4hlt weniger Fehlfunktionen aus, erh\u00e4lt aber eine kleinere FLR, w\u00e4hrend die niedrigere Schwelle aggressiver Programme ausw\u00e4hlt und ausf\u00fchrt. Wir vergleichen die beiden Ans\u00e4tze, die wir vorschlagen, mit einer Baseline, die nichts anderes tut, als den Offline-Parser f\u00fcr den Online-Einsatz anzuwenden. Der obere linke Bereich hat den besten FLR und Kostenvorteil. Wir sehen, dass beide unserer Methoden die Baseline um eine gro\u00dfe Differenz \u00fcbertreffen und sie bei TreeDST \u00e4hnlicher abschneiden. W\u00e4hrend die Ausf\u00fchrung einzelner Funktionen schneller ist, gibt es tendenziell mehr Ausf\u00fchrungsvorg\u00e4nge und weniger Raum f\u00fcr die Latenzreduzierung. Wenn die Ausf\u00fchrung einzelner Funktionen langsamer ist, gibt es mehr M\u00f6glichkeiten f\u00fcr FLR-Verbesserungen. Unsere beiden Ans\u00e4tze erreichen eine bessere Leistung in verschiedenen Kostenbereichen. Insgesamt erreichen wir je nach Ausf\u00fchrungszeit und zul\u00e4ssigen Kosten eine Reduzierung der relativen Latenz um 63 bis 60 Prozent. Schlie\u00dflich haben wir eine Aufschl\u00fcsselung der durchschnittlichen Latenzreduktion in Token f\u00fcr jeden Typ des Funktionsknotens, wenn die zul\u00e4ssigen Kosten drei Ausf\u00fchrungsvorg\u00e4nge betragen. Wie wir sehen k\u00f6nnen, gibt es in jedem Bereich positive Ergebnisse. Es gibt auch einige Funktionen, bei denen wir eine beeindruckende Latenzreduzierung erzielen und der rote Balken viel l\u00e4nger ist, wie z.\u00a0B. Find Manager und Empf\u00e4nger. Dies sind Low-Level-Funktionen, die keine gro\u00dfe Abh\u00e4ngigkeit von anderen haben. Abschlie\u00dfend haben wir das semantische Online-Parsing als neue Aufgabe vorgeschlagen, das wir mit der strengen Latenzreduktionsmetrik untersuchen. Mit einem starken graph-basierten, semantischen Parser erreichen wir eine relativ gute Latenzreduktion, entweder durch unseren Pipeline-Ansatz mit LM-Abschluss und einem vollst\u00e4ndigen Parser, oder direkt durch einen gelernten Parser mit Fokus auf die Pr\u00e4fixe. Dar\u00fcber hinaus kann unser Ansatz ein allgemeiner Rahmen sein und auf andere ausf\u00fchrbare semantische Darstellungen in verschiedenen Dom\u00e4nen angewendet werden. Zuk\u00fcnftige Arbeiten k\u00f6nnten eine intelligentere Vorhersage und die Methode der Ausf\u00fchrungsintegration erforschen. Danke f\u00fcrs Zuh\u00f6ren.", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.110.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:43.007 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 703007.375}
{"index": 4, "prediction": "Hallo, ich werde unsere Arbeit \u00fcber die Erzeugung von Retrieval-Augmented-Code diskutieren. Das ist Arbeit, die ich w\u00e4hrend meiner Ich hatte ein Praktikum bei Google Research, wo ich von Matthew Lam und Ian Tenney betreut wurde. Um die Aufgabe zu motivieren, lasst mich mit einer Definition beginnen. In diesem Werk definieren wir ein Konterfaktual als eine Perterbation, Das ist eine sehr wichtige Funktion der Eingabe, die sich in einer bedeutungsvollen, kontrollierten Weise von der Der Originaltext und erlaubt uns, \u00fcber die Ver\u00e4nderungen in der Ausgabe zu reden. Zum Beispiel \u00e4ndert man die Worte faszinierend, um sie zu kaptivieren. Und wenn man erwartet, dass man sich nicht mal einf\u00e4llt, \u00e4ndert sich das Gef\u00fchl. Gleicherma\u00dfen f\u00fcgt man den Qualifikationswomen zu den Eine Frage \u00e4ndert die Antwort auf die Frage im folgenden Beispiel. Die Menschen sind im Vergleich zu einem NLP-Prozess typischerweise robust gegen solche St\u00f6rungen. Warum ist das so? Die Datens\u00e4tze k\u00f6nnen sich in der Tat mit systematischen B\u00fcssen, die zu einer einfachen Entscheidung f\u00fchren. Das ist durch die Gegenwirkung der Diktatur verletzt. Die haben das Problem der Vernichtung. Exemplare zu den Training-Daten k\u00f6nnen das Modell robust machen. Wenn Counterfeit-Regeln wertvoll sind, Wie k\u00f6nnen wir sie generieren? Diese Aufgabe ist besonders schwierig f\u00fcr NLP. Weil hier sind drei Beispiele aus drei verschiedenen NLP-Aufgaben. Wie Sie sehen k\u00f6nnen, gibt es Beispiele, die die Entscheidungsschwelle verletzen. zwischen ausg\u00e4ngen m\u00fcssen sehr sorgf\u00e4ltig von peter pink gefertigt werden Einige Attribute des Textes, die hier unterstrichen sind. Das k\u00f6nnte man durch menschliche Anmerkungen machen. Aber das ist teuer und beides. Ich habe mich auf die Verwendung von Syntax-Tree und semantischen Rollen-Labelung konzentriert. Die Menge der von dieser Technik erzeugten Perturbationen ist durch die Das ist ein fantastisches Framework. Modelle, um Masse des Textes zu f\u00fcllen, um zu \u00e4ndern. Aber es kann eine Herausforderung sein, zu finden, welche Teile des Textes zu st\u00f6ren sind. Es gibt mehr Herausforderungen, um eine Ordnung zu generieren. f\u00fcr die Frage beantworten. Das erfordert Hintergrundwissen. Zum Beispiel, um die urspr\u00fcngliche Frage zu stellen, Wir m\u00fcssen uns \u00fcber die anderen Filme bewusst sein. um zu einer Frage zu kommen wie: Ist Indiana Jones Raider Dar\u00fcber hinaus k\u00f6nnen die St\u00f6rungen durch Zufallsschl\u00e4ge und kann zu Fragen f\u00fchren, die nicht beantwortbar sind mit den verf\u00fcgbaren Beweisen oder Dar\u00fcber hinaus k\u00f6nnen einige Fragenverwirrungen zu signifikanten semantischen Driften von der urspr\u00fcnglichen Eingabe. Diese Frage ist: Praktiziert Indiana Jones Kindersklaverei im Temple of Doom? Wir schlagen eine sehr einfache Wir haben eine effektive Technik namens Retrieve Generate Filter oder RGF. und auch zu bearbeiten. und alle anderen oben genannten Herausforderungen. Die Kernintuition hinter RTF ist, dass die notwendige Hintergrundinformation dass es ben\u00f6tigt wird, um St\u00f6rungen zu erzeugen, die vielleicht in der N\u00e4he von Das ist ein Modell, das von einem Fragesteller erstellt wurde. und produziert die folgenden Top-K-Antworte auf die Frage: Wer ist der Kapit\u00e4n des Richmond der Fu\u00dfballverein. Es erholt das Original. Der Referenzpassage-Anzeige Trent Kotkin als die Top-Most-Choice. Er erh\u00e4lt auch zus\u00e4tzliche Passages und Antworten, die man verwenden kann, um zu f\u00fchren. For instance, es erholt zwei weitere Antworten, die sich entsprechen. Und das ist der Fall mit den Kapit\u00e4nen der Reserve-Team und dem Women's Team des gleichen Clubs. Das kann zu interessanten Edits f\u00fchren. Erst einmal retriebe ich Top-K-Relevant-Ansagen und -Kontakte, die die Referenzantwort und den Kontext zu matchen. Generationsmodell Konditionen auf diese alternativen Antworten zu generieren. Und schlie\u00dflich k\u00f6nnen wir die generierten Fragen filtern. basiert auf Minimalit\u00e4t oder basiert auf der Art der semantischen Perturbation Wir sind interessiert in die Einf\u00fchrung. F\u00fcr das Retrieval verwenden wir ein Retrieve-Modell. Die Texte sind in der urspr\u00fcnglichen Frage und einem gro\u00dfen Korpus wie Wikikurs. Es besteht aus zwei Modulen: dem Retriever-Modul und dem Retriever-Modul. Similarity Search \u00fcber den Index der Passagiere, um den Top-Kampf zu finden. die meisten relevanten Passagen zu der Frage und ein Reader-Modul, als eine potenzielle Antwort. In den meisten F\u00e4llen wird der Goldpassage in diesem Fall jedoch zur\u00fcckgewonnen. Wir sind mehr interessiert in die Antworten und den Kontext, den es weiter in die Linie bringt. In der n\u00e4chsten Frage, die Frage Generation, verwenden wir diese Alternative Antworten und Kontexte, um neue Fragen zu erzeugen, die mit diesen Fragen korrespondieren. Das Modell der Frage-Generation ist ein pr\u00e4-trainiertes Modell. Text-to-text-Transformer, der auf die NQ-Daten ausgerichtet ist, um eine Frage zu erzeugen. f\u00fcr eine Antwort, die in Kontext markiert ist. W\u00e4hrend der Inferenz Die Frage der Generation: Modell der alternativen Antwort und Kontext. Wir haben in der vorherigen Zeit retrieved. Wer ist der Kapit\u00e4n des Richmond Football Clubs? Das ist das Team der Clubs, das von Jess Kennedy angef\u00fchrt wird. Generationsmodell generiert die Query: Who Captain Richmond Football Clubs First? die durch eine Frauenstiel, die eine spezifische somatische St\u00f6rung hat, In \u00e4hnlicher Weise bekommen wir auch Queries wie: Wer ist Kapit\u00e4n Richmond? Das FFL-Reserveteam oder \"Graham Negate\" in der Grand Final Schlie\u00dflich filtern wir eine Teilmenge der erzeugten Kr\u00fcmel aus. Das ist basierend auf einigen gew\u00fcnschten Charakteristiken. Wir w\u00fcrden gerne sicherstellen, dass die neue Frage immer noch semantisch nahe an der Oralfrage steht. f\u00fcr Filtertechniken, die keine zus\u00e4tzlichen Superwoo-Join-Werke erfordern. Wir behalten einfach neue Fragen, die einen kleinen Token haben. Das ist ein Level at a distance von der urspr\u00fcnglichen Frage. Wir entfernen die Frage: Wer hat Graham Negate in der Grand Final letztes Jahr? hat eine l\u00e4ngere Red-Distanz von der urspr\u00fcnglichen Frage. Die Experimente zeigen, dass diese einfachen Heuristiken werden verwendet, um die Ausbildungsdaten zu erweitern und zu bewerten. Wir experimentieren auch mit einer Filterstrategie, die auf der Art von Wir verwenden eine allgemeine Probleml\u00f6sung, um die Probleml\u00f6sung zu l\u00f6sen. Das war das Query-Dekomposition-Framework, QED. Die Frage ist, ob man zwei Teile der Frage identifiziert: ein Pr\u00e4dikat und eine Referenz. Die Verwendungen sind Nomen und Phrasen in der Frage, die zu Entit\u00e4ten im Kontext entsprechen. Ein Predikat ist im Grunde der verbleibende Teil der Frage. Zum Beispiel k\u00f6nnen wir die Query dekomposieren, die Captain Richmonds erste In to two references: Richmond Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Club, Women's Football Clubs Football, Women's Football Clubs Football, Women's Football Clubs Football, Women's Football, Women's Football Clubs Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's Football, Women's, Women's Football, Women's, Women's, Women's, Women's, Women's, Women's, Women's, Women's, Women und das Pr\u00e4dikat: Wer hat X angef\u00fchrt? Das Modell Train on Reference Predicate Annotations f\u00fcr NQ gibt Das ist die Frage der Dekomposition. Dekomposing both the original and generated question based on Q&amp;D erlaubt uns, unsere generierten Konterfaktualen f\u00fcr die Spezifisch bekommen wir zwei Gruppen von Fragen. Und das untergeht einer Referenz\u00e4nderung, w\u00e4hrend sie die Pr\u00e4dikate beibehalten und die untergehaltenen und optionale Referenzen hinzuf\u00fcgen. Wer Kapit\u00e4n Richmonds VFL-Reserveteam ist, ist eine Referenz\u00e4nderung. W\u00e4hrend Wer tr\u00e4gt Nummer 9 f\u00fcr den Club ein Pr\u00e4dikat ist, Change. Wir bewerten jetzt die Wirksamkeit von RGF-Perturbationen. wurden zu Trainingsdaten erweitert. Also, um die Wirksamkeit der Effektivit\u00e4t der Gegenwirkung von Augmentation in besonderem Sinne effektiv zu bewerten. Wir experimentieren mit zwei starken Daten-Augmentations-Basislinien. Das hei\u00dft, dass die Datenlinie \"Random Answer and Question Generation\" Das hei\u00dft, dass Passagen und Antworten einfach Das ist eine random samplte Seite von Wikipedia. mit der zweiten Wellenlinie, die wir in der n\u00e4chsten Woche vorlegen. Gold Answer and Question Generation, speziell die Retrieval-Generation. Hier sind alternative Antworten aus der Die gleiche Passage, die die goldene Antwort enthielt. Wie machen die Baseline- und RGF-Augmentationen? und kann auf Reading Comprehension ausf\u00fchren, wo das Modell Zugang zu Fragen und Antworten hat. Wir experimentieren mit 6 Out-of-Domain-Datens\u00e4tzen und pr\u00e4sentieren Ergebnisse, Wir haben hier: Training Data ist doppelt so wichtig wie die Daten. Wir finden, dass beide in der Augmentation Die Datenvergr\u00f6\u00dferung basiert auf den Basislinien, die nicht in der Lage sind, die Domain zu verallgemeinern. In der Tat, ein Ensemble von sechs Modellen, trainiert auf den Originaldaten. Sieht nach der wettbewerbsf\u00e4higsten Basis aus. Verglichen mit dieser Grundlinie finden wir, dass RGF Counterfacts die k\u00f6nnen ihre Domain-Performance verbessern, w\u00e4hrend sie in der Dom\u00e4ne Das suggeriert, dass wir in der Reasoning Gap Also das Modell mit der Quantifikation ist effektiver als mit der Quantifizierung. Wir haben mehr Daten aus der Training-Distribution. Wir finden, dass wir mit Retrieval alternative Ergebnisse sammeln. ist wichtig f\u00fcr eine effektive CDA. Wir experimentieren auch mit Open-Domain-QA-Einstellungen. Wir bewerten das Modell nur auf 4 Punkten. Wir finden, dass Baseline-Modelle nicht so effektiv sind. f\u00fcr Out-of-Domain-Generalisation. Augmentation mit RGF zeigt mehr signifikante Verbesserungen. Wir verbessern sogar das Indom\u00e4n- und Q-Datensatz. dass die kontrafaktische Data Augmentation die Modelle bei der Erforschung von besseren Query-Enkodierungen f\u00fcr sehr \u00e4hnliche Queries. Schlie\u00dflich bewerten wir auch die Modelle, die wir vorstellen. die F\u00e4higkeit zu verbessern, die Konsistenz in der lokalen Nachbarschaft der urspr\u00fcnglichen Frage zu verbessern. Die Verh\u00e4ltnism\u00e4\u00dfigkeit der Fragen wird durch das Modell korrekt beantwortet. dass beide die urspr\u00fcngliche und die gegenst\u00e4ndliche Frage korrekt beantwortet wurden. Das hilft uns, die Robustheit des Modells zu messen. Kleine St\u00f6rungen in der Nachbarschaft der urspr\u00fcnglichen Eingabe. Wir experimentieren mit 5 Datens\u00e4tzen, die Paare von Fragen enthalten, Abgesehen von den drei Datens\u00e4tzen, die wir hier vorstellen, Ambiquate und CoreF Contrast Set, die sind bereits verf\u00fcgbar. Wir evaluieren auch auf RGF-Counterfactuals, die mit Originalen gepaart sind. Dank f\u00fcr die Fragen, basierend auf der Frage, ob sie eine \u00c4nderung oder Referenz vorgenommen haben. Die Unters\u00e4tze wurden in der Hausordnung annotiert, um L\u00e4rm zu eliminieren. und werden als Ressource zur Verf\u00fcgung gestellt. Alle Basislinien sind nicht in der Lage, die Konsistenz zu verbessern. Das Modell verbessert die Konsistenz mit einem kleinen Margin. Allerdings hat der Argument der gegenfaktualen Augmentierung Die Daten werden in der Regel in der Form von Inkonsistenzen erzeugt, die sich sowohl auf die vorherigen Datens\u00e4tze als auch auf die die f\u00fcr Referenz- und Predikatmotivationen kuratiert wurden. Beachten Sie, dass die Augmented Array von Daten nicht durch St\u00f6rungen verzerrt ist. nur die Evaluierungs-Sets sind. Eine qualitative Inspektion der Arten von Counterfacts wurde generiert. Zeigen Sie an, dass die generierten Fragen mehrere unterschiedliche Fragen enthalten. Das ist die urspr\u00fcngliche Frage auf der Die Bev\u00f6lkerung von Walnut Grove, Minnesota, ist durch verschiedene D\u00e4monen gest\u00f6rt. wie Stadt, Staat, Land und so weiter. Es predikates wie: Standort, Armut, Anzahl der Schulen. RGF Perturbations sind kontextspezifisch. Zum Beispiel f\u00fcr diese andere Frage Das ist der Wimmenden Singles-Turnier. ist ein langes Spiel, ein Turnier oder das Ergebnis des Spiels. Die letzten Takeaways Die Aufgabe der Konterfaktendaten-Augmentation und -Perturbe. f\u00fcr Informationseeking-Queries und Tackles. Wir haben eine neue Generation-Ansatz-Variante, die \u00fcber Generationen hinweg mit Nearsight-Misses des Modells und Filter auf der Basis von Perturbationstypen oder Minimalisierung. Wir finden, dass diese Technik keine zus\u00e4tzliche \u00dcberwachung erfordert. Und die Beispiele sind f\u00fcr Augmentation labelt. Wir finden, dass RG von der Die Faktoffle sind semantisch divers, ohne dass man Buyers w\u00e4hrend der Augmentation einf\u00fchrt. Ich bin sehr froh, dass Sie so eine Vorstellung haben. * Schreie *", "delays": [4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 4000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 8000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 12000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 16000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 20000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 24000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 28000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 32000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 36000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 40000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 44000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 48000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 52000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 56000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 60000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 64000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 68000.0, 72000.0, 72000.0, 72000.0, 72000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 76000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 80000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 84000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 88000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 92000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 96000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 100000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 104000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 108000.0, 112000.0, 112000.0, 112000.0, 112000.0, 112000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 116000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 120000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 124000.0, 128000.0, 128000.0, 128000.0, 128000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 132000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 136000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 140000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 144000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 148000.0, 152000.0, 152000.0, 152000.0, 152000.0, 152000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 156000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 160000.0, 164000.0, 164000.0, 164000.0, 164000.0, 164000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 168000.0, 172000.0, 172000.0, 172000.0, 172000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 176000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 180000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 184000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 188000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 192000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 196000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 200000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 204000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 208000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 212000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 216000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 220000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 224000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 228000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 232000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 236000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 240000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 244000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 248000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 252000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 256000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 260000.0, 264000.0, 264000.0, 264000.0, 264000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 268000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 272000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 276000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 280000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 284000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 288000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 292000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 296000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 300000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 304000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 308000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 312000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 316000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 320000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 324000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 328000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 332000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 336000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 340000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 344000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 348000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 352000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 356000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 360000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 364000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 368000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 372000.0, 376000.0, 376000.0, 376000.0, 376000.0, 376000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 380000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 384000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 388000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 392000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 396000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 400000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 404000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 408000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 412000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 416000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 420000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 424000.0, 428000.0, 428000.0, 428000.0, 428000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 432000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 436000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 440000.0, 444000.0, 444000.0, 444000.0, 444000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 448000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 452000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 456000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 460000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 464000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 468000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 472000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 476000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 480000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 484000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 488000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 492000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 496000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 500000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 504000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 508000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 512000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 516000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 520000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 524000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 528000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 532000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 536000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 540000.0, 544000.0, 544000.0, 544000.0, 544000.0, 544000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 548000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 552000.0, 556000.0, 556000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 560000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 564000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 568000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 572000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 576000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 580000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 584000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 588000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 592000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 596000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 600000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 604000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 608000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 612000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 616000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 620000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 624000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 628000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 632000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 636000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 640000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 644000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 648000.0, 652000.0, 652000.0, 652000.0, 652000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 656000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 660000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 664000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 668000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 672000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 676000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 680000.0, 684000.0, 684000.0, 684000.0, 684000.0, 684000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 688000.0, 692000.0, 692000.0, 692000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 696000.0, 700000.0, 700000.0, 700000.0, 700000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 704000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 708000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 712000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 716000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 720000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 724000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 728000.0, 729013.6875, 729013.6875, 729013.6875], "elapsed": [4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 4882.316589355469, 9404.896974563599, 9404.896974563599, 9404.896974563599, 9404.896974563599, 9404.896974563599, 9404.896974563599, 9404.896974563599, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 14216.21322631836, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 18892.523765563965, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 23606.55426979065, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 28436.444759368896, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 33132.19141960144, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 37845.46613693237, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 42593.60861778259, 47229.14218902588, 47229.14218902588, 47229.14218902588, 47229.14218902588, 47229.14218902588, 47229.14218902588, 47229.14218902588, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 51847.32365608215, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 56695.61409950256, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 61333.75144004822, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 65989.80045318604, 70645.81751823425, 70645.81751823425, 70645.81751823425, 70645.81751823425, 70645.81751823425, 70645.81751823425, 70645.81751823425, 70645.81751823425, 75184.63063240051, 75184.63063240051, 75184.63063240051, 75184.63063240051, 75184.63063240051, 75184.63063240051, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 79855.72409629822, 84430.05061149597, 84430.05061149597, 84430.05061149597, 84430.05061149597, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 89099.524974823, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 93770.24507522583, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 98523.16665649414, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 103234.41457748413, 107904.66833114624, 107904.66833114624, 107904.66833114624, 107904.66833114624, 107904.66833114624, 107904.66833114624, 107904.66833114624, 107904.66833114624, 112465.77787399292, 112465.77787399292, 112465.77787399292, 112465.77787399292, 112465.77787399292, 112465.77787399292, 112465.77787399292, 117007.59220123291, 117007.59220123291, 117007.59220123291, 117007.59220123291, 117007.59220123291, 117007.59220123291, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 121876.05953216553, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 126528.47528457642, 131027.73880958557, 131027.73880958557, 131027.73880958557, 131027.73880958557, 131027.73880958557, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 135723.78730773926, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 140490.88382720947, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 145124.64237213135, 149626.92189216614, 149626.92189216614, 149626.92189216614, 149626.92189216614, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 154358.44564437866, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 158912.49537467957, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 163525.1760482788, 168158.5991382599, 168158.5991382599, 168158.5991382599, 168158.5991382599, 168158.5991382599, 168158.5991382599, 168158.5991382599, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 172910.42184829712, 177452.42881774902, 177452.42881774902, 177452.42881774902, 177452.42881774902, 177452.42881774902, 182110.609292984, 182110.609292984, 182110.609292984, 182110.609292984, 182110.609292984, 182110.609292984, 182110.609292984, 182110.609292984, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 186819.88883018494, 191300.75335502625, 191300.75335502625, 191300.75335502625, 191300.75335502625, 191300.75335502625, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 196010.60485839844, 200495.14865875244, 200495.14865875244, 200495.14865875244, 200495.14865875244, 205016.63374900818, 205016.63374900818, 205016.63374900818, 205016.63374900818, 205016.63374900818, 205016.63374900818, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 209696.75135612488, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 214428.29871177673, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 219064.85176086426, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 223871.75345420837, 228463.4072780609, 228463.4072780609, 228463.4072780609, 228463.4072780609, 228463.4072780609, 228463.4072780609, 233264.64128494263, 233264.64128494263, 233264.64128494263, 233264.64128494263, 233264.64128494263, 233264.64128494263, 233264.64128494263, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 237987.9858493805, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 242681.01406097412, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 247528.89466285706, 252064.8865699768, 252064.8865699768, 252064.8865699768, 252064.8865699768, 252064.8865699768, 252064.8865699768, 256905.86185455322, 256905.86185455322, 256905.86185455322, 256905.86185455322, 256905.86185455322, 256905.86185455322, 256905.86185455322, 256905.86185455322, 261504.71329689026, 261504.71329689026, 261504.71329689026, 261504.71329689026, 261504.71329689026, 261504.71329689026, 261504.71329689026, 266155.4112434387, 266155.4112434387, 266155.4112434387, 266155.4112434387, 266155.4112434387, 266155.4112434387, 266155.4112434387, 266155.4112434387, 270727.40745544434, 270727.40745544434, 270727.40745544434, 270727.40745544434, 270727.40745544434, 270727.40745544434, 270727.40745544434, 270727.40745544434, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 275436.1238479614, 279953.7601470947, 279953.7601470947, 279953.7601470947, 279953.7601470947, 279953.7601470947, 279953.7601470947, 284609.9078655243, 284609.9078655243, 284609.9078655243, 284609.9078655243, 284609.9078655243, 284609.9078655243, 284609.9078655243, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 289341.30597114563, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 294187.9861354828, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 298973.7641811371, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 303646.67415618896, 308131.0889720917, 308131.0889720917, 308131.0889720917, 308131.0889720917, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 312844.2597389221, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 317627.82621383667, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 322222.53465652466, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 327089.57839012146, 331802.9217720032, 331802.9217720032, 331802.9217720032, 331802.9217720032, 331802.9217720032, 331802.9217720032, 331802.9217720032, 331802.9217720032, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 336709.5744609833, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 341403.9731025696, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 346041.09740257263, 350620.2988624573, 350620.2988624573, 350620.2988624573, 350620.2988624573, 350620.2988624573, 350620.2988624573, 350620.2988624573, 355200.72627067566, 355200.72627067566, 355200.72627067566, 355200.72627067566, 355200.72627067566, 355200.72627067566, 355200.72627067566, 355200.72627067566, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 359895.56097984314, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 364590.8246040344, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 369324.2995738983, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 374017.44961738586, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 378748.12507629395, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 383460.62111854553, 388079.19788360596, 388079.19788360596, 388079.19788360596, 388079.19788360596, 388079.19788360596, 388079.19788360596, 388079.19788360596, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 392909.55352783203, 397737.3514175415, 397737.3514175415, 397737.3514175415, 397737.3514175415, 397737.3514175415, 397737.3514175415, 397737.3514175415, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 402376.5106201172, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 406996.01912498474, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 411726.2616157532, 416375.58579444885, 416375.58579444885, 416375.58579444885, 416375.58579444885, 416375.58579444885, 416375.58579444885, 416375.58579444885, 416375.58579444885, 420986.540555954, 420986.540555954, 420986.540555954, 420986.540555954, 420986.540555954, 420986.540555954, 420986.540555954, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 425679.14605140686, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 430351.49812698364, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 435045.6700325012, 439743.08037757874, 439743.08037757874, 439743.08037757874, 439743.08037757874, 439743.08037757874, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 444535.44211387634, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 449362.14232444763, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 454037.9967689514, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 458734.86256599426, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 468031.00657463074, 472726.48763656616, 472726.48763656616, 472726.48763656616, 472726.48763656616, 472726.48763656616, 472726.48763656616, 472726.48763656616, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 477380.6092739105, 481920.62640190125, 481920.62640190125, 481920.62640190125, 481920.62640190125, 481920.62640190125, 481920.62640190125, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 486724.50852394104, 491343.6186313629, 491343.6186313629, 491343.6186313629, 491343.6186313629, 491343.6186313629, 491343.6186313629, 491343.6186313629, 495905.7905673981, 495905.7905673981, 495905.7905673981, 495905.7905673981, 495905.7905673981, 495905.7905673981, 495905.7905673981, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 500795.1400279999, 505356.153011322, 505356.153011322, 505356.153011322, 505356.153011322, 510127.48742103577, 510127.48742103577, 510127.48742103577, 510127.48742103577, 510127.48742103577, 510127.48742103577, 510127.48742103577, 510127.48742103577, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 514965.12842178345, 519640.4404640198, 519640.4404640198, 519640.4404640198, 519640.4404640198, 519640.4404640198, 519640.4404640198, 519640.4404640198, 524163.66386413574, 524163.66386413574, 524163.66386413574, 524163.66386413574, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 529070.8885192871, 533806.0238361359, 533806.0238361359, 533806.0238361359, 533806.0238361359, 533806.0238361359, 533806.0238361359, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 538499.6738433838, 543059.8664283752, 543059.8664283752, 543059.8664283752, 543059.8664283752, 543059.8664283752, 543059.8664283752, 543059.8664283752, 547636.1956596375, 547636.1956596375, 547636.1956596375, 547636.1956596375, 547636.1956596375, 547636.1956596375, 547636.1956596375, 547636.1956596375, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 552307.5714111328, 557017.7474021912, 557017.7474021912, 557017.7474021912, 557017.7474021912, 557017.7474021912, 557017.7474021912, 557017.7474021912, 557017.7474021912, 561512.8755569458, 561512.8755569458, 561512.8755569458, 561512.8755569458, 561512.8755569458, 561512.8755569458, 566142.9378986359, 566142.9378986359, 566142.9378986359, 566142.9378986359, 566142.9378986359, 566142.9378986359, 566142.9378986359, 566142.9378986359, 570794.2955493927, 570794.2955493927, 570794.2955493927, 570794.2955493927, 570794.2955493927, 570794.2955493927, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 575577.4726867676, 580388.0121707916, 580388.0121707916, 580388.0121707916, 580388.0121707916, 580388.0121707916, 580388.0121707916, 580388.0121707916, 580388.0121707916, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 585046.9732284546, 589609.5712184906, 589609.5712184906, 589609.5712184906, 589609.5712184906, 589609.5712184906, 589609.5712184906, 589609.5712184906, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 594554.7752380371, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 599290.3761863708, 603906.7685604095, 603906.7685604095, 603906.7685604095, 603906.7685604095, 603906.7685604095, 603906.7685604095, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 608561.3613128662, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 613219.3117141724, 617834.7840309143, 617834.7840309143, 617834.7840309143, 617834.7840309143, 617834.7840309143, 617834.7840309143, 617834.7840309143, 617834.7840309143, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 622605.8509349823, 627206.9180011749, 627206.9180011749, 627206.9180011749, 627206.9180011749, 627206.9180011749, 627206.9180011749, 627206.9180011749, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 631864.814043045, 636389.4424438477, 636389.4424438477, 636389.4424438477, 636389.4424438477, 636389.4424438477, 636389.4424438477, 641123.6581802368, 641123.6581802368, 641123.6581802368, 641123.6581802368, 641123.6581802368, 645701.840877533, 645701.840877533, 645701.840877533, 645701.840877533, 645701.840877533, 645701.840877533, 645701.840877533, 645701.840877533, 650338.7176990509, 650338.7176990509, 650338.7176990509, 650338.7176990509, 650338.7176990509, 650338.7176990509, 650338.7176990509, 650338.7176990509, 654956.6307067871, 654956.6307067871, 659594.9351787567, 659594.9351787567, 659594.9351787567, 659594.9351787567, 659594.9351787567, 659594.9351787567, 659594.9351787567, 664248.1126785278, 664248.1126785278, 664248.1126785278, 664248.1126785278, 664248.1126785278, 664248.1126785278, 664248.1126785278, 668862.3924255371, 668862.3924255371, 668862.3924255371, 668862.3924255371, 668862.3924255371, 668862.3924255371, 668862.3924255371, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 673631.9124698639, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 678291.6350364685, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 683103.8784980774, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 687781.867980957, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 692477.5130748749, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 697131.1037540436, 701821.0620880127, 701821.0620880127, 701821.0620880127, 701821.0620880127, 701821.0620880127, 701821.0620880127, 701821.0620880127, 701821.0620880127, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 706517.781496048, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 711193.6707496643, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 715866.4391040802, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 720691.4262771606, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 725496.9387054443, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 730287.8725528717, 734829.8659324646, 734829.8659324646, 734829.8659324646, 734829.8659324646, 734829.8659324646, 734829.8659324646, 734829.8659324646, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 739526.5944004059, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 744160.790681839, 748774.4107246399, 748774.4107246399, 748774.4107246399, 748774.4107246399, 748774.4107246399, 748774.4107246399, 748774.4107246399, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 753734.0800762177, 758409.9898338318, 758409.9898338318, 758409.9898338318, 758409.9898338318, 758409.9898338318, 758409.9898338318, 758409.9898338318, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 763221.3170528412, 767802.5071620941, 767802.5071620941, 767802.5071620941, 767802.5071620941, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 772460.3536128998, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 777136.7425918579, 781654.3371677399, 781654.3371677399, 781654.3371677399, 781654.3371677399, 781654.3371677399, 781654.3371677399, 781654.3371677399, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 786384.491443634, 790938.8871192932, 790938.8871192932, 790938.8871192932, 790938.8871192932, 790938.8871192932, 790938.8871192932, 790938.8871192932, 795626.9149780273, 795626.9149780273, 795626.9149780273, 795626.9149780273, 795626.9149780273, 795626.9149780273, 795626.9149780273, 795626.9149780273, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 800354.6621799469, 804934.241771698, 804934.241771698, 804934.241771698, 804934.241771698, 804934.241771698, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 809610.48412323, 814075.7796764374, 814075.7796764374, 814075.7796764374, 818848.0622768402, 818848.0622768402, 818848.0622768402, 818848.0622768402, 818848.0622768402, 818848.0622768402, 823461.9908332825, 823461.9908332825, 823461.9908332825, 823461.9908332825, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 828210.0396156311, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 833116.0399913788, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 837734.828710556, 842334.51628685, 842334.51628685, 842334.51628685, 842334.51628685, 842334.51628685, 842334.51628685, 842334.51628685, 846854.8314571381, 846854.8314571381, 846854.8314571381, 846854.8314571381, 846854.8314571381, 846854.8314571381, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 851682.3110580444, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 856319.5152282715, 857776.4970149994, 857776.4970149994, 857776.4970149994], "prediction_length": 1825, "reference": "Hi. Ich werde nun unsere Arbeit am generierenden Retrieval und den erweiterten Kontrafakten f\u00fcr Aufgaben der Fragenbeantwortung vorstellen. Dies ist die Arbeit, die ich w\u00e4hrend meines Praktikums bei Google Research gemacht habe, wo ich von Matthew Lamm und Ian Tenney betreut wurde. Um die Aufgabe vorzustellen, m\u00f6chte ich damit beginnen, das Wort kontrafaktisch zu definieren. In dieser Arbeit definieren wir kontrafaktisch als eine St\u00f6rung des eingegebenen Textes, der sich in irgendeiner bedeutungsvollen kontrollierten Weise vom urspr\u00fcnglichen Text unterscheidet. Damit k\u00f6nnen wir \u00fcber die \u00c4nderungen des Ergebnisses oder des Labels der Aufgabe schlussfolgern. Wenn man beispielsweise die W\u00f6rter \u201efaszinierend\u201c zu \u201efesselnd\u201c oder \u201eerwartet\u201c zu \u201etodlangweilig\u201c \u00e4ndert, \u00e4ndert das die Stimmung der Filmrezension. Wird die n\u00e4here Bestimmung \u201eDamen\u201c zur Frage hinzugef\u00fcgt, \u00e4ndert sich die Antwort auf die Frage wie im Beispiel unten dargestellt. Menschen sind in der Regel robust gegen\u00fcber solchen St\u00f6rungen im Vergleich zu NLP-Modellen, die f\u00fcr die Aufgabe trainiert wurden. Warum? Der Datensatz kann mit systematischen Bias gesampelt werden. Das f\u00fchrt zu einer einfachen Entscheidungsgrenze, die kontrafaktisch \u00fcbertreten wird. Das zeigt sich in diesem 2D-Klassifizierungsproblem. Mit meiner Arbeit habe ich herausgefunden, dass das Hinzuf\u00fcgen von kontrafaktischen Beispielen zu den Trainingsdaten das Modell robust gegen solche St\u00f6rungen machen kann. Wenn also Kontrafakten wertvoll sind, wie k\u00f6nnen wir sie dann generieren? Diese Aufgabe ist besonders schwierig f\u00fcr NLP, denn hier sind drei Beispiele aus drei verschiedenen NLP-Aufgaben. Wie Sie sehen k\u00f6nnen, m\u00fcssen Beispiele, die die Entscheidungsgrenze zwischen den Ergebnissen verletzen, sehr sorgf\u00e4ltig erstellt werden, indem einige Attribute des Textes, die hier unterstrichen werden, gest\u00f6rt werden. Dies k\u00f6nnte durch menschliche Annotation geschehen, aber dies ist teuer und voreingenommen. Einige fr\u00fchere Arbeiten konzentrierten sich auf die Verwendung von Syntax-B\u00e4umen oder einer semantischen Rollenbezeichnung. Aber die Reihe von St\u00f6rungen, die durch diese Techniken generiert werden, sind durch den semantischen Rahmen begrenzt. Neuere Arbeiten haben maskierte Sprachmodelle verwendet, um maskierte Teile des Textes auszuf\u00fcllen, um Labels zu \u00e4ndern. Aber herauszufinden, welche Teile des Textes zu st\u00f6ren sind, kann eine Herausforderung sein. Es gibt mehr Herausforderungen f\u00fcr die Generierung von Kontrafakten als f\u00fcr die spezifische Beantwortung der Frage. Diese Aufgabe erfordert Hintergrundwissen. Um beispielsweise die urspr\u00fcngliche Frage zu st\u00f6ren: \u201eIst Indiana Jones und der Tempel des Todes ein Prequel?\u201c Wir m\u00fcssen die anderen Filme im Franchise kennen, um die Frage stellen zu k\u00f6nnen: \u201eIst Indiana Jones \u2013 J\u00e4ger des verlorenen Schatzes ein Prequel?\u201c Dar\u00fcber hinaus k\u00f6nnen zuf\u00e4llige St\u00f6rungen zu Fragen f\u00fchren, die mit den verf\u00fcgbaren Beweisen nicht beantwortet werden k\u00f6nnen oder falsche Voraussetzungen haben. Dar\u00fcber hinaus k\u00f6nnen einige Frage-St\u00f6rungen zu einer signifikanten semantischen Abweichung von der urspr\u00fcnglichen Eingabe f\u00fchren. Zum Beispiel ist diese Frage hier: \u201ePraktiziert Indiana Jones Kindersklaverei im Tempel des Todes?\u201c Wir wollen eine sehr einfache, aber effektive Technik mit dem Namen \u201eRetrieve Generate Filter\u201c oder RGF vorschlagen, um kontrafaktische St\u00f6rungen von Fragen in Angriff zu nehmen. Sie zielt auch darauf ab, alle anderen oben genannten Herausforderungen zu bew\u00e4ltigen. Die Kernintuition hinter RGF ist, dass die notwendigen Hintergrundinformationen, die erforderlich sind, um St\u00f6rungen zu genieren, in den Near-Misses vorhanden sein k\u00f6nnen, die von einem Frage-Antwort-Modell erstellt werden. Zum Beispiel liefert das hochmoderne Modell REALM die folgenden Top-k-Antworten auf die Frage, wer der Kapit\u00e4n des Richmond Football Club ist. Es holt die urspr\u00fcngliche Referenzpassage und die Antwort \u201eTrent Cotchin\u201c als erste Wahl ein. Zus\u00e4tzlich werden auch zus\u00e4tzliche Passagen und Antworten abgerufen, die verwendet werden k\u00f6nnen, um St\u00f6rungen der Frage zu steuern. Zum Beispiel holt es zwei weitere Antworten ein, passend zu den Kapit\u00e4nen der Reservemannschaft und der Damenmannschaft des gleichen Vereins. Dies kann zu interessanten \u00c4nderungen f\u00fchren. Zusammenfassend l\u00e4sst sich sagen, dass RGF zuerst die wichtigsten Top-k-Antworten und Kontexte abruft, die nicht mit der Referenz Antwort in Kontext \u00fcbereinstimmen. Im Anschluss an diesen Schritt konditioniert dieses Fragengenerierungsmodell diese alternativen Antworten, um eine ihnen entsprechende Frage zu generieren. Schlie\u00dflich k\u00f6nnen wir die generierten Fragen nach Minimalit\u00e4t oder nach der Art der semantischen St\u00f6rung, die wir einf\u00fchren m\u00f6chten, filtern. Wenn wir beim Retrieval jeden Schritt genauer durchgehen, dann sehen wir, dass wir einen Abruf verwenden. Dann lesen wir ein Modell wie REALM, das als Eingabe die urspr\u00fcngliche Frage und einen gro\u00dfen Korpus wie etwa Wikipedia hernimmt. Es besteht aus zwei Modulen. Das Retrieval-Modul f\u00fchrt eine \u00c4hnlichkeitssuche \u00fcber einen dichten Index von Passagen durch, um die wichtigsten Top-k-Passagen zur Frage abzurufen. Das Lesemodul extrahiert dann aus jeder Passage einen Bereich als potenzielle Antwort. REALM ruft die Goldpassage und in den meisten F\u00e4llen die Antwort ab. In dieser Arbeit sind wir jedoch mehr an den Antworten und am Kontext interessiert, der sp\u00e4ter abgerufen wird. Im n\u00e4chsten Schritt der Fragengenerierung verwenden wir diese alternativen Antworten und Kontexte, um neue Fragen zu generieren, die diesen Alternativen entsprechen. Das Modell der Fragengenerierung ist ein vortrainierter Text-to-Text-Transformer, der auf die NQ-Daten abgestimmt ist, um eine Frage f\u00fcr eine Antwort zu generieren, die f\u00fcr den Kontext markiert ist. W\u00e4hrend der Interferenz liefern wir das Fragengenerierungsmodell, die alternative Antwort und den Kontext, die wir im fr\u00fcheren Schritt abgerufen haben. Zum Beispiel f\u00fcr die Anfrage: \u201eWer ist der Kapit\u00e4n des Richmond Football Clubs?\u201c REALM ruft Passagen \u00fcber die Damenmannschaft des Clubs ab, die von Jess Kennedy angef\u00fchrt wird. Das fragengenerierende Modell generiert die Anfrage: \u201eWer war Kapit\u00e4nin der ersten Damenmannschaft des Richmond Football Clubs?\u201c Hier gibt es eine spezifische semantische St\u00f6rung. In einer \u00e4hnlichen Art und Weise erhalten wir auch Abfragen, wie etwa: \u201eWer war Kapit\u00e4n der Richmond's VFL-Reservemannschaft?\u201c Oder: \u201eWen hat Graham letztes Jahr im gro\u00dfen Finale geschlagen?\u201c Schlie\u00dflich filtern wir eine Teilmenge der generierten Abfragen basierend auf gew\u00fcnschten Eigenschaften aus. Wie vorhin begr\u00fcndet, m\u00f6chten wir sicherstellen, dass die neue Frage immer noch semantisch nah am Original ist. Bei den Filtertechniken, die keine zus\u00e4tzliche \u00dcberwachung erfordern, speichern wir einfach neue Fragen, die einen kleinen Token-Label und einen Bearbeitungsabstand von der urspr\u00fcnglichen Frage haben. Wir entfernen zum Beispiel die Frage: \u201eWen hat Graham letztes Jahr im gro\u00dfen Finale geschlagen?\u201c Denn diese hat einen l\u00e4ngeren Bearbeitungsabstand zur urspr\u00fcnglichen Frage. In unseren Experimenten zeigen wir, dass diese einfache Heuristik verwendet werden kann, um Trainingsdaten zu erweitern und in die Warteschlange zu stellen. Wir experimentieren auch mit einer Filterstrategie, die auf der Art der semantischen St\u00f6rung basiert. Zu diesem Zweck verwenden wir einen allgemeinen Zerlegungsrahmen f\u00fcr die Anfrage mit dem Namen QED. QED identifiziert zwei Teile der Frage: ein Pr\u00e4dikat und eine Referenz. Referenzen sind Substantivgruppen in der Frage, die Entit\u00e4ten im Kontext entsprechen. Ein Pr\u00e4dikat ist im Grunde der verbleibende Teil der Frage. Zum Beispiel sind wir in der Lage, die Abfrage zu zerlegen: \u201eWer war Kapit\u00e4nin der ersten Damenmannschaft des Richmond Football Clubs?\u201c Wir k\u00f6nnen die Frage in zwei Referenzen zerlegen: das Damenteam vom Richmond Football Club und das Pr\u00e4dikat X (wer war Kapit\u00e4nin?). Ein Modell, das auf Referenzen der Pr\u00e4dikatannotationen f\u00fcr NQ trainiert wurde, erlaubt uns diese Zerlegung der Frage. Die Zerlegung sowohl des Originals als auch der generierten Frage basierend auf QED erm\u00f6glicht es uns, unsere generierten Kontrafakten f\u00fcr die Bewertung zu kategorisieren. Konkret erhalten wir zwei Gruppen von Fragen. Es gibt Fragen, bei denen sich die Referenz \u00e4ndert, aber die Pr\u00e4dikate gleichbleiben, und Fragen, bei denen sich die Pr\u00e4dikate \u00e4ndern und optional Referenzen hinzugef\u00fcgt werden. Hier ist ein Beispiel f\u00fcr eine \u00c4nderung der Referenz: \u201eWer war Kapit\u00e4n der Richmond's VFL-Reservemannschaft?\u201c Das ist eine Ver\u00e4nderung des Pr\u00e4dikats: \u201eWer tr\u00e4gt die Nummer neun beim Club?\u201c Wir bewerten nun die Effektivit\u00e4t von RGF-St\u00f6rungen, wenn diese um die Trainingsdaten erg\u00e4nzt werden. Um insbesondere die Effektivit\u00e4t des kontrafaktischen Aufbaus effektiv bewerten zu k\u00f6nnen, experimentieren wir mit zwei starken Baselines des Datenaufbaus. Die erste Baseline, die als zuf\u00e4llige Antwort- und Fragengenerierung bezeichnet wird, f\u00fcgt Daten hinzu, die keine Relation zur urspr\u00fcnglichen Frage haben. Das hei\u00dft, dass Passagen und Antworten einfach zuf\u00e4llig aus Wikipedia entnommen werden. Diese Baseline f\u00fcgt im Grunde mehr Daten hinzu, die wie NQ aussehen. Mit der zweiten Baseline, der Goldantwort und der Fragengeneration, aktualisieren wir speziell den Retrieval bei unserer Methode. Hier werden alternative Antworten nur aus der gleichen Passage ausgew\u00e4hlt, welche die Goldantwort enth\u00e4lt. Welche Leistung erbringen die Baselines, RGF und der Aufbau beim Leseverst\u00e4ndnis, wo das Modell Zugriff auf Frage und Kontext hat? Wir experimentieren mit sechs von den Datens\u00e4tzen der Dom\u00e4ne und pr\u00e4sentieren hier die Ergebnisse, wobei es bei den Daten um die Trainingsdaten geht und beim Aufbau verdoppelt werden. Wir stellten fest, dass beide Baselines des Datenaufbaus nicht in der Lage sind, unsere Verallgemeinerung der Dom\u00e4ne zu verbessern. Tats\u00e4chlich scheint ein Ensemble von sechs Modellen, die mit den urspr\u00fcnglichen Daten trainiert wurden, die wettbewerbsf\u00e4higste Baseline zu sein. Im Vergleich zu dieser Baseline stellten wir fest, dass RGF-Kontrafakten in der Lage sind, die Leistung au\u00dferhalb der Dom\u00e4ne zu verbessern, w\u00e4hrend die Leistung innerhalb der Dom\u00e4ne beibehalten wird. Dies deutet darauf hin, dass das F\u00fcllen der Argumentationsl\u00fccken beim Modell \u00fcber einen kontrafaktischen Aufbau effektiver ist als mehr Daten aus der Training-Verteilung hinzuzuf\u00fcgen. Dar\u00fcber hinaus fanden wir heraus, dass die Verwendung von Retrievals zur Erprobung alternativer Ergebnisse oder Antworten f\u00fcr effektive CDA wichtig ist. Wir experimentieren auch mit einer offenen Dom\u00e4ne-QA -Einstellung, bei der das Modell nur die Frage sieht. Wir bewerten wieder vier von den Datens\u00e4tzen der Dom\u00e4ne. Wir stellten fest, dass die Baseline-Modelle nicht so effektiv f\u00fcr die Verallgemeinerung der Dom\u00e4ne sind. Allerdings zeigt der Datenaufbau mit RGF signifikantere Verbesserungen. Wir verbessern uns sogar in der Dom\u00e4ne NQ-Datensatz. Wir haben angenommen, dass der kontrafaktische Datenaufbau das Modell beim Lernen von besseren Abfragekodierungen f\u00fcr sehr \u00e4hnliche Abfragen unterst\u00fctzt. Schlie\u00dflich bewerten wir auch die F\u00e4higkeit des Modells, die Einheitlichkeit in der lokalen Nachbarschaft der urspr\u00fcnglichen Frage zu verbessern. Die Einheitlichkeit misst den Anteil der vom Modell korrekt beantworteten Fragen, bei denen sowohl das Original als auch die kontrafaktische Abfrage korrekt beantwortet werden. Dies hilft uns explizit, die Robustheit des Modells bei kleinen St\u00f6rungen in der N\u00e4he der urspr\u00fcnglichen Eingabe zu messen. Wir experimentieren mit f\u00fcnf Datens\u00e4tzen, die Paare von Fragen enthalten, die semantisch nahe beieinander liegen. Abgesehen von den drei Datens\u00e4tzen AQA, AmbigQA und den QUOREF-Kontrasts\u00e4tzen, die bereits verf\u00fcgbar sind, bewerten wir auch RGF-Kontrafakten. Diese sind mit urspr\u00fcnglichen NQ-Fragen gepaart, basierend darauf, ob sie von einer Pr\u00e4dikat- oder Referenz\u00e4nderung betroffen waren. Diese Teilmengen wurden intern annotiert, um Qualit\u00e4tsm\u00e4ngel zu eliminieren. Sie werden als Ressource bereitgestellt. Alle Baselines k\u00f6nnen die Einheitlichkeit signifikant nicht verbessern. Das Ensemble der Modelle kann die Einheitlichkeit geringf\u00fcgig verbessern. Der kontrafaktische Aufbau der RGF kann jedoch eine beeindruckende Steigerung der Einheitlichkeit sowohl bei fr\u00fcheren Datens\u00e4tzen als auch bei den beiden Teilmengen, die wir f\u00fcr Referenz- und Pr\u00e4dikat-St\u00f6rungen ausgew\u00e4hlt haben, aufweisen. Beachten Sie, dass die erweiterten RGF-Daten nicht durch den St\u00f6rungstyp verf\u00e4lscht werden, sondern nur durch die Evaluationss\u00e4tze. Tats\u00e4chlich zeigt eine qualitative \u00dcberpr\u00fcfung der verschiedenen Arten von Kontrafaktoren, dass die generierten Fragen mehrere unterschiedliche St\u00f6rungen enthalten. Zum Beispiel ist diese urspr\u00fcngliche Frage \u00fcber die Bev\u00f6lkerung von Walnut Grove in Minnesota gest\u00f6rt. Diese St\u00f6rung betrifft verschiedene Dimensionen wie Stadt, Bundesland, Land und verschiedene Pr\u00e4dikate wie Lage, Armut, Anzahl von Schulen. Das Audio von St\u00f6rungen ist kontextspezifisch. Bei dieser anderen Frage \u00fcber das Einzelturnier in Wimbledon handelt die St\u00f6rung von der Art des Spiels, der Art des Turniers oder des Spielergebnisses. Abschlie\u00dfende Erkenntnisse: Wir befassen uns mit der Aufgabe des kontrafaktischen Datenaufbaus und St\u00f6rungen bei der Information. Wir suchen nach Abfragen und bew\u00e4ltigen deren einzigartige Herausforderungen durch eine Umkehrung des Generierungsansatzes. Wir \u00fcbergenerieren mithilfe von Near-Misses des Modells und filtern basierend auf dem St\u00f6rungstyp oder der Minimalit\u00e4t. Wir stellten fest, dass diese Technik keiner zus\u00e4tzlichen \u00dcberwachung bedarf und die Beispiele f\u00fcr den Aufbau markiert sind. Der Aufbau verbessert sich dank der Dom\u00e4neverallgemeinerung und der Konsistenz der Nachbarschaft. Zudem stellten wir fest, dass die RGF-Kontrafakten semantisch divers sind, ohne dass Verzerrungen w\u00e4hrend des Aufbaus eingef\u00fchrt wurden. Vielen Dank!", "source": ["2/acl_6060/dev/full_wavs/2022.acl-long.117.wav", "samplerate: 16000 Hz", "channels: 1", "duration: 1e+01:9.014 min", "format: WAV (Microsoft) [WAV]", "subtype: Signed 16 bit PCM [PCM_16]"], "source_length": 729013.6875}
